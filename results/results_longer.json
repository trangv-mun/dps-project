{
  "dense": [
    {
      "eval_exact_match": 77.86187322611164,
      "eval_f1": 86.77091537210505,
      "eval_runtime": 24.8511,
      "eval_samples": 10784,
      "eval_samples_per_second": 433.945,
      "eval_steps_per_second": 54.243,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7554738049162706,
      "train_runtime": 1300.8848,
      "train_samples": 88524,
      "train_samples_per_second": 204.147,
      "train_steps_per_second": 12.76,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.970603942871094,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.804731369018555,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.380484580993652,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3347,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 14.08846664428711,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2417,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.178503036499023,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1392,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.903520584106445,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0983,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.533294677734375,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1026,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 9.024723052978516,
            "learning_rate": 2.5306914786799653e-05,
            "loss": 1.0413,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.536866188049316,
            "learning_rate": 2.4302831514826963e-05,
            "loss": 1.0002,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 11.731292724609375,
            "learning_rate": 2.3298748242854276e-05,
            "loss": 1.0057,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.136830806732178,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0026,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.25922421948913,
            "eval_f1": 86.63274980908686,
            "eval_runtime": 24.4782,
            "eval_samples_per_second": 440.555,
            "eval_steps_per_second": 55.069,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.501175403594971,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6556,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.708466053009033,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.6156,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 16.710006713867188,
            "learning_rate": 1.9284423321507463e-05,
            "loss": 0.6274,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 12.029682159423828,
            "learning_rate": 1.8280340049534776e-05,
            "loss": 0.6152,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.386755466461182,
            "learning_rate": 1.7276256777562085e-05,
            "loss": 0.6149,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 11.069730758666992,
            "learning_rate": 1.6272173505589395e-05,
            "loss": 0.6343,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 24.942893981933594,
            "learning_rate": 1.5268090233616708e-05,
            "loss": 0.6013,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 12.113030433654785,
            "learning_rate": 1.4264006961644019e-05,
            "loss": 0.5941,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 14.376262664794922,
            "learning_rate": 1.3261931856215275e-05,
            "loss": 0.6069,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 13.256561279296875,
            "learning_rate": 1.2257848584242588e-05,
            "loss": 0.5967,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.69084095954895,
            "learning_rate": 1.1253765312269899e-05,
            "loss": 0.5973,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.17975402081362,
            "eval_f1": 87.8749472812861,
            "eval_runtime": 24.4598,
            "eval_samples_per_second": 440.887,
            "eval_steps_per_second": 55.111,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.66694164276123,
            "learning_rate": 1.0249682040297208e-05,
            "loss": 0.2833,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.428456783294678,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.2471,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 23.25951385498047,
            "learning_rate": 8.243523662895777e-06,
            "loss": 0.2336,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.047767162322998,
            "learning_rate": 7.239440390923088e-06,
            "loss": 0.236,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 7.350187301635742,
            "learning_rate": 6.235357118950398e-06,
            "loss": 0.2428,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 8.905328750610352,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2371,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.3516621589660645,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2269,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 10.33725643157959,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2293,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.63990020751953,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2263,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 19.68137550354004,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.216,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 13.88097858428955,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2233,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.86187322611164,
            "eval_f1": 86.77091537210505,
            "eval_runtime": 25.0784,
            "eval_samples_per_second": 430.011,
            "eval_steps_per_second": 53.751,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7554738049162706,
            "train_runtime": 1300.8848,
            "train_samples_per_second": 204.147,
            "train_steps_per_second": 12.76
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 78.02270577105014,
      "eval_f1": 86.85803853396379,
      "eval_runtime": 24.9034,
      "eval_samples": 10784,
      "eval_samples_per_second": 433.034,
      "eval_steps_per_second": 54.129,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7558537194855106,
      "train_runtime": 1303.7922,
      "train_samples": 88524,
      "train_samples_per_second": 203.692,
      "train_steps_per_second": 12.731,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.61409568786621,
            "learning_rate": 9e-06,
            "loss": 4.0975,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.848051071166992,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6165,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.517473220825195,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3337,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 13.623806953430176,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.2418,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.779327392578125,
            "learning_rate": 2.8317156436173775e-05,
            "loss": 1.1378,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.29140853881836,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.0985,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 15.74545669555664,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.104,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 11.427583694458008,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0422,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 8.944720268249512,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.0025,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 9.993041038513184,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0065,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.899055004119873,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 0.9992,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.87417218543047,
            "eval_f1": 87.06832556037155,
            "eval_runtime": 24.9308,
            "eval_samples_per_second": 432.558,
            "eval_steps_per_second": 54.07,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.608479022979736,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6515,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.744524955749512,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6195,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 19.040040969848633,
            "learning_rate": 1.9288439654595356e-05,
            "loss": 0.6256,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 12.135294914245605,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.6209,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 12.243901252746582,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.6205,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 12.996682167053223,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.6341,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 22.661287307739258,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.6032,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 13.306790351867676,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5986,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 15.660735130310059,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6049,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 11.275062561035156,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.5957,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.5150084495544434,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.599,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.81078524124882,
            "eval_f1": 87.57432089839455,
            "eval_runtime": 24.5376,
            "eval_samples_per_second": 439.49,
            "eval_steps_per_second": 54.936,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.21121883392334,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.2794,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 8.773653984069824,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.2434,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 18.321502685546875,
            "learning_rate": 8.243523662895777e-06,
            "loss": 0.2342,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.70812463760376,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2385,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 11.28438663482666,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2385,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 4.1968889236450195,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2502,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 9.222129821777344,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.2295,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 14.986085891723633,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2282,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 15.604327201843262,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2266,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 16.624326705932617,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.2138,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 9.708937644958496,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2187,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.02270577105014,
            "eval_f1": 86.85803853396379,
            "eval_runtime": 24.959,
            "eval_samples_per_second": 432.068,
            "eval_steps_per_second": 54.008,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7558537194855106,
            "train_runtime": 1303.7922,
            "train_samples_per_second": 203.692,
            "train_steps_per_second": 12.731
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.80510879848629,
      "eval_f1": 86.76798353864886,
      "eval_runtime": 26.9264,
      "eval_samples": 10784,
      "eval_samples_per_second": 400.499,
      "eval_steps_per_second": 50.062,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7544995957206866,
      "train_runtime": 1367.0492,
      "train_samples": 88524,
      "train_samples_per_second": 194.267,
      "train_steps_per_second": 12.142,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.98105239868164,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.82612419128418,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6164,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.466663360595703,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3349,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 13.561144828796387,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.2422,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.113189697265625,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.139,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 12.968436241149902,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.098,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.620748519897461,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.1025,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 12.018250465393066,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.045,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.162771224975586,
            "learning_rate": 2.430483968137091e-05,
            "loss": 0.9999,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.546636581420898,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0089,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.197096824645996,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0041,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.63765373699148,
            "eval_f1": 86.82266394895522,
            "eval_runtime": 27.6557,
            "eval_samples_per_second": 389.938,
            "eval_steps_per_second": 48.742,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.249050140380859,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.6489,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.609647750854492,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6159,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 23.033611297607422,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6209,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 16.418630599975586,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.615,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 8.817246437072754,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6157,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 16.403783798217773,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6325,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.926048278808594,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.6006,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 13.550437927246094,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5902,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 16.531274795532227,
            "learning_rate": 1.3265948189303167e-05,
            "loss": 0.6036,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.90988540649414,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.597,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.113998889923096,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.5971,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.81078524124882,
            "eval_f1": 87.52412525531214,
            "eval_runtime": 26.752,
            "eval_samples_per_second": 403.11,
            "eval_steps_per_second": 50.389,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.074183464050293,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.2792,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 6.705899715423584,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2431,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 16.820695877075195,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2397,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.492344856262207,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2341,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 20.36311912536621,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2351,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 9.891864776611328,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2434,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 9.534126281738281,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2243,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 10.222543716430664,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2286,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 15.645332336425781,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2226,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.285850524902344,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.214,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.398012161254883,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2193,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.80510879848629,
            "eval_f1": 86.76798353864886,
            "eval_runtime": 27.6057,
            "eval_samples_per_second": 390.643,
            "eval_steps_per_second": 48.83,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7544995957206866,
            "train_runtime": 1367.0492,
            "train_samples_per_second": 194.267,
            "train_steps_per_second": 12.142
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.99432355723746,
      "eval_f1": 86.8689334809468,
      "eval_runtime": 24.7046,
      "eval_samples": 10784,
      "eval_samples_per_second": 436.517,
      "eval_steps_per_second": 54.565,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7521296708625055,
      "train_runtime": 1318.6306,
      "train_samples": 88524,
      "train_samples_per_second": 201.4,
      "train_steps_per_second": 12.588,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.984663009643555,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.762187957763672,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.388188362121582,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3355,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 14.857826232910156,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.2422,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.158254623413086,
            "learning_rate": 2.8317156436173775e-05,
            "loss": 1.1385,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.273405075073242,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.0958,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.829570770263672,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.1,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 14.474534034729004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0411,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.964914321899414,
            "learning_rate": 2.430483968137091e-05,
            "loss": 0.9971,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.156379699707031,
            "learning_rate": 2.3302764575942168e-05,
            "loss": 1.0019,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.056805610656738,
            "learning_rate": 2.2298681303969478e-05,
            "loss": 1.0019,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.81740775780511,
            "eval_f1": 86.98498181273037,
            "eval_runtime": 24.2094,
            "eval_samples_per_second": 445.447,
            "eval_steps_per_second": 55.681,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.56065559387207,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.6485,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.494468688964844,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6144,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 20.961044311523438,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6192,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.188990592956543,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6098,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 9.44714641571045,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6131,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 18.09085464477539,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6293,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.673095703125,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.6002,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.885472297668457,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5966,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 13.731654167175293,
            "learning_rate": 1.3265948189303167e-05,
            "loss": 0.6052,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.820796966552734,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5958,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.316528797149658,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.598,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.94323557237465,
            "eval_f1": 87.80681403841953,
            "eval_runtime": 24.2523,
            "eval_samples_per_second": 444.659,
            "eval_steps_per_second": 55.582,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 8.892772674560547,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.2741,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.514345645904541,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2384,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 19.22227668762207,
            "learning_rate": 8.247539995983668e-06,
            "loss": 0.2291,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 4.970686912536621,
            "learning_rate": 7.243456724010978e-06,
            "loss": 0.23,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 16.61489486694336,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.2324,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 10.988911628723145,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.2364,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.743374824523926,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2226,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 10.85326099395752,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2235,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 16.16131019592285,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2143,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 13.046173095703125,
            "learning_rate": 1.2209652587187898e-06,
            "loss": 0.2105,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 15.498839378356934,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.2206,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.99432355723746,
            "eval_f1": 86.8689334809468,
            "eval_runtime": 25.3807,
            "eval_samples_per_second": 424.891,
            "eval_steps_per_second": 53.111,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7521296708625055,
            "train_runtime": 1318.6306,
            "train_samples_per_second": 201.4,
            "train_steps_per_second": 12.588
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.95648060548723,
      "eval_f1": 86.88074478213977,
      "eval_runtime": 25.789,
      "eval_samples": 10784,
      "eval_samples_per_second": 418.163,
      "eval_steps_per_second": 52.27,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7554270630967539,
      "train_runtime": 1293.292,
      "train_samples": 88524,
      "train_samples_per_second": 205.346,
      "train_steps_per_second": 12.835,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.9835147857666,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.759159088134766,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6162,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.465298652648926,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3339,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 12.852956771850586,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.242,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.10047721862793,
            "learning_rate": 2.8317156436173775e-05,
            "loss": 1.1402,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 15.836434364318848,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0996,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.189743995666504,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.1008,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 21.424758911132812,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0454,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.718111991882324,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.0,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 18.330875396728516,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0083,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.098560810089111,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0036,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.55250709555345,
            "eval_f1": 86.87728820484264,
            "eval_runtime": 24.5933,
            "eval_samples_per_second": 438.494,
            "eval_steps_per_second": 54.812,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.443630695343018,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.6557,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.791431427001953,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.618,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 23.992198944091797,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6231,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 11.402138710021973,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6186,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 8.46717643737793,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.613,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 12.221261978149414,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6309,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.23282814025879,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.6035,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 12.062396049499512,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5981,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 13.955653190612793,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6041,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 9.45583438873291,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5953,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.370293378829956,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.6011,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.02838221381268,
            "eval_f1": 87.83777343702889,
            "eval_runtime": 24.6465,
            "eval_samples_per_second": 437.547,
            "eval_steps_per_second": 54.693,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.662251472473145,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.2803,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 8.336333274841309,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2454,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 19.651763916015625,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.233,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.620663642883301,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.236,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 12.218334197998047,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2402,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 8.943901062011719,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2411,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 9.507898330688477,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.2239,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 10.429471969604492,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.2295,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 18.494911193847656,
            "learning_rate": 2.2210321976035883e-06,
            "loss": 0.225,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 14.918323516845703,
            "learning_rate": 1.216948925630899e-06,
            "loss": 0.2174,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 13.516860008239746,
            "learning_rate": 2.1286565365821007e-07,
            "loss": 0.2197,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.95648060548723,
            "eval_f1": 86.88074478213977,
            "eval_runtime": 26.231,
            "eval_samples_per_second": 411.117,
            "eval_steps_per_second": 51.39,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7554270630967539,
            "train_runtime": 1293.292,
            "train_samples_per_second": 205.346,
            "train_steps_per_second": 12.835
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 78.24976348155155,
      "eval_f1": 87.07653582096017,
      "eval_runtime": 26.5602,
      "eval_samples": 10784,
      "eval_samples_per_second": 406.021,
      "eval_steps_per_second": 50.753,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7536249642803321,
      "train_runtime": 1350.9228,
      "train_samples": 88524,
      "train_samples_per_second": 196.586,
      "train_steps_per_second": 12.287,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.633420944213867,
            "learning_rate": 8.981927710843375e-06,
            "loss": 4.0996,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.110464096069336,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.6213,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.35235595703125,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.3337,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.565200805664062,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2439,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.889095306396484,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1409,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.727564811706543,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0975,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.632230758666992,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.1008,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 17.388347625732422,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0426,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 12.786723136901855,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.0005,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 9.806448936462402,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0039,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.046446800231934,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0011,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.63765373699148,
            "eval_f1": 86.95627163032135,
            "eval_runtime": 25.8515,
            "eval_samples_per_second": 417.152,
            "eval_steps_per_second": 52.144,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.405757904052734,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6523,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.021928310394287,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6175,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 29.023244857788086,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6196,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 14.20254135131836,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6136,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 8.100659370422363,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6143,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 17.568113327026367,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6313,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 24.27451515197754,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.6004,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 11.205479621887207,
            "learning_rate": 1.4266015128187965e-05,
            "loss": 0.596,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 18.33684730529785,
            "learning_rate": 1.3261931856215275e-05,
            "loss": 0.6033,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.265204429626465,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.5959,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 5.00691032409668,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.5988,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.00946073793756,
            "eval_f1": 87.79054706889337,
            "eval_runtime": 25.5258,
            "eval_samples_per_second": 422.474,
            "eval_steps_per_second": 52.809,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 8.423199653625488,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.2813,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 8.856779098510742,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.2407,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 46.67563247680664,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2268,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.207851409912109,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.237,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 5.570068836212158,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2318,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 10.813559532165527,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2344,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 9.399791717529297,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.2193,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 11.634828567504883,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.2265,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 18.011850357055664,
            "learning_rate": 2.2210321976035883e-06,
            "loss": 0.2204,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 12.90722942352295,
            "learning_rate": 1.216948925630899e-06,
            "loss": 0.2118,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 12.726250648498535,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.22,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.24976348155155,
            "eval_f1": 87.07653582096017,
            "eval_runtime": 26.3344,
            "eval_samples_per_second": 409.503,
            "eval_steps_per_second": 51.188,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7536249642803321,
            "train_runtime": 1350.9228,
            "train_samples_per_second": 196.586,
            "train_steps_per_second": 12.287
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.86187322611164,
      "eval_f1": 86.82468964331336,
      "eval_runtime": 27.3932,
      "eval_samples": 10784,
      "eval_samples_per_second": 393.674,
      "eval_steps_per_second": 49.209,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7522731122356401,
      "train_runtime": 1349.9882,
      "train_samples": 88524,
      "train_samples_per_second": 196.722,
      "train_steps_per_second": 12.296,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.286014556884766,
            "learning_rate": 9e-06,
            "loss": 4.0976,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.47948455810547,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6179,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.449310302734375,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.3344,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.979491233825684,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2414,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.092445373535156,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1383,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 15.521081924438477,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.0964,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 15.711648941040039,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.1009,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 26.367189407348633,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0417,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.664338111877441,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.0014,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.777617454528809,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.001,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.9660115242004395,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 0.9979,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.83632923368023,
            "eval_f1": 87.01678315183648,
            "eval_runtime": 25.8794,
            "eval_samples_per_second": 416.702,
            "eval_steps_per_second": 52.088,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.721780300140381,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6518,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.157027721405029,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.616,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 18.342296600341797,
            "learning_rate": 1.9284423321507463e-05,
            "loss": 0.6158,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 13.770956993103027,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6086,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 9.93601131439209,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6141,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 13.27469253540039,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6284,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 23.53200912475586,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.599,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 13.09061050415039,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5985,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 16.613563537597656,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6051,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.291887283325195,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.5967,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.2745351791381836,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.5981,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.72563859981078,
            "eval_f1": 87.60389839974769,
            "eval_runtime": 25.9324,
            "eval_samples_per_second": 415.85,
            "eval_steps_per_second": 51.981,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.098958015441895,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.2772,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.7950921058654785,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.2388,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 20.091442108154297,
            "learning_rate": 8.243523662895777e-06,
            "loss": 0.2259,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.179221153259277,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2284,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 29.358407974243164,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2346,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 8.80049991607666,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2365,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.82114028930664,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.219,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 8.232596397399902,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.2235,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 15.884819984436035,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2187,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 16.0103759765625,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.216,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 13.291433334350586,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2146,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.86187322611164,
            "eval_f1": 86.82468964331336,
            "eval_runtime": 26.7437,
            "eval_samples_per_second": 403.235,
            "eval_steps_per_second": 50.404,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7522731122356401,
            "train_runtime": 1349.9882,
            "train_samples_per_second": 196.722,
            "train_steps_per_second": 12.296
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 78.00378429517502,
      "eval_f1": 86.91796721723205,
      "eval_runtime": 25.391,
      "eval_samples": 10784,
      "eval_samples_per_second": 424.718,
      "eval_steps_per_second": 53.09,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.753573434382607,
      "train_runtime": 1362.4865,
      "train_samples": 88524,
      "train_samples_per_second": 194.917,
      "train_steps_per_second": 12.183,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.95538330078125,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.79117202758789,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6162,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.418328285217285,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.335,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 12.063992500305176,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.2421,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.174468994140625,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1399,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.136848449707031,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.095,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 16.293760299682617,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.0996,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 20.03820037841797,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0436,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.559122085571289,
            "learning_rate": 2.430483968137091e-05,
            "loss": 0.9986,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 9.445526123046875,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0035,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.592203617095947,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 0.9982,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.43897824030275,
            "eval_f1": 86.73239855975382,
            "eval_runtime": 25.1665,
            "eval_samples_per_second": 428.506,
            "eval_steps_per_second": 53.563,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.842396259307861,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6477,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.193055629730225,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.6151,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 19.261281967163086,
            "learning_rate": 1.9284423321507463e-05,
            "loss": 0.6194,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 12.620041847229004,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6101,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.308969497680664,
            "learning_rate": 1.728228127719392e-05,
            "loss": 0.6149,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 13.768442153930664,
            "learning_rate": 1.6278198005221234e-05,
            "loss": 0.6296,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.878822326660156,
            "learning_rate": 1.5274114733248547e-05,
            "loss": 0.5975,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 11.308368682861328,
            "learning_rate": 1.4270031461275856e-05,
            "loss": 0.5996,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 17.235219955444336,
            "learning_rate": 1.3265948189303167e-05,
            "loss": 0.6041,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.602730751037598,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5966,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.843288898468018,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.6033,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.72563859981078,
            "eval_f1": 87.69762517537097,
            "eval_runtime": 24.9615,
            "eval_samples_per_second": 432.026,
            "eval_steps_per_second": 54.003,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.188482284545898,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.278,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.741922378540039,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2428,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 19.753437042236328,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2311,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 4.763524532318115,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2342,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 9.768630027770996,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.2346,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 9.519665718078613,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.2399,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 9.190213203430176,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2217,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 10.331416130065918,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2266,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 16.873615264892578,
            "learning_rate": 2.2250485306914787e-06,
            "loss": 0.2242,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 28.61549186706543,
            "learning_rate": 1.2209652587187898e-06,
            "loss": 0.2161,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 14.82862377166748,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.2217,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.00378429517502,
            "eval_f1": 86.91796721723205,
            "eval_runtime": 25.5728,
            "eval_samples_per_second": 421.699,
            "eval_steps_per_second": 52.712,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.753573434382607,
            "train_runtime": 1362.4865,
            "train_samples_per_second": 194.917,
            "train_steps_per_second": 12.183
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 78.16461684011352,
      "eval_f1": 86.99877894434383,
      "eval_runtime": 24.732,
      "eval_samples": 10784,
      "eval_samples_per_second": 436.034,
      "eval_steps_per_second": 54.504,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7551597817216023,
      "train_runtime": 1296.6342,
      "train_samples": 88524,
      "train_samples_per_second": 204.816,
      "train_steps_per_second": 12.802,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.984777450561523,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.771827697753906,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.418891906738281,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.3363,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 13.753430366516113,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2404,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.97607421875,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.14,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 12.886763572692871,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0988,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 15.157941818237305,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.1013,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.588085174560547,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.043,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 8.73078441619873,
            "learning_rate": 2.430483968137091e-05,
            "loss": 0.9998,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 11.219423294067383,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0073,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.659802436828613,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0011,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.6092715231788,
            "eval_f1": 86.76788507740814,
            "eval_runtime": 24.7385,
            "eval_samples_per_second": 435.92,
            "eval_steps_per_second": 54.49,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.491450786590576,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6526,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.739998817443848,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.6167,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 21.348403930664062,
            "learning_rate": 1.9284423321507463e-05,
            "loss": 0.6215,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 12.91980266571045,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.618,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.598462104797363,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6147,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.833246231079102,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6347,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 24.214984893798828,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.6016,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 12.419865608215332,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5984,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 15.942450523376465,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6063,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.624794960021973,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.5959,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.040206432342529,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.6047,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.97161778618732,
            "eval_f1": 87.66669190479733,
            "eval_runtime": 24.6737,
            "eval_samples_per_second": 437.065,
            "eval_steps_per_second": 54.633,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.989788055419922,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.2818,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 6.738997459411621,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.2436,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 24.8144474029541,
            "learning_rate": 8.243523662895777e-06,
            "loss": 0.2279,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.058662414550781,
            "learning_rate": 7.239440390923088e-06,
            "loss": 0.2353,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 19.292770385742188,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2393,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 10.290213584899902,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2445,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.815561294555664,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.2249,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 13.923674583435059,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.2254,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 22.347726821899414,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2244,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 17.02342987060547,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.2145,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 11.4618501663208,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2233,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.16461684011352,
            "eval_f1": 86.99877894434383,
            "eval_runtime": 25.1202,
            "eval_samples_per_second": 429.296,
            "eval_steps_per_second": 53.662,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7551597817216023,
            "train_runtime": 1296.6342,
            "train_samples_per_second": 204.816,
            "train_steps_per_second": 12.802
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.71996215704824,
      "eval_f1": 86.83751008694578,
      "eval_runtime": 25.1567,
      "eval_samples": 10784,
      "eval_samples_per_second": 428.673,
      "eval_steps_per_second": 53.584,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7531148338398306,
      "train_runtime": 1295.8585,
      "train_samples": 88524,
      "train_samples_per_second": 204.939,
      "train_steps_per_second": 12.809,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.78221321105957,
            "learning_rate": 9e-06,
            "loss": 4.0972,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.68574333190918,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6166,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.456852912902832,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.3345,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 13.357315063476562,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2415,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.666582107543945,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1379,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.223584175109863,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.1,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.412332534790039,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1054,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 8.311064720153809,
            "learning_rate": 2.5306914786799653e-05,
            "loss": 1.0413,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.216996192932129,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.0015,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.550503730773926,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0042,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.591360569000244,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 0.9997,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.76064333017976,
            "eval_f1": 86.89764114187419,
            "eval_runtime": 24.5041,
            "eval_samples_per_second": 440.09,
            "eval_steps_per_second": 55.011,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.858114719390869,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.648,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.150188446044922,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.6173,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 13.119677543640137,
            "learning_rate": 1.9284423321507463e-05,
            "loss": 0.6191,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.860458374023438,
            "learning_rate": 1.8280340049534776e-05,
            "loss": 0.6142,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 10.037524223327637,
            "learning_rate": 1.7276256777562085e-05,
            "loss": 0.6142,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 20.159120559692383,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6324,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 17.355731964111328,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.5981,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 12.90291690826416,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5934,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 15.991959571838379,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6035,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 8.742831230163574,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.6,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.8665995597839355,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.5934,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.85808893093662,
            "eval_f1": 87.66812865734397,
            "eval_runtime": 24.5105,
            "eval_samples_per_second": 439.974,
            "eval_steps_per_second": 54.997,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.101067543029785,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.2789,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 9.41380500793457,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.2424,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 18.368144989013672,
            "learning_rate": 8.243523662895777e-06,
            "loss": 0.2308,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.862370491027832,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2309,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 30.323684692382812,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.235,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 41.46225357055664,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2351,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.978047370910645,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.2234,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.006926536560059,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2218,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 18.37108612060547,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2225,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 12.916787147521973,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.2155,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 14.397943496704102,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2158,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.71996215704824,
            "eval_f1": 86.83751008694578,
            "eval_runtime": 25.2263,
            "eval_samples_per_second": 427.49,
            "eval_steps_per_second": 53.436,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7531148338398306,
            "train_runtime": 1295.8585,
            "train_samples_per_second": 204.939,
            "train_steps_per_second": 12.809
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    }
  ],
  "mix": [
    {
      "eval_exact_match": 78.08893093661305,
      "eval_f1": 86.91928579333005,
      "eval_runtime": 25.1692,
      "eval_samples": 10784,
      "eval_samples_per_second": 428.46,
      "eval_steps_per_second": 53.558,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.755310684609495,
      "train_runtime": 1310.8133,
      "train_samples": 88524,
      "train_samples_per_second": 202.601,
      "train_steps_per_second": 12.663,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.970603942871094,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.81585121154785,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.338027954101562,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3344,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 13.177033424377441,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.2415,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 15.570135116577148,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1392,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.828787803649902,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0982,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.999775886535645,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1027,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 23.252321243286133,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0426,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.4190092086792,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.002,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 11.441801071166992,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0063,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.154688835144043,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0037,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.54304635761589,
            "eval_f1": 86.76498202634384,
            "eval_runtime": 24.9694,
            "eval_samples_per_second": 431.889,
            "eval_steps_per_second": 53.986,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.526037216186523,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6515,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.165730953216553,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.617,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 24.147018432617188,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6232,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 13.658651351928711,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6153,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 8.46008586883545,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6192,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 22.604101181030273,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.637,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 20.901744842529297,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.5991,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 12.35442066192627,
            "learning_rate": 1.4266015128187965e-05,
            "loss": 0.5992,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 15.17541790008545,
            "learning_rate": 1.3261931856215275e-05,
            "loss": 0.5999,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.591423034667969,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.6,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 5.002105712890625,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.5978,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.8391674550615,
            "eval_f1": 87.55665033504532,
            "eval_runtime": 24.4739,
            "eval_samples_per_second": 440.633,
            "eval_steps_per_second": 55.079,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 8.158547401428223,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.2816,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.5648322105407715,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2448,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 17.102060317993164,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2364,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.019179821014404,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2382,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 14.159284591674805,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.2357,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 10.573875427246094,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.2442,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.432377815246582,
            "learning_rate": 4.233215074636857e-06,
            "loss": 0.2254,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 11.53770637512207,
            "learning_rate": 3.229131802664168e-06,
            "loss": 0.2263,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.9929256439209,
            "learning_rate": 2.2250485306914787e-06,
            "loss": 0.2201,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 13.241512298583984,
            "learning_rate": 1.2209652587187898e-06,
            "loss": 0.2198,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 20.848390579223633,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.2189,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.08893093661305,
            "eval_f1": 86.91928579333005,
            "eval_runtime": 25.6878,
            "eval_samples_per_second": 419.81,
            "eval_steps_per_second": 52.476,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.755310684609495,
            "train_runtime": 1310.8133,
            "train_samples_per_second": 202.601,
            "train_steps_per_second": 12.663
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 78.06054872280038,
      "eval_f1": 87.06995160757228,
      "eval_runtime": 25.1124,
      "eval_samples": 10784,
      "eval_samples_per_second": 429.43,
      "eval_steps_per_second": 53.679,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7566524142277902,
      "train_runtime": 1301.8901,
      "train_samples": 88524,
      "train_samples_per_second": 203.99,
      "train_steps_per_second": 12.75,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.923812866210938,
            "learning_rate": 8.981927710843375e-06,
            "loss": 4.1009,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.388729095458984,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.6183,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.341835021972656,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.3348,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 12.46716594696045,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2427,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.04957389831543,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1427,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.149796485900879,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.1025,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 15.583542823791504,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1065,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 18.36817169189453,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0452,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 8.764806747436523,
            "learning_rate": 2.4306847847914855e-05,
            "loss": 1.0003,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.720274925231934,
            "learning_rate": 2.3302764575942168e-05,
            "loss": 1.0055,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.545159816741943,
            "learning_rate": 2.2298681303969478e-05,
            "loss": 1.0054,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.52412488174078,
            "eval_f1": 86.9963526264143,
            "eval_runtime": 24.3888,
            "eval_samples_per_second": 442.17,
            "eval_steps_per_second": 55.271,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.890732288360596,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.653,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.253884792327881,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6226,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 19.81784439086914,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6241,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 13.064631462097168,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6198,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.9284210205078125,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6213,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 13.188237190246582,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6332,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 22.611217498779297,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.6047,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 12.178255081176758,
            "learning_rate": 1.4266015128187965e-05,
            "loss": 0.5957,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 16.458147048950195,
            "learning_rate": 1.3261931856215275e-05,
            "loss": 0.6023,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 13.037262916564941,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5981,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.693665981292725,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.6055,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.82024597918638,
            "eval_f1": 87.67584551468059,
            "eval_runtime": 24.4928,
            "eval_samples_per_second": 440.292,
            "eval_steps_per_second": 55.036,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.211557388305664,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.285,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.8815813064575195,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2453,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 23.141443252563477,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2363,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 4.393406867980957,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2317,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 10.15151596069336,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.238,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 10.742380142211914,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.239,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.73530912399292,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2261,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.563495635986328,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2305,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.94843292236328,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2254,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 8.992972373962402,
            "learning_rate": 1.2209652587187898e-06,
            "loss": 0.2167,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 14.611917495727539,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.2219,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.06054872280038,
            "eval_f1": 87.06995160757228,
            "eval_runtime": 25.7826,
            "eval_samples_per_second": 418.266,
            "eval_steps_per_second": 52.283,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7566524142277902,
            "train_runtime": 1301.8901,
            "train_samples_per_second": 203.99,
            "train_steps_per_second": 12.75
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.94701986754967,
      "eval_f1": 86.89194657388089,
      "eval_runtime": 26.7787,
      "eval_samples": 10784,
      "eval_samples_per_second": 402.708,
      "eval_steps_per_second": 50.339,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7520570868188713,
      "train_runtime": 1366.4973,
      "train_samples": 88524,
      "train_samples_per_second": 194.345,
      "train_steps_per_second": 12.147,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.669435501098633,
            "learning_rate": 9e-06,
            "loss": 4.0963,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.777402877807617,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6154,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.475616455078125,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3341,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 13.197420120239258,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.2424,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.318603515625,
            "learning_rate": 2.8317156436173775e-05,
            "loss": 1.1402,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.206290245056152,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.0995,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.253211975097656,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.099,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 24.83576011657715,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0403,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.046103477478027,
            "learning_rate": 2.430483968137091e-05,
            "loss": 0.9982,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 9.373503684997559,
            "learning_rate": 2.330075640939822e-05,
            "loss": 0.9981,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.058871269226074,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.80794701986756,
            "eval_f1": 87.00044442399464,
            "eval_runtime": 26.7294,
            "eval_samples_per_second": 403.45,
            "eval_steps_per_second": 50.431,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.9249372482299805,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.6468,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.931378364562988,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6165,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 16.6803035736084,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6199,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 13.848536491394043,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6121,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.2901482582092285,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6117,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 20.794118881225586,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6282,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 22.16570281982422,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.5988,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 12.006074905395508,
            "learning_rate": 1.4270031461275856e-05,
            "loss": 0.5904,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 14.045666694641113,
            "learning_rate": 1.3265948189303167e-05,
            "loss": 0.6039,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.81229019165039,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5967,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 7.575899124145508,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.6006,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.14191106906338,
            "eval_f1": 87.9410697855373,
            "eval_runtime": 26.3687,
            "eval_samples_per_second": 408.97,
            "eval_steps_per_second": 51.121,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.875475883483887,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.277,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 8.093500137329102,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2384,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 16.074417114257812,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2283,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.831007480621338,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2322,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 10.142205238342285,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2297,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 8.153590202331543,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2368,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 9.05085563659668,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.2224,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.308281898498535,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.2222,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 16.78917694091797,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2208,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 20.919113159179688,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.2144,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 13.42729377746582,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2168,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.94701986754967,
            "eval_f1": 86.89194657388089,
            "eval_runtime": 27.0261,
            "eval_samples_per_second": 399.022,
            "eval_steps_per_second": 49.878,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7520570868188713,
            "train_runtime": 1366.4973,
            "train_samples_per_second": 194.345,
            "train_steps_per_second": 12.147
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.918637653737,
      "eval_f1": 86.94018053340595,
      "eval_runtime": 26.9893,
      "eval_samples": 10784,
      "eval_samples_per_second": 399.566,
      "eval_steps_per_second": 49.946,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7551515698612465,
      "train_runtime": 1380.882,
      "train_samples": 88524,
      "train_samples_per_second": 192.321,
      "train_steps_per_second": 12.021,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.033666610717773,
            "learning_rate": 9e-06,
            "loss": 4.097,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.666702270507812,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6164,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.499272346496582,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3346,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 14.37752628326416,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2432,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.4224853515625,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1381,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 12.05223560333252,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0987,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.309002876281738,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1063,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.974637985229492,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0419,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.208895683288574,
            "learning_rate": 2.430483968137091e-05,
            "loss": 0.9999,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.047924041748047,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0028,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.608819484710693,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0006,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.59035004730369,
            "eval_f1": 86.74343983627931,
            "eval_runtime": 27.3745,
            "eval_samples_per_second": 393.943,
            "eval_steps_per_second": 49.243,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.3986430168151855,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6509,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.779131889343262,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6177,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 16.46636390686035,
            "learning_rate": 1.9288439654595356e-05,
            "loss": 0.6219,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 12.356283187866211,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.6185,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 11.191187858581543,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.6164,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 13.247360229492188,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.6349,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 25.455198287963867,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.6029,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 11.308798789978027,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5984,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 17.108261108398438,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.602,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 9.968732833862305,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5924,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.001882553100586,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.6023,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.0473036896878,
            "eval_f1": 87.7267269557717,
            "eval_runtime": 27.0372,
            "eval_samples_per_second": 398.858,
            "eval_steps_per_second": 49.857,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.343323707580566,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.2809,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.260697841644287,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2469,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 19.819599151611328,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2323,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 4.915976047515869,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2366,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 7.692312240600586,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2376,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 9.105295181274414,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2408,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.262242317199707,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.228,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 15.575957298278809,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.2302,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 18.8706111907959,
            "learning_rate": 2.2210321976035883e-06,
            "loss": 0.2219,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 10.716763496398926,
            "learning_rate": 1.216948925630899e-06,
            "loss": 0.2159,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 12.173624038696289,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2224,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.918637653737,
            "eval_f1": 86.94018053340595,
            "eval_runtime": 27.877,
            "eval_samples_per_second": 386.842,
            "eval_steps_per_second": 48.355,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7551515698612465,
            "train_runtime": 1380.882,
            "train_samples_per_second": 192.321,
            "train_steps_per_second": 12.021
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 78.240302743614,
      "eval_f1": 87.08203756920751,
      "eval_runtime": 25.0676,
      "eval_samples": 10784,
      "eval_samples_per_second": 430.197,
      "eval_steps_per_second": 53.775,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.755191102732563,
      "train_runtime": 1332.1579,
      "train_samples": 88524,
      "train_samples_per_second": 199.355,
      "train_steps_per_second": 12.46,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.969066619873047,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.78342056274414,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.525702476501465,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.3347,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 14.277837753295898,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2391,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.486818313598633,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1404,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.0197114944458,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0961,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 16.532373428344727,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1029,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 17.84205436706543,
            "learning_rate": 2.5306914786799653e-05,
            "loss": 1.0424,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.208499908447266,
            "learning_rate": 2.4302831514826963e-05,
            "loss": 1.0018,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 11.008685111999512,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0063,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.341747760772705,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0039,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.06338694418164,
            "eval_f1": 87.17875392840983,
            "eval_runtime": 25.0606,
            "eval_samples_per_second": 430.317,
            "eval_steps_per_second": 53.79,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.663729190826416,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.6569,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.377005100250244,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6165,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 26.776920318603516,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6223,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 12.797605514526367,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6166,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.365614414215088,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6173,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 16.739608764648438,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.6334,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.817729949951172,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.6014,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 11.066028594970703,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5982,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 27.72222137451172,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6055,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 13.02407455444336,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.5969,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.9536077976226807,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.597,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.8391674550615,
            "eval_f1": 87.73188563617218,
            "eval_runtime": 25.0402,
            "eval_samples_per_second": 430.667,
            "eval_steps_per_second": 53.833,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 7.962194919586182,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.2833,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.527750015258789,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.2445,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 23.382104873657227,
            "learning_rate": 8.243523662895777e-06,
            "loss": 0.2365,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 8.658281326293945,
            "learning_rate": 7.239440390923088e-06,
            "loss": 0.235,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 10.702791213989258,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2376,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 11.149714469909668,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2396,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.238435745239258,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.2246,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.361886978149414,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.2256,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 19.6268310546875,
            "learning_rate": 2.2210321976035883e-06,
            "loss": 0.2258,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 28.96780014038086,
            "learning_rate": 1.216948925630899e-06,
            "loss": 0.2177,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 12.529261589050293,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2194,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.240302743614,
            "eval_f1": 87.08203756920751,
            "eval_runtime": 25.5028,
            "eval_samples_per_second": 422.856,
            "eval_steps_per_second": 52.857,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.755191102732563,
            "train_runtime": 1332.1579,
            "train_samples_per_second": 199.355,
            "train_steps_per_second": 12.46
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 78.02270577105014,
      "eval_f1": 86.98528590676376,
      "eval_runtime": 24.6062,
      "eval_samples": 10784,
      "eval_samples_per_second": 438.264,
      "eval_steps_per_second": 54.783,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7552011111707772,
      "train_runtime": 1300.8075,
      "train_samples": 88524,
      "train_samples_per_second": 204.159,
      "train_steps_per_second": 12.761,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.10486602783203,
            "learning_rate": 9e-06,
            "loss": 4.0967,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.640262603759766,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.349523544311523,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3345,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 12.471575736999512,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.2437,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.162906646728516,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1382,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.68718433380127,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0993,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.760516166687012,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1052,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 19.941022872924805,
            "learning_rate": 2.5306914786799653e-05,
            "loss": 1.0435,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.32070255279541,
            "learning_rate": 2.4302831514826963e-05,
            "loss": 0.9982,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 12.179132461547852,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0044,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.444684028625488,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0009,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.6092715231788,
            "eval_f1": 86.79868168398855,
            "eval_runtime": 24.4027,
            "eval_samples_per_second": 441.918,
            "eval_steps_per_second": 55.24,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.699978828430176,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6522,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.828272819519043,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.6185,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 17.043441772460938,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6197,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 12.783785820007324,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6208,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 9.363787651062012,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.6141,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 17.461360931396484,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.6368,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.244279861450195,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.6012,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.394845008850098,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5972,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 16.94060516357422,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.605,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 9.222853660583496,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5964,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.128865718841553,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.6,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.5364238410596,
            "eval_f1": 87.5619040557966,
            "eval_runtime": 24.5695,
            "eval_samples_per_second": 438.918,
            "eval_steps_per_second": 54.865,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.842111587524414,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.285,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 8.063804626464844,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2459,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 19.42530632019043,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2327,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 3.976935386657715,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2341,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 4.521670341491699,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2403,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 12.811868667602539,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2394,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 10.358305931091309,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2251,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 13.466327667236328,
            "learning_rate": 3.229131802664168e-06,
            "loss": 0.2252,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 16.280317306518555,
            "learning_rate": 2.2250485306914787e-06,
            "loss": 0.2256,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 20.883895874023438,
            "learning_rate": 1.2209652587187898e-06,
            "loss": 0.2161,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.657878875732422,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.2192,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.02270577105014,
            "eval_f1": 86.98528590676376,
            "eval_runtime": 25.9249,
            "eval_samples_per_second": 415.97,
            "eval_steps_per_second": 51.996,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7552011111707772,
            "train_runtime": 1300.8075,
            "train_samples_per_second": 204.159,
            "train_steps_per_second": 12.761
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.918637653737,
      "eval_f1": 86.8363562506349,
      "eval_runtime": 25.8694,
      "eval_samples": 10784,
      "eval_samples_per_second": 416.863,
      "eval_steps_per_second": 52.108,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7550147270479793,
      "train_runtime": 1359.7423,
      "train_samples": 88524,
      "train_samples_per_second": 195.311,
      "train_steps_per_second": 12.207,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.66972541809082,
            "learning_rate": 8.981927710843375e-06,
            "loss": 4.0983,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.81743621826172,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.6189,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.115803718566895,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.3364,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 13.879692077636719,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2455,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.771482467651367,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1381,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.059794425964355,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.098,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.290511131286621,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1061,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 17.734445571899414,
            "learning_rate": 2.5306914786799653e-05,
            "loss": 1.0417,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.963909149169922,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.0016,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.237689018249512,
            "learning_rate": 2.3302764575942168e-05,
            "loss": 1.0071,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.843197822570801,
            "learning_rate": 2.2298681303969478e-05,
            "loss": 1.0005,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.67549668874172,
            "eval_f1": 86.97241488039272,
            "eval_runtime": 25.895,
            "eval_samples_per_second": 416.451,
            "eval_steps_per_second": 52.056,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.939389228820801,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.6502,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.159777641296387,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6197,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 15.995902061462402,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6228,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 14.985206604003906,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6191,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 9.184237480163574,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6181,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 13.327241897583008,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.6323,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 23.666954040527344,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.6028,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.977482795715332,
            "learning_rate": 1.4270031461275856e-05,
            "loss": 0.5957,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 13.19940185546875,
            "learning_rate": 1.3265948189303167e-05,
            "loss": 0.6044,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 11.70166301727295,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5951,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.812678813934326,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.5991,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.0473036896878,
            "eval_f1": 87.87438176285038,
            "eval_runtime": 25.9892,
            "eval_samples_per_second": 414.941,
            "eval_steps_per_second": 51.868,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.64556884765625,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.2796,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 9.003299713134766,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.244,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 20.716087341308594,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2376,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 4.397836208343506,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2323,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 20.23186683654785,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.238,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 11.383278846740723,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2387,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.272417068481445,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2242,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 15.572429656982422,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2233,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 15.817455291748047,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2195,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 16.02326774597168,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.2159,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 16.227230072021484,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2225,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.918637653737,
            "eval_f1": 86.8363562506349,
            "eval_runtime": 26.5779,
            "eval_samples_per_second": 405.75,
            "eval_steps_per_second": 50.719,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7550147270479793,
            "train_runtime": 1359.7423,
            "train_samples_per_second": 195.311,
            "train_steps_per_second": 12.207
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.76726584673605,
      "eval_f1": 86.693045517987,
      "eval_runtime": 24.702,
      "eval_samples": 10784,
      "eval_samples_per_second": 436.564,
      "eval_steps_per_second": 54.57,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7549726646042306,
      "train_runtime": 1337.794,
      "train_samples": 88524,
      "train_samples_per_second": 198.515,
      "train_steps_per_second": 12.408,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.970603942871094,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.804731369018555,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.548685073852539,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3346,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 12.149006843566895,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.242,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.61004066467285,
            "learning_rate": 2.8317156436173775e-05,
            "loss": 1.1407,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.760173797607422,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.0995,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.518585205078125,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.105,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 13.215970039367676,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0445,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 8.543512344360352,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.0016,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.02805233001709,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0068,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.242370128631592,
            "learning_rate": 2.2298681303969478e-05,
            "loss": 1.0035,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.97824030274361,
            "eval_f1": 87.2480390223306,
            "eval_runtime": 24.6652,
            "eval_samples_per_second": 437.215,
            "eval_steps_per_second": 54.652,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.090775489807129,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.6514,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.830283164978027,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6167,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 24.21141242980957,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.625,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 14.649197578430176,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6175,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 8.208906173706055,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6162,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 14.17249870300293,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.6345,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 22.535799026489258,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.601,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.365897178649902,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5962,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 15.679882049560547,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6069,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 11.770853996276855,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5962,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 6.854116916656494,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.6005,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.5364238410596,
            "eval_f1": 87.4716378483489,
            "eval_runtime": 24.557,
            "eval_samples_per_second": 439.142,
            "eval_steps_per_second": 54.893,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 12.082313537597656,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.2812,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 7.398705005645752,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2424,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 17.951618194580078,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2309,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.0623602867126465,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2337,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 13.7821626663208,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2354,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 6.402510643005371,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2352,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.14222526550293,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.226,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 15.193177223205566,
            "learning_rate": 3.229131802664168e-06,
            "loss": 0.2298,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 20.498716354370117,
            "learning_rate": 2.2250485306914787e-06,
            "loss": 0.2254,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 17.733659744262695,
            "learning_rate": 1.2209652587187898e-06,
            "loss": 0.2127,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 14.529638290405273,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.2181,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.76726584673605,
            "eval_f1": 86.693045517987,
            "eval_runtime": 25.375,
            "eval_samples_per_second": 424.986,
            "eval_steps_per_second": 53.123,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7549726646042306,
            "train_runtime": 1337.794,
            "train_samples_per_second": 198.515,
            "train_steps_per_second": 12.408
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 78.08893093661305,
      "eval_f1": 86.89207630067783,
      "eval_runtime": 24.8473,
      "eval_samples": 10784,
      "eval_samples_per_second": 434.012,
      "eval_steps_per_second": 54.251,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7541756533708864,
      "train_runtime": 1296.1649,
      "train_samples": 88524,
      "train_samples_per_second": 204.891,
      "train_steps_per_second": 12.806,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.970603942871094,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.803733825683594,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.505633354187012,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.3356,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 12.423308372497559,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.2425,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.55613899230957,
            "learning_rate": 2.8317156436173775e-05,
            "loss": 1.138,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.74266529083252,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.0971,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 16.191757202148438,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.1049,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 12.709637641906738,
            "learning_rate": 2.5306914786799653e-05,
            "loss": 1.0428,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 8.133567810058594,
            "learning_rate": 2.4302831514826963e-05,
            "loss": 1.0018,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.850174903869629,
            "learning_rate": 2.3298748242854276e-05,
            "loss": 1.0057,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.069565296173096,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0008,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.73226111636707,
            "eval_f1": 86.90981907253945,
            "eval_runtime": 24.6013,
            "eval_samples_per_second": 438.351,
            "eval_steps_per_second": 54.794,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.864016532897949,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.6531,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.404624938964844,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.6162,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 26.76197624206543,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6219,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 14.007710456848145,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6154,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 8.173027038574219,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.616,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.277941703796387,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.6305,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 17.77168846130371,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.6015,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 11.871389389038086,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.5929,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 17.71417808532715,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6038,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 12.447854042053223,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.5955,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.6906545162200928,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.5958,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.21759697256385,
            "eval_f1": 87.94435417553066,
            "eval_runtime": 25.5009,
            "eval_samples_per_second": 422.886,
            "eval_steps_per_second": 52.861,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 11.178766250610352,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.2829,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 8.401529312133789,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.2442,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 21.648426055908203,
            "learning_rate": 8.243523662895777e-06,
            "loss": 0.2341,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 4.036607265472412,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2321,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 5.198052406311035,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.2364,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 24.422143936157227,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.2416,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 8.998930931091309,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2232,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.083142280578613,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2232,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.438974380493164,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2236,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 20.87040138244629,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.2144,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 13.05346393585205,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2189,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 78.08893093661305,
            "eval_f1": 86.89207630067783,
            "eval_runtime": 26.8344,
            "eval_samples_per_second": 401.872,
            "eval_steps_per_second": 50.234,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7541756533708864,
            "train_runtime": 1296.1649,
            "train_samples_per_second": 204.891,
            "train_steps_per_second": 12.806
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 77.76726584673605,
      "eval_f1": 86.80214156242586,
      "eval_runtime": 24.9757,
      "eval_samples": 10784,
      "eval_samples_per_second": 431.78,
      "eval_steps_per_second": 53.972,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.7538944467075389,
      "train_runtime": 1306.3091,
      "train_samples": 88524,
      "train_samples_per_second": 203.3,
      "train_steps_per_second": 12.707,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.970603942871094,
            "learning_rate": 9e-06,
            "loss": 4.0966,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 19.81815528869629,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.6163,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 8.269113540649414,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.3354,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.791980743408203,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.2418,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.01339340209961,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.1394,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 13.313071250915527,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.1006,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.890798568725586,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.1024,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 18.51945686340332,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.0448,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.123761177062988,
            "learning_rate": 2.430483968137091e-05,
            "loss": 0.9986,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 8.207571983337402,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0022,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.288400650024414,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0006,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.92147587511826,
            "eval_f1": 87.0960205718487,
            "eval_runtime": 25.1649,
            "eval_samples_per_second": 428.534,
            "eval_steps_per_second": 53.567,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.1054205894470215,
            "learning_rate": 2.1294598031996787e-05,
            "loss": 0.6497,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.958099365234375,
            "learning_rate": 2.0290514760024097e-05,
            "loss": 0.615,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 21.89511489868164,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.6197,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 13.612069129943848,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.6141,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.854471206665039,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.6147,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 13.182584762573242,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.629,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 20.16349220275879,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.5991,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 11.61806583404541,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.594,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 15.341988563537598,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.6034,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 10.485062599182129,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.5945,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.408097267150879,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.5998,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.89593188268685,
            "eval_f1": 87.65097364229696,
            "eval_runtime": 24.8465,
            "eval_samples_per_second": 434.025,
            "eval_steps_per_second": 54.253,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 10.798102378845215,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.2784,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 6.99989128112793,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.2478,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 16.406543731689453,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.2322,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 7.6754150390625,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.2322,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 22.51957130432129,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.2369,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 8.238862037658691,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.2409,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 10.048910140991211,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.2251,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 13.494025230407715,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.2255,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.571819305419922,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.2217,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 16.16901397705078,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.2126,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 13.12663459777832,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.2234,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 77.76726584673605,
            "eval_f1": 86.80214156242586,
            "eval_runtime": 26.0436,
            "eval_samples_per_second": 414.075,
            "eval_steps_per_second": 51.759,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.7538944467075389,
            "train_runtime": 1306.3091,
            "train_samples_per_second": 203.3,
            "train_steps_per_second": 12.707
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    }
  ],
  "none": [
    {
      "eval_exact_match": 81.02175969725639,
      "eval_f1": 88.51622213207543,
      "eval_runtime": 25.7863,
      "eval_samples": 10784,
      "eval_samples_per_second": 418.207,
      "eval_steps_per_second": 52.276,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9596715421876,
      "train_runtime": 1387.5661,
      "train_samples": 88524,
      "train_samples_per_second": 191.394,
      "train_steps_per_second": 11.963,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.913684844970703,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.2089,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.547843933105469,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2007,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.84397315979004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1344,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 14.860240936279297,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1069,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 16.142606735229492,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0929,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.606765747070312,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0844,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.6565752128666,
            "eval_f1": 86.77402994333353,
            "eval_runtime": 26.1949,
            "eval_samples_per_second": 411.683,
            "eval_steps_per_second": 51.46,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.978269577026367,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8266,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.358566761016846,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.799,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.892132759094238,
            "learning_rate": 1.9284423321507463e-05,
            "loss": 0.8204,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 19.609621047973633,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.7994,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.2936577796936035,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.7979,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 26.47273826599121,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.8159,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.076255798339844,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.7842,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 18.7651309967041,
            "learning_rate": 1.4266015128187965e-05,
            "loss": 0.7702,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 25.92477798461914,
            "learning_rate": 1.3261931856215275e-05,
            "loss": 0.7718,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 17.942176818847656,
            "learning_rate": 1.2257848584242588e-05,
            "loss": 0.7773,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 13.524541854858398,
            "learning_rate": 1.1253765312269899e-05,
            "loss": 0.7719,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.12582781456953,
            "eval_f1": 88.48099507263223,
            "eval_runtime": 26.739,
            "eval_samples_per_second": 403.305,
            "eval_steps_per_second": 50.413,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.397797584533691,
            "learning_rate": 1.0249682040297208e-05,
            "loss": 0.5485,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 15.403209686279297,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.5242,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 11.566575050354004,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.5196,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.856220245361328,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.5284,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 14.695585250854492,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.5296,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 10.166080474853516,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.5349,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 6.452503204345703,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.5208,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 10.504493713378906,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.5234,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 19.372154235839844,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.5122,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.368810653686523,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.4859,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.752052307128906,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.489,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 81.02175969725639,
            "eval_f1": 88.51622213207543,
            "eval_runtime": 26.4364,
            "eval_samples_per_second": 407.923,
            "eval_steps_per_second": 50.99,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9596715421876,
            "train_runtime": 1387.5661,
            "train_samples_per_second": 191.394,
            "train_steps_per_second": 11.963
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.96499526963103,
      "eval_f1": 88.55209991644612,
      "eval_runtime": 26.054,
      "eval_samples": 10784,
      "eval_samples_per_second": 413.909,
      "eval_steps_per_second": 51.739,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9577838870816736,
      "train_runtime": 1356.256,
      "train_samples": 88524,
      "train_samples_per_second": 195.813,
      "train_steps_per_second": 12.239,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 32.441795349121094,
            "learning_rate": 9e-06,
            "loss": 4.3796,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 18.445533752441406,
            "learning_rate": 1.8036144578313255e-05,
            "loss": 1.9427,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.111029624938965,
            "learning_rate": 2.7072289156626507e-05,
            "loss": 1.5115,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 14.770208358764648,
            "learning_rate": 2.9321239708146466e-05,
            "loss": 1.3662,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 18.326778411865234,
            "learning_rate": 2.8319164602717718e-05,
            "loss": 1.2584,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 18.934709548950195,
            "learning_rate": 2.731508133074503e-05,
            "loss": 1.2039,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.350980758666992,
            "learning_rate": 2.631099805877234e-05,
            "loss": 1.2005,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.511396408081055,
            "learning_rate": 2.5306914786799653e-05,
            "loss": 1.1336,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 16.29693031311035,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1037,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.019425392150879,
            "learning_rate": 2.330477274248611e-05,
            "loss": 1.0919,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.741995811462402,
            "learning_rate": 2.230068947051342e-05,
            "loss": 1.0849,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.88363292336803,
            "eval_f1": 86.83593425418606,
            "eval_runtime": 25.4359,
            "eval_samples_per_second": 423.967,
            "eval_steps_per_second": 52.996,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.014334201812744,
            "learning_rate": 2.129660619854073e-05,
            "loss": 0.8194,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 8.21361255645752,
            "learning_rate": 2.0292522926568046e-05,
            "loss": 0.7966,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.058611869812012,
            "learning_rate": 1.9288439654595356e-05,
            "loss": 0.8147,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 20.933826446533203,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.805,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 10.085369110107422,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.8005,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 23.56556510925293,
            "learning_rate": 1.6278198005221234e-05,
            "loss": 0.8095,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 17.80902099609375,
            "learning_rate": 1.5274114733248547e-05,
            "loss": 0.7828,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 16.474502563476562,
            "learning_rate": 1.4270031461275856e-05,
            "loss": 0.7729,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.244403839111328,
            "learning_rate": 1.3265948189303167e-05,
            "loss": 0.7738,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 18.523681640625,
            "learning_rate": 1.2261864917330477e-05,
            "loss": 0.7763,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 13.592772483825684,
            "learning_rate": 1.1257781645357788e-05,
            "loss": 0.7745,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.00283822138127,
            "eval_f1": 88.24464796104162,
            "eval_runtime": 25.1248,
            "eval_samples_per_second": 429.217,
            "eval_steps_per_second": 53.652,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.265650749206543,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.547,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 17.113155364990234,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.5225,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 21.173397064208984,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.5118,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.902355670928955,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.5254,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 16.459672927856445,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.5295,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 18.0740909576416,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.5401,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.104714393615723,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.5188,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 10.91691780090332,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.5238,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 18.5976505279541,
            "learning_rate": 2.227056697235424e-06,
            "loss": 0.5094,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 13.921380043029785,
            "learning_rate": 1.222973425262735e-06,
            "loss": 0.4839,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 18.81856918334961,
            "learning_rate": 2.1889015329004618e-07,
            "loss": 0.486,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 80.96499526963103,
            "eval_f1": 88.55209991644612,
            "eval_runtime": 25.7128,
            "eval_samples_per_second": 419.402,
            "eval_steps_per_second": 52.425,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9577838870816736,
            "train_runtime": 1356.256,
            "train_samples_per_second": 195.813,
            "train_steps_per_second": 12.239
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.05014191106906,
      "eval_f1": 88.6235940133063,
      "eval_runtime": 25.6188,
      "eval_samples": 10784,
      "eval_samples_per_second": 420.941,
      "eval_steps_per_second": 52.618,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9597166022217929,
      "train_runtime": 1356.3628,
      "train_samples": 88524,
      "train_samples_per_second": 195.797,
      "train_steps_per_second": 12.238,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.913684844970703,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.2089,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.547843933105469,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2007,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.84397315979004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1344,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 14.860240936279297,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1069,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.578546524047852,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.093,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.84813117980957,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0833,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.7038789025544,
            "eval_f1": 86.81577452996505,
            "eval_runtime": 25.3103,
            "eval_samples_per_second": 426.072,
            "eval_steps_per_second": 53.259,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.887401103973389,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8254,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.370741844177246,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.7988,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.603623390197754,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.8195,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 18.911182403564453,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.7987,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.532482147216797,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.7972,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 22.979312896728516,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.8143,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.801422119140625,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.7861,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.72150421142578,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.7691,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.811017990112305,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.774,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 18.273284912109375,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.7777,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.809036254882812,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.7732,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.02175969725639,
            "eval_f1": 88.3548319274338,
            "eval_runtime": 25.315,
            "eval_samples_per_second": 425.992,
            "eval_steps_per_second": 53.249,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.021299362182617,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.5501,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 17.016569137573242,
            "learning_rate": 9.251623267956356e-06,
            "loss": 0.5225,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 9.649484634399414,
            "learning_rate": 8.247539995983668e-06,
            "loss": 0.5175,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.631414413452148,
            "learning_rate": 7.243456724010978e-06,
            "loss": 0.5289,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 15.645941734313965,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.5303,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 9.622344970703125,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.5368,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.117865562438965,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.5209,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.35116958618164,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.5251,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.966453552246094,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.5119,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.839661598205566,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.4851,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.308107376098633,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.4901,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 81.05014191106906,
            "eval_f1": 88.6235940133063,
            "eval_runtime": 27.2592,
            "eval_samples_per_second": 395.61,
            "eval_steps_per_second": 49.451,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9597166022217929,
            "train_runtime": 1356.3628,
            "train_samples_per_second": 195.797,
            "train_steps_per_second": 12.238
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.15421002838221,
      "eval_f1": 88.68670261750918,
      "eval_runtime": 26.9193,
      "eval_samples": 10784,
      "eval_samples_per_second": 400.605,
      "eval_steps_per_second": 50.076,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9597012804634522,
      "train_runtime": 1404.3914,
      "train_samples": 88524,
      "train_samples_per_second": 189.101,
      "train_steps_per_second": 11.819,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.913684844970703,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.2089,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.547843933105469,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2007,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.84397315979004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1344,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 14.860240936279297,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1069,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.578546524047852,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.093,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.84813117980957,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0833,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.7038789025544,
            "eval_f1": 86.81577452996505,
            "eval_runtime": 26.9081,
            "eval_samples_per_second": 400.771,
            "eval_steps_per_second": 50.096,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.887401103973389,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8254,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.370741844177246,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.7988,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.603623390197754,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.8195,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 18.911182403564453,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.7987,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.532482147216797,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.7972,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 22.979312896728516,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.8143,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.801422119140625,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.7861,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.72150421142578,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.7691,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.811017990112305,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.774,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 18.273284912109375,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.7777,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.809036254882812,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.7732,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.03122043519394,
            "eval_f1": 88.36018302355234,
            "eval_runtime": 26.6868,
            "eval_samples_per_second": 404.094,
            "eval_steps_per_second": 50.512,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 8.933035850524902,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.5502,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 16.44463348388672,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.5227,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 9.987590789794922,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.5177,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.580815315246582,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.5289,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 15.836092948913574,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.5306,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 9.347551345825195,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.5369,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.212416648864746,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.5211,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.190814971923828,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.5247,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.5815486907959,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.5116,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.932326316833496,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.4847,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.134923934936523,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.4895,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 81.15421002838221,
            "eval_f1": 88.68670261750918,
            "eval_runtime": 27.6262,
            "eval_samples_per_second": 390.353,
            "eval_steps_per_second": 48.794,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9597012804634522,
            "train_runtime": 1404.3914,
            "train_samples_per_second": 189.101,
            "train_steps_per_second": 11.819
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.0406811731315,
      "eval_f1": 88.61516945142859,
      "eval_runtime": 25.5064,
      "eval_samples": 10784,
      "eval_samples_per_second": 422.797,
      "eval_steps_per_second": 52.85,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9597151417482028,
      "train_runtime": 1369.3322,
      "train_samples": 88524,
      "train_samples_per_second": 193.943,
      "train_steps_per_second": 12.122,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.913684844970703,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.2089,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.547843933105469,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2007,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.84397315979004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1344,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 14.860240936279297,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1069,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.578546524047852,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.093,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.84813117980957,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0833,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.7038789025544,
            "eval_f1": 86.81577452996505,
            "eval_runtime": 24.6003,
            "eval_samples_per_second": 438.368,
            "eval_steps_per_second": 54.796,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.887401103973389,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8254,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.370741844177246,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.7988,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.603623390197754,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.8195,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 18.911182403564453,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.7987,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.532482147216797,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.7972,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 22.979312896728516,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.8143,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.801422119140625,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.7861,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.72150421142578,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.7691,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.811017990112305,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.774,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 18.273284912109375,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.7777,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.809036254882812,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.7732,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.02175969725639,
            "eval_f1": 88.3548319274338,
            "eval_runtime": 24.6572,
            "eval_samples_per_second": 437.357,
            "eval_steps_per_second": 54.67,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.021299362182617,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.5501,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 17.016569137573242,
            "learning_rate": 9.251623267956356e-06,
            "loss": 0.5225,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 9.649484634399414,
            "learning_rate": 8.247539995983668e-06,
            "loss": 0.5175,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.631414413452148,
            "learning_rate": 7.243456724010978e-06,
            "loss": 0.5289,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 15.645941734313965,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.5303,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 9.615787506103516,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.5368,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.123577117919922,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.5209,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.339407920837402,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.5251,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.954225540161133,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.5119,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.76912784576416,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.4851,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.288976669311523,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.49,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 81.0406811731315,
            "eval_f1": 88.61516945142859,
            "eval_runtime": 25.5808,
            "eval_samples_per_second": 421.566,
            "eval_steps_per_second": 52.696,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9597151417482028,
            "train_runtime": 1369.3322,
            "train_samples_per_second": 193.943,
            "train_steps_per_second": 12.122
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.0879848628193,
      "eval_f1": 88.64250052916499,
      "eval_runtime": 24.823,
      "eval_samples": 10784,
      "eval_samples_per_second": 434.435,
      "eval_steps_per_second": 54.304,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.959665224116799,
      "train_runtime": 1342.0266,
      "train_samples": 88524,
      "train_samples_per_second": 197.889,
      "train_steps_per_second": 12.369,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.913684844970703,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.2089,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.547843933105469,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2007,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.84397315979004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1344,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 14.860240936279297,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1069,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.578546524047852,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.093,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.84813117980957,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0833,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.7038789025544,
            "eval_f1": 86.81577452996505,
            "eval_runtime": 24.8799,
            "eval_samples_per_second": 433.443,
            "eval_steps_per_second": 54.18,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.887401103973389,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8254,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.370741844177246,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.7988,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.603623390197754,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.8195,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 18.911182403564453,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.7987,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.532482147216797,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.7972,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 22.979312896728516,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.8143,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.801422119140625,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.7861,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.894954681396484,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.7692,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.86054801940918,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.7742,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 17.8725528717041,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.7769,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.686985969543457,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.773,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.06906338694418,
            "eval_f1": 88.3753425661659,
            "eval_runtime": 24.8902,
            "eval_samples_per_second": 433.263,
            "eval_steps_per_second": 54.158,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 8.867936134338379,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.5501,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 16.422433853149414,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.5231,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 9.548101425170898,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.518,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.417427062988281,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.5292,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 15.255314826965332,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.5305,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 10.913847923278809,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.5358,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 6.974823951721191,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.5213,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.514256477355957,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.5246,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 18.79218101501465,
            "learning_rate": 2.2210321976035883e-06,
            "loss": 0.511,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.937544822692871,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.485,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 16.680654525756836,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.4898,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 81.0879848628193,
            "eval_f1": 88.64250052916499,
            "eval_runtime": 25.8799,
            "eval_samples_per_second": 416.694,
            "eval_steps_per_second": 52.087,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.959665224116799,
            "train_runtime": 1342.0266,
            "train_samples_per_second": 197.889,
            "train_steps_per_second": 12.369
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.0406811731315,
      "eval_f1": 88.61886364433752,
      "eval_runtime": 25.8827,
      "eval_samples": 10784,
      "eval_samples_per_second": 416.649,
      "eval_steps_per_second": 52.081,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9597167056384909,
      "train_runtime": 1383.7865,
      "train_samples": 88524,
      "train_samples_per_second": 191.917,
      "train_steps_per_second": 11.995,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.913684844970703,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.2089,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.547843933105469,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2007,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.84397315979004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1344,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 14.860240936279297,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1069,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.578546524047852,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.093,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.84813117980957,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0833,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.7038789025544,
            "eval_f1": 86.81577452996505,
            "eval_runtime": 25.7302,
            "eval_samples_per_second": 419.119,
            "eval_steps_per_second": 52.39,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.887401103973389,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8254,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.370741844177246,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.7988,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.603623390197754,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.8195,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 18.911182403564453,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.7987,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.532482147216797,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.7972,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 22.979312896728516,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.8143,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.801422119140625,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.7861,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.72150421142578,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.7691,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.811017990112305,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.774,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 18.273284912109375,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.7777,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.809036254882812,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.7732,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.02175969725639,
            "eval_f1": 88.3548319274338,
            "eval_runtime": 25.9638,
            "eval_samples_per_second": 415.348,
            "eval_steps_per_second": 51.919,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.021299362182617,
            "learning_rate": 1.02536983733851e-05,
            "loss": 0.5501,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 17.016569137573242,
            "learning_rate": 9.251623267956356e-06,
            "loss": 0.5225,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 9.649484634399414,
            "learning_rate": 8.247539995983668e-06,
            "loss": 0.5175,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.631414413452148,
            "learning_rate": 7.243456724010978e-06,
            "loss": 0.5289,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 15.645941734313965,
            "learning_rate": 6.239373452038289e-06,
            "loss": 0.5303,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 9.622344970703125,
            "learning_rate": 5.2352901800656e-06,
            "loss": 0.5368,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.117865562438965,
            "learning_rate": 4.231206908092911e-06,
            "loss": 0.5209,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.35116958618164,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.5251,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 17.966453552246094,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.5119,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.820036888122559,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.4851,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.3032169342041,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.49,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 81.0406811731315,
            "eval_f1": 88.61886364433752,
            "eval_runtime": 26.2403,
            "eval_samples_per_second": 410.97,
            "eval_steps_per_second": 51.371,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9597167056384909,
            "train_runtime": 1383.7865,
            "train_samples_per_second": 191.917,
            "train_steps_per_second": 11.995
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.10690633869442,
      "eval_f1": 88.64058901798454,
      "eval_runtime": 26.8248,
      "eval_samples": 10784,
      "eval_samples_per_second": 402.016,
      "eval_steps_per_second": 50.252,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9597092869842087,
      "train_runtime": 1383.7558,
      "train_samples": 88524,
      "train_samples_per_second": 191.921,
      "train_steps_per_second": 11.996,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.913684844970703,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.2089,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.547843933105469,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2007,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.84397315979004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1344,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 14.860240936279297,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1069,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.578546524047852,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.093,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.84813117980957,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0833,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.7038789025544,
            "eval_f1": 86.81577452996505,
            "eval_runtime": 26.1408,
            "eval_samples_per_second": 412.536,
            "eval_steps_per_second": 51.567,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.887401103973389,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8254,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.370741844177246,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.7988,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.603623390197754,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.8195,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 18.911182403564453,
            "learning_rate": 1.8284356382622665e-05,
            "loss": 0.7987,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.532482147216797,
            "learning_rate": 1.7280273110649978e-05,
            "loss": 0.7972,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 22.979312896728516,
            "learning_rate": 1.6276189838677287e-05,
            "loss": 0.8143,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.801422119140625,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.7861,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.72150421142578,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.7691,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.812559127807617,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.774,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 18.264741897583008,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.7777,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.748310089111328,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.7733,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.0406811731315,
            "eval_f1": 88.37798253636153,
            "eval_runtime": 26.0605,
            "eval_samples_per_second": 413.807,
            "eval_steps_per_second": 51.726,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 8.929082870483398,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.5499,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 16.501081466674805,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.5229,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 9.778219223022461,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.5177,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.481655120849609,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.5287,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 15.655770301818848,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.531,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 10.640231132507324,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.5362,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 6.879837512969971,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.5211,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 12.233328819274902,
            "learning_rate": 3.2271236361202225e-06,
            "loss": 0.525,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 18.347782135009766,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.512,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.672799110412598,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.4848,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.404016494750977,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.4897,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 81.10690633869442,
            "eval_f1": 88.64058901798454,
            "eval_runtime": 27.32,
            "eval_samples_per_second": 394.729,
            "eval_steps_per_second": 49.341,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9597092869842087,
            "train_runtime": 1383.7558,
            "train_samples_per_second": 191.921,
            "train_steps_per_second": 11.996
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.89877010406812,
      "eval_f1": 88.48359505111648,
      "eval_runtime": 25.003,
      "eval_samples": 10784,
      "eval_samples_per_second": 431.309,
      "eval_steps_per_second": 53.914,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9593989718526995,
      "train_runtime": 1380.0643,
      "train_samples": 88524,
      "train_samples_per_second": 192.435,
      "train_steps_per_second": 12.028,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.913684844970703,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.2089,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.547843933105469,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2007,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.84397315979004,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1344,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 13.325318336486816,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1067,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.372035026550293,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0944,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.84225845336914,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0838,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.78902554399244,
            "eval_f1": 86.80975277033751,
            "eval_runtime": 24.7427,
            "eval_samples_per_second": 435.846,
            "eval_steps_per_second": 54.481,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.113189220428467,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8273,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.179316520690918,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.8003,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 15.129199028015137,
            "learning_rate": 1.928643148805141e-05,
            "loss": 0.8184,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 19.9072208404541,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.8001,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 8.200834274291992,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.7985,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 28.605655670166016,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.8147,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.17641258239746,
            "learning_rate": 1.5272106566704597e-05,
            "loss": 0.7833,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.215621948242188,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.7704,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.579753875732422,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.7752,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 17.048856735229492,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.7769,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.607348442077637,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.7703,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.91769157994324,
            "eval_f1": 88.2886216085368,
            "eval_runtime": 24.3501,
            "eval_samples_per_second": 442.872,
            "eval_steps_per_second": 55.359,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.50861644744873,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.5501,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 17.406999588012695,
            "learning_rate": 9.247606934868466e-06,
            "loss": 0.5219,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 10.62896728515625,
            "learning_rate": 8.243523662895777e-06,
            "loss": 0.5182,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 6.208484172821045,
            "learning_rate": 7.239440390923088e-06,
            "loss": 0.5285,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 15.224264144897461,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.5276,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 9.519306182861328,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.5358,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.030191421508789,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.5195,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 11.243378639221191,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.5223,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 18.523256301879883,
            "learning_rate": 2.2230403641475333e-06,
            "loss": 0.51,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.671846389770508,
            "learning_rate": 1.2189570921748444e-06,
            "loss": 0.4841,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 17.523883819580078,
            "learning_rate": 2.1688198674610082e-07,
            "loss": 0.4876,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 80.89877010406812,
            "eval_f1": 88.48359505111648,
            "eval_runtime": 24.7461,
            "eval_samples_per_second": 435.786,
            "eval_steps_per_second": 54.473,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9593989718526995,
            "train_runtime": 1380.0643,
            "train_samples_per_second": 192.435,
            "train_steps_per_second": 12.028
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.75685903500474,
      "eval_f1": 88.38657091064077,
      "eval_runtime": 25.1315,
      "eval_samples": 10784,
      "eval_samples_per_second": 429.102,
      "eval_steps_per_second": 53.638,
      "total_flos": 5.204482670991974e+16,
      "train_loss": 0.9595406642196566,
      "train_runtime": 1326.3412,
      "train_samples": 88524,
      "train_samples_per_second": 200.229,
      "train_steps_per_second": 12.515,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 3.0,
        "eval_steps": 500,
        "global_step": 16599,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 33.491729736328125,
            "learning_rate": 9e-06,
            "loss": 4.3773,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.824382781982422,
            "learning_rate": 1.8018072289156627e-05,
            "loss": 1.9425,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.194063186645508,
            "learning_rate": 2.705421686746988e-05,
            "loss": 1.5206,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 17.026514053344727,
            "learning_rate": 2.932324787469041e-05,
            "loss": 1.3777,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 19.91390037536621,
            "learning_rate": 2.8321172769261668e-05,
            "loss": 1.2659,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 18.036828994750977,
            "learning_rate": 2.7317089497288977e-05,
            "loss": 1.209,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.575067520141602,
            "learning_rate": 2.6313006225316287e-05,
            "loss": 1.2012,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.513761520385742,
            "learning_rate": 2.53089229533436e-05,
            "loss": 1.1355,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 11.786233901977539,
            "learning_rate": 2.430483968137091e-05,
            "loss": 1.1074,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 14.188621520996094,
            "learning_rate": 2.330075640939822e-05,
            "loss": 1.0966,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.134888648986816,
            "learning_rate": 2.2296673137425528e-05,
            "loss": 1.0853,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 78.87417218543047,
            "eval_f1": 86.91850127052433,
            "eval_runtime": 24.4613,
            "eval_samples_per_second": 440.859,
            "eval_steps_per_second": 55.107,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.805070400238037,
            "learning_rate": 2.1292589865452844e-05,
            "loss": 0.8267,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.400326251983643,
            "learning_rate": 2.0288506593480154e-05,
            "loss": 0.7987,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 13.929049491882324,
            "learning_rate": 1.9284423321507463e-05,
            "loss": 0.8179,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 20.668962478637695,
            "learning_rate": 1.828234821607872e-05,
            "loss": 0.7975,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.766941547393799,
            "learning_rate": 1.7278264944106032e-05,
            "loss": 0.802,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 23.862707138061523,
            "learning_rate": 1.6274181672133345e-05,
            "loss": 0.8139,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.721683502197266,
            "learning_rate": 1.5270098400160654e-05,
            "loss": 0.7829,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.276391983032227,
            "learning_rate": 1.426802329473191e-05,
            "loss": 0.7711,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.768165588378906,
            "learning_rate": 1.3263940022759221e-05,
            "loss": 0.7764,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 18.530466079711914,
            "learning_rate": 1.2259856750786532e-05,
            "loss": 0.7732,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.45876407623291,
            "learning_rate": 1.1255773478813843e-05,
            "loss": 0.7734,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.91769157994324,
            "eval_f1": 88.23418189382869,
            "eval_runtime": 24.6521,
            "eval_samples_per_second": 437.447,
            "eval_steps_per_second": 54.681,
            "step": 11066
          },
          {
            "epoch": 2.0784384601482015,
            "grad_norm": 9.601163864135742,
            "learning_rate": 1.0251690206841154e-05,
            "loss": 0.5479,
            "step": 11500
          },
          {
            "epoch": 2.1688053497198627,
            "grad_norm": 17.976879119873047,
            "learning_rate": 9.24961510141241e-06,
            "loss": 0.5218,
            "step": 12000
          },
          {
            "epoch": 2.2591722392915234,
            "grad_norm": 10.847336769104004,
            "learning_rate": 8.245531829439721e-06,
            "loss": 0.5192,
            "step": 12500
          },
          {
            "epoch": 2.3495391288631846,
            "grad_norm": 5.941437244415283,
            "learning_rate": 7.2414485574670325e-06,
            "loss": 0.5274,
            "step": 13000
          },
          {
            "epoch": 2.4399060184348453,
            "grad_norm": 14.057985305786133,
            "learning_rate": 6.237365285494344e-06,
            "loss": 0.5268,
            "step": 13500
          },
          {
            "epoch": 2.5302729080065065,
            "grad_norm": 13.573505401611328,
            "learning_rate": 5.233282013521656e-06,
            "loss": 0.5346,
            "step": 14000
          },
          {
            "epoch": 2.6206397975781672,
            "grad_norm": 7.1927313804626465,
            "learning_rate": 4.229198741548966e-06,
            "loss": 0.5178,
            "step": 14500
          },
          {
            "epoch": 2.7110066871498284,
            "grad_norm": 11.831391334533691,
            "learning_rate": 3.2251154695762767e-06,
            "loss": 0.5238,
            "step": 15000
          },
          {
            "epoch": 2.801373576721489,
            "grad_norm": 21.916099548339844,
            "learning_rate": 2.2210321976035883e-06,
            "loss": 0.5121,
            "step": 15500
          },
          {
            "epoch": 2.8917404662931503,
            "grad_norm": 9.942416191101074,
            "learning_rate": 1.216948925630899e-06,
            "loss": 0.4876,
            "step": 16000
          },
          {
            "epoch": 2.982107355864811,
            "grad_norm": 18.41409683227539,
            "learning_rate": 2.1487382020215546e-07,
            "loss": 0.4873,
            "step": 16500
          },
          {
            "epoch": 3.0,
            "eval_exact_match": 80.75685903500474,
            "eval_f1": 88.38657091064077,
            "eval_runtime": 25.5451,
            "eval_samples_per_second": 422.156,
            "eval_steps_per_second": 52.769,
            "step": 16599
          },
          {
            "epoch": 3.0,
            "step": 16599,
            "total_flos": 5.204482670991974e+16,
            "train_loss": 0.9595406642196566,
            "train_runtime": 1326.3412,
            "train_samples_per_second": 200.229,
            "train_steps_per_second": 12.515
          }
        ],
        "logging_steps": 500,
        "max_steps": 16599,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 3,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 5.204482670991974e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    }
  ]
}