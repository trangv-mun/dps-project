{
  "dense": [
    {
      "eval_exact_match": 80.31220435193946,
      "eval_f1": 88.19995295239055,
      "eval_runtime": 34.8229,
      "eval_samples": 10784,
      "eval_samples_per_second": 309.681,
      "eval_steps_per_second": 38.71,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9566274060708326,
      "train_runtime": 2145.4513,
      "train_samples": 88524,
      "train_samples_per_second": 82.522,
      "train_steps_per_second": 5.158,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.00047492980957,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7349,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.84634780883789,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4917,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 7.15578031539917,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2977,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.797237396240234,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1967,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.48946762084961,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1055,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.491536140441895,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0731,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.437315940856934,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0799,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.466428756713867,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0167,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.444414138793945,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9795,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.91411828994751,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9813,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.231544017791748,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.977,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.96215704824976,
            "eval_f1": 87.74747926613026,
            "eval_runtime": 34.7022,
            "eval_samples_per_second": 310.758,
            "eval_steps_per_second": 38.845,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.102810859680176,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.6146,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.7689924240112305,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5696,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 10.987424850463867,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5819,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 13.927759170532227,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5742,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.375072002410889,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5682,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 12.01220989227295,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.5723,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 17.18401336669922,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5374,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 8.776703834533691,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.5405,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.36866569519043,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5396,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 13.31126880645752,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.535,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.130706787109375,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.5376,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.31220435193946,
            "eval_f1": 88.19995295239055,
            "eval_runtime": 35.0168,
            "eval_samples_per_second": 307.966,
            "eval_steps_per_second": 38.496,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9566274060708326,
            "train_runtime": 2145.4513,
            "train_samples_per_second": 82.522,
            "train_steps_per_second": 5.158
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.07568590350047,
      "eval_f1": 88.02894450601798,
      "eval_runtime": 25.4674,
      "eval_samples": 10784,
      "eval_samples_per_second": 423.444,
      "eval_steps_per_second": 52.931,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9571399940368002,
      "train_runtime": 885.9568,
      "train_samples": 88524,
      "train_samples_per_second": 199.838,
      "train_steps_per_second": 12.49,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.93972396850586,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7334,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.131561279296875,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4895,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 7.132856369018555,
            "learning_rate": 2.882217090069284e-05,
            "loss": 1.2961,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.566662788391113,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1986,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 15.730301856994629,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1081,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.135528564453125,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.073,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.749757766723633,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0794,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 18.576007843017578,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0163,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 11.812603950500488,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9784,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 19.338407516479492,
            "learning_rate": 1.8281956019680694e-05,
            "loss": 0.9862,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.929222106933594,
            "learning_rate": 1.6775780700873582e-05,
            "loss": 0.9805,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.59318826868495,
            "eval_f1": 87.42040456583602,
            "eval_runtime": 25.2826,
            "eval_samples_per_second": 426.538,
            "eval_steps_per_second": 53.317,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.848379611968994,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6128,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.954238414764404,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5706,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 12.301126480102539,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5822,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 16.09889793395996,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5742,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.113504886627197,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.566,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.84628677368164,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.5682,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.574731826782227,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5381,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.720961570739746,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5425,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 32.56793975830078,
            "learning_rate": 3.226227532884828e-06,
            "loss": 0.548,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 15.882164001464844,
            "learning_rate": 1.7200522140777186e-06,
            "loss": 0.533,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 5.444374084472656,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.5409,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.07568590350047,
            "eval_f1": 88.02894450601798,
            "eval_runtime": 25.7324,
            "eval_samples_per_second": 419.082,
            "eval_steps_per_second": 52.385,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9571399940368002,
            "train_runtime": 885.9568,
            "train_samples_per_second": 199.838,
            "train_steps_per_second": 12.49
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.00946073793756,
      "eval_f1": 88.08812645998479,
      "eval_runtime": 26.0357,
      "eval_samples": 10784,
      "eval_samples_per_second": 414.201,
      "eval_steps_per_second": 51.775,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9568743389466777,
      "train_runtime": 879.8259,
      "train_samples": 88524,
      "train_samples_per_second": 201.231,
      "train_steps_per_second": 12.577,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.019182205200195,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7344,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.34379005432129,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4891,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.8313374519348145,
            "learning_rate": 2.882217090069284e-05,
            "loss": 1.298,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.121960639953613,
            "learning_rate": 2.7315995581885733e-05,
            "loss": 1.1987,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.37164306640625,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1086,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.572044372558594,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.0718,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.820137977600098,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.0785,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 17.309167861938477,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.0161,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.427499771118164,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9762,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 8.151468276977539,
            "learning_rate": 1.828798072095592e-05,
            "loss": 0.9849,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.531716823577881,
            "learning_rate": 1.6784817752786422e-05,
            "loss": 0.9793,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.64995269631031,
            "eval_f1": 87.38513791608084,
            "eval_runtime": 25.0104,
            "eval_samples_per_second": 431.18,
            "eval_steps_per_second": 53.897,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.39408016204834,
            "learning_rate": 1.5278642433979314e-05,
            "loss": 0.6147,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.769857883453369,
            "learning_rate": 1.3772467115172207e-05,
            "loss": 0.5711,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 12.913421630859375,
            "learning_rate": 1.2266291796365097e-05,
            "loss": 0.5831,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.684967041015625,
            "learning_rate": 1.0760116477557988e-05,
            "loss": 0.5669,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.691373348236084,
            "learning_rate": 9.25394115875088e-06,
            "loss": 0.5645,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.551658630371094,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.5736,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.00420379638672,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5381,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.62395191192627,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.5406,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.385805130004883,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5445,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 16.281112670898438,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5365,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.955726623535156,
            "learning_rate": 2.2291394718345217e-07,
            "loss": 0.5414,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.00946073793756,
            "eval_f1": 88.08812645998479,
            "eval_runtime": 27.2758,
            "eval_samples_per_second": 395.368,
            "eval_steps_per_second": 49.421,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9568743389466777,
            "train_runtime": 879.8259,
            "train_samples_per_second": 201.231,
            "train_steps_per_second": 12.577
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.00946073793756,
      "eval_f1": 88.02920372949214,
      "eval_runtime": 26.0552,
      "eval_samples": 10784,
      "eval_samples_per_second": 413.891,
      "eval_steps_per_second": 51.736,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9563747676957608,
      "train_runtime": 884.4914,
      "train_samples": 88524,
      "train_samples_per_second": 200.169,
      "train_steps_per_second": 12.511,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.365158081054688,
            "learning_rate": 1.3468834688346885e-05,
            "loss": 3.7346,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 15.797548294067383,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4906,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.628347396850586,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2982,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 12.079680442810059,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1969,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 14.880218505859375,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1092,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.16753387451172,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.0752,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.888373374938965,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.0765,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 18.559965133666992,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.0173,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 11.242321968078613,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9782,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.95669412612915,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9856,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.270699977874756,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9794,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.76348155156103,
            "eval_f1": 87.45525431148144,
            "eval_runtime": 25.3067,
            "eval_samples_per_second": 426.132,
            "eval_steps_per_second": 53.266,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.584343910217285,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.611,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.469682216644287,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5718,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 18.985132217407227,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.5797,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.938027381896973,
            "learning_rate": 1.075409177628276e-05,
            "loss": 0.5688,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.781521797180176,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5637,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 11.068357467651367,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.566,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 20.13046646118164,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5404,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 8.946358680725098,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5397,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 27.406768798828125,
            "learning_rate": 3.226227532884828e-06,
            "loss": 0.5474,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 12.687005043029785,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.531,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.115363597869873,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5396,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.00946073793756,
            "eval_f1": 88.02920372949214,
            "eval_runtime": 26.5969,
            "eval_samples_per_second": 405.461,
            "eval_steps_per_second": 50.683,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9563747676957608,
            "train_runtime": 884.4914,
            "train_samples_per_second": 200.169,
            "train_steps_per_second": 12.511
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.05676442762535,
      "eval_f1": 88.0062529467266,
      "eval_runtime": 25.5447,
      "eval_samples": 10784,
      "eval_samples_per_second": 422.161,
      "eval_steps_per_second": 52.77,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9564204247890233,
      "train_runtime": 879.659,
      "train_samples": 88524,
      "train_samples_per_second": 201.269,
      "train_steps_per_second": 12.58,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.373605728149414,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7294,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.18465232849121,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4918,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 7.261703014373779,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2966,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.096860885620117,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1941,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 15.567449569702148,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1064,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.564868927001953,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0723,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.308813095092773,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0807,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.946903228759766,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.0149,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.522096633911133,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9785,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 9.908477783203125,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9832,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.919694900512695,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9794,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.5364238410596,
            "eval_f1": 87.3951595794355,
            "eval_runtime": 25.265,
            "eval_samples_per_second": 426.835,
            "eval_steps_per_second": 53.354,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.036013126373291,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6104,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.580792427062988,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5743,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 10.253121376037598,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.5846,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.784974098205566,
            "learning_rate": 1.075409177628276e-05,
            "loss": 0.571,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.575484275817871,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5652,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 12.708659172058105,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.5694,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 17.70203399658203,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5409,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.024473190307617,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5434,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 25.5428466796875,
            "learning_rate": 3.226227532884828e-06,
            "loss": 0.543,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 15.75662899017334,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.5352,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.593461036682129,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.5351,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.05676442762535,
            "eval_f1": 88.0062529467266,
            "eval_runtime": 26.0393,
            "eval_samples_per_second": 414.142,
            "eval_steps_per_second": 51.768,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9564204247890233,
            "train_runtime": 879.659,
            "train_samples_per_second": 201.269,
            "train_steps_per_second": 12.58
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.19867549668874,
      "eval_f1": 88.10836465268609,
      "eval_runtime": 25.3224,
      "eval_samples": 10784,
      "eval_samples_per_second": 425.868,
      "eval_steps_per_second": 53.233,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9580053804839862,
      "train_runtime": 880.4981,
      "train_samples": 88524,
      "train_samples_per_second": 201.077,
      "train_steps_per_second": 12.568,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.431377410888672,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7349,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.80915069580078,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4913,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 7.409008979797363,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2982,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.175371170043945,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1994,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.765289306640625,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1064,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 15.397324562072754,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0741,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 15.789437294006348,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0805,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.914952278137207,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0202,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 12.698362350463867,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9803,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 8.784414291381836,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9845,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.274438858032227,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9804,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.71617786187322,
            "eval_f1": 87.47835736831846,
            "eval_runtime": 24.8381,
            "eval_samples_per_second": 434.172,
            "eval_steps_per_second": 54.271,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.892698287963867,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6143,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.172560691833496,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5715,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 15.040839195251465,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5845,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.511882781982422,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.571,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.422669887542725,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5664,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.091192245483398,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.5742,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.396240234375,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5409,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.853045463562012,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.5407,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 20.95521354675293,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5474,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 17.838436126708984,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5357,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 6.427236557006836,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5394,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.19867549668874,
            "eval_f1": 88.10836465268609,
            "eval_runtime": 25.4409,
            "eval_samples_per_second": 423.884,
            "eval_steps_per_second": 52.985,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9580053804839862,
            "train_runtime": 880.4981,
            "train_samples_per_second": 201.077,
            "train_steps_per_second": 12.568
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.1608325449385,
      "eval_f1": 88.09206226583802,
      "eval_runtime": 25.7431,
      "eval_samples": 10784,
      "eval_samples_per_second": 418.908,
      "eval_steps_per_second": 52.364,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9556654494558087,
      "train_runtime": 873.0,
      "train_samples": 88524,
      "train_samples_per_second": 202.804,
      "train_steps_per_second": 12.676,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.93972396850586,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7334,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.23664665222168,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4912,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 7.570643901824951,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2987,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.062553405761719,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1984,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.767227172851562,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1093,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 15.450104713439941,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.0708,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.405937194824219,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.0774,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 17.448928833007812,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.0151,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.303043365478516,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9744,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.416565895080566,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9819,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.504431247711182,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.978,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.6972563859981,
            "eval_f1": 87.5760721052011,
            "eval_runtime": 24.664,
            "eval_samples_per_second": 437.237,
            "eval_steps_per_second": 54.655,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.857215881347656,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6094,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.77539587020874,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5684,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 15.092616081237793,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5782,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.857115745544434,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5666,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.695882797241211,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5614,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 11.193315505981445,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.5692,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.860065460205078,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.538,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.188486099243164,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.5384,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.857267379760742,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5479,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 14.117161750793457,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5387,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.9865734577178955,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5386,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.1608325449385,
            "eval_f1": 88.09206226583802,
            "eval_runtime": 27.4351,
            "eval_samples_per_second": 393.073,
            "eval_steps_per_second": 49.134,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9556654494558087,
            "train_runtime": 873.0,
            "train_samples_per_second": 202.804,
            "train_steps_per_second": 12.676
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.07568590350047,
      "eval_f1": 88.10571387713213,
      "eval_runtime": 25.022,
      "eval_samples": 10784,
      "eval_samples_per_second": 430.982,
      "eval_steps_per_second": 53.873,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9569284955136237,
      "train_runtime": 870.0974,
      "train_samples": 88524,
      "train_samples_per_second": 203.481,
      "train_steps_per_second": 12.718,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.054401397705078,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7285,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 15.30129337310791,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4879,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 7.055049419403076,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2966,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.521141052246094,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1982,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 15.949164390563965,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.109,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.560955047607422,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0735,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.978836059570312,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0774,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 13.715633392333984,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.018,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.745270729064941,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9789,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.98109245300293,
            "learning_rate": 1.8281956019680694e-05,
            "loss": 0.986,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.5977277755737305,
            "learning_rate": 1.6775780700873582e-05,
            "loss": 0.9808,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.76348155156103,
            "eval_f1": 87.59801150600899,
            "eval_runtime": 24.6296,
            "eval_samples_per_second": 437.847,
            "eval_steps_per_second": 54.731,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.292909145355225,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6113,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.130431175231934,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5707,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 17.095035552978516,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.5809,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 16.522483825683594,
            "learning_rate": 1.075409177628276e-05,
            "loss": 0.5707,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.866661071777344,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5678,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 13.429765701293945,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.5731,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 20.143259048461914,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5417,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.157999038696289,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5408,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 25.13437271118164,
            "learning_rate": 3.226227532884828e-06,
            "loss": 0.5488,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 12.31423568725586,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.5343,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.993205547332764,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.5377,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.07568590350047,
            "eval_f1": 88.10571387713213,
            "eval_runtime": 26.2215,
            "eval_samples_per_second": 411.266,
            "eval_steps_per_second": 51.408,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9569284955136237,
            "train_runtime": 870.0974,
            "train_samples_per_second": 203.481,
            "train_steps_per_second": 12.718
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.15137180700094,
      "eval_f1": 88.10422588035105,
      "eval_runtime": 26.2176,
      "eval_samples": 10784,
      "eval_samples_per_second": 411.327,
      "eval_steps_per_second": 51.416,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9566245321207961,
      "train_runtime": 902.7848,
      "train_samples": 88524,
      "train_samples_per_second": 196.113,
      "train_steps_per_second": 12.258,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.94374656677246,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7335,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.963781356811523,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4897,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.765415668487549,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2978,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.987167358398438,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1983,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.804656982421875,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1086,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.779541015625,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0762,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.689428329467773,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0782,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.740022659301758,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0172,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.143536567687988,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9768,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.824792861938477,
            "learning_rate": 1.8281956019680694e-05,
            "loss": 0.9838,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.697266578674316,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9811,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.91485335856197,
            "eval_f1": 87.6111100920613,
            "eval_runtime": 25.3447,
            "eval_samples_per_second": 425.493,
            "eval_steps_per_second": 53.187,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.797802925109863,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6119,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.554336071014404,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5718,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.41146469116211,
            "learning_rate": 1.2266291796365097e-05,
            "loss": 0.5811,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.642046928405762,
            "learning_rate": 1.0760116477557988e-05,
            "loss": 0.5693,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.431126117706299,
            "learning_rate": 9.25394115875088e-06,
            "loss": 0.5663,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 18.911258697509766,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.5711,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.342239379882812,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5381,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.61705207824707,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.5408,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 19.215164184570312,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5415,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 12.836638450622559,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5345,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 8.72577953338623,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5377,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.15137180700094,
            "eval_f1": 88.10422588035105,
            "eval_runtime": 26.2865,
            "eval_samples_per_second": 410.248,
            "eval_steps_per_second": 51.281,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9566245321207961,
            "train_runtime": 902.7848,
            "train_samples_per_second": 196.113,
            "train_steps_per_second": 12.258
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 79.8391674550615,
      "eval_f1": 87.88737307701216,
      "eval_runtime": 25.347,
      "eval_samples": 10784,
      "eval_samples_per_second": 425.455,
      "eval_steps_per_second": 53.182,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9577880268520932,
      "train_runtime": 878.8948,
      "train_samples": 88524,
      "train_samples_per_second": 201.444,
      "train_steps_per_second": 12.591,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.94374656677246,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7335,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.963781356811523,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4897,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.765415668487549,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2978,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.987167358398438,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1983,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.804656982421875,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1086,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.779541015625,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0762,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 11.689428329467773,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0782,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.740022659301758,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0172,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 10.143536567687988,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9768,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.824792861938477,
            "learning_rate": 1.8281956019680694e-05,
            "loss": 0.9838,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.697266578674316,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9811,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.91485335856197,
            "eval_f1": 87.6111100920613,
            "eval_runtime": 25.3447,
            "eval_samples_per_second": 425.493,
            "eval_steps_per_second": 53.187,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.797802925109863,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6119,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.554336071014404,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5718,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 14.41146469116211,
            "learning_rate": 1.2266291796365097e-05,
            "loss": 0.5811,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.642046928405762,
            "learning_rate": 1.0760116477557988e-05,
            "loss": 0.5693,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.431126117706299,
            "learning_rate": 9.25394115875088e-06,
            "loss": 0.5663,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 18.911258697509766,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.5711,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 18.342239379882812,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5381,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.61705207824707,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.5408,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 19.215164184570312,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5415,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 12.836638450622559,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5345,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 8.72577953338623,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5377,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.15137180700094,
            "eval_f1": 88.10422588035105,
            "eval_runtime": 26.2865,
            "eval_samples_per_second": 410.248,
            "eval_steps_per_second": 51.281,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9566245321207961,
            "train_runtime": 902.7848,
            "train_samples_per_second": 196.113,
            "train_steps_per_second": 12.258
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    }
  ],
  "mix": [
    {
      "eval_exact_match": 80.02838221381268,
      "eval_f1": 88.1171359814419,
      "eval_runtime": 35.459,
      "eval_samples": 10784,
      "eval_samples_per_second": 304.126,
      "eval_steps_per_second": 38.016,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9573563565920042,
      "train_runtime": 2167.0889,
      "train_samples": 88524,
      "train_samples_per_second": 81.699,
      "train_steps_per_second": 5.106,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.42000961303711,
            "learning_rate": 1.3468834688346885e-05,
            "loss": 3.735,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.698516845703125,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4908,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.678889274597168,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2981,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.84217643737793,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1982,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.358623504638672,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1058,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.82726287841797,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.0724,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.006007194519043,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.0797,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 17.13368797302246,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.0189,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.22879695892334,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9754,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.692230701446533,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9842,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.320976257324219,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9823,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.66887417218543,
            "eval_f1": 87.61403555465341,
            "eval_runtime": 35.338,
            "eval_samples_per_second": 305.167,
            "eval_steps_per_second": 38.146,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.721856594085693,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6132,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.233222484588623,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5735,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 10.25684928894043,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5846,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 16.265668869018555,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5706,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.947171211242676,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5669,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 11.742395401000977,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.5698,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.715517044067383,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5383,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 8.743237495422363,
            "learning_rate": 4.738427552967166e-06,
            "loss": 0.5425,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 19.722253799438477,
            "learning_rate": 3.2322522341600563e-06,
            "loss": 0.5471,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 22.28006362915039,
            "learning_rate": 1.7290892659905614e-06,
            "loss": 0.5364,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 5.320019245147705,
            "learning_rate": 2.2291394718345217e-07,
            "loss": 0.538,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.02838221381268,
            "eval_f1": 88.1171359814419,
            "eval_runtime": 35.4267,
            "eval_samples_per_second": 304.403,
            "eval_steps_per_second": 38.05,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9573563565920042,
            "train_runtime": 2167.0889,
            "train_samples_per_second": 81.699,
            "train_steps_per_second": 5.106
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.1608325449385,
      "eval_f1": 88.01941975989706,
      "eval_runtime": 25.0638,
      "eval_samples": 10784,
      "eval_samples_per_second": 430.262,
      "eval_steps_per_second": 53.783,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9578763219604823,
      "train_runtime": 874.9869,
      "train_samples": 88524,
      "train_samples_per_second": 202.344,
      "train_steps_per_second": 12.647,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.209941864013672,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7323,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 15.643461227416992,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4896,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.834956169128418,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2963,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.509405136108398,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1971,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.22376251220703,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1061,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.196673393249512,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0722,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.640212059020996,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0802,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.677112579345703,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0162,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 11.942595481872559,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9787,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.2805280685424805,
            "learning_rate": 1.8281956019680694e-05,
            "loss": 0.9853,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.533228397369385,
            "learning_rate": 1.678180540214881e-05,
            "loss": 0.9812,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.47019867549669,
            "eval_f1": 87.41723327979064,
            "eval_runtime": 25.0688,
            "eval_samples_per_second": 430.176,
            "eval_steps_per_second": 53.772,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.554876327514648,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.6161,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 5.279178619384766,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5757,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 9.952468872070312,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5868,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 16.20637321472168,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5712,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.1279802322387695,
            "learning_rate": 9.25394115875088e-06,
            "loss": 0.5679,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 14.122355461120605,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.5738,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.389982223510742,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5448,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.933882713317871,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.5423,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 32.06452941894531,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5492,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 14.693585395812988,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.5338,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.015106678009033,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.5362,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.1608325449385,
            "eval_f1": 88.01941975989706,
            "eval_runtime": 25.2683,
            "eval_samples_per_second": 426.779,
            "eval_steps_per_second": 53.347,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9578763219604823,
            "train_runtime": 874.9869,
            "train_samples_per_second": 202.344,
            "train_steps_per_second": 12.647
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.14191106906338,
      "eval_f1": 88.11141318257872,
      "eval_runtime": 24.9644,
      "eval_samples": 10784,
      "eval_samples_per_second": 431.974,
      "eval_steps_per_second": 53.997,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9569326887160039,
      "train_runtime": 888.9442,
      "train_samples": 88524,
      "train_samples_per_second": 199.167,
      "train_steps_per_second": 12.448,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.93972396850586,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7334,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.131561279296875,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4895,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.907313346862793,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2962,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.044636726379395,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1974,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 14.99517822265625,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1074,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 15.833094596862793,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0768,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.473613739013672,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0786,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 14.484065055847168,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0182,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.05624008178711,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9765,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.84603214263916,
            "learning_rate": 1.8281956019680694e-05,
            "loss": 0.9832,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.242658615112305,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9785,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.54588457899716,
            "eval_f1": 87.38884839572394,
            "eval_runtime": 24.697,
            "eval_samples_per_second": 436.652,
            "eval_steps_per_second": 54.581,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.611917972564697,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6138,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 8.442094802856445,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5699,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 11.44664478302002,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.5844,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 16.390321731567383,
            "learning_rate": 1.075409177628276e-05,
            "loss": 0.5716,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.882226467132568,
            "learning_rate": 9.247916457475651e-06,
            "loss": 0.565,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 12.319623947143555,
            "learning_rate": 7.741741138668541e-06,
            "loss": 0.5694,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 17.51512908935547,
            "learning_rate": 6.235565819861432e-06,
            "loss": 0.5406,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.136330604553223,
            "learning_rate": 4.729390501054323e-06,
            "loss": 0.5407,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 28.308433532714844,
            "learning_rate": 3.2232151822472135e-06,
            "loss": 0.5475,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 13.076071739196777,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.5357,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.829589366912842,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.5379,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.14191106906338,
            "eval_f1": 88.11141318257872,
            "eval_runtime": 29.0429,
            "eval_samples_per_second": 371.313,
            "eval_steps_per_second": 46.414,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9569326887160039,
            "train_runtime": 888.9442,
            "train_samples_per_second": 199.167,
            "train_steps_per_second": 12.448,
            "trainer_state": {
              "best_metric": null,
              "best_model_checkpoint": null,
              "epoch": 2.0,
              "eval_steps": 500,
              "global_step": 11066,
              "is_hyper_param_search": false,
              "is_local_process_zero": true,
              "is_world_process_zero": true,
              "log_history": [
                {
                  "epoch": 0.09036688957166095,
                  "grad_norm": 16.93972396850586,
                  "learning_rate": 1.3495934959349594e-05,
                  "loss": 3.7334,
                  "step": 500
                },
                {
                  "epoch": 0.1807337791433219,
                  "grad_norm": 16.131561279296875,
                  "learning_rate": 2.7046070460704608e-05,
                  "loss": 1.4895,
                  "step": 1000
                },
                {
                  "epoch": 0.27110066871498284,
                  "grad_norm": 6.907313346862793,
                  "learning_rate": 2.8825183251330457e-05,
                  "loss": 1.2962,
                  "step": 1500
                },
                {
                  "epoch": 0.3614675582866438,
                  "grad_norm": 11.044636726379395,
                  "learning_rate": 2.731900793252335e-05,
                  "loss": 1.1974,
                  "step": 2000
                },
                {
                  "epoch": 0.45183444785830473,
                  "grad_norm": 14.99517822265625,
                  "learning_rate": 2.581283261371624e-05,
                  "loss": 1.1074,
                  "step": 2500
                },
                {
                  "epoch": 0.5422013374299657,
                  "grad_norm": 15.833094596862793,
                  "learning_rate": 2.4306657294909128e-05,
                  "loss": 1.0768,
                  "step": 3000
                },
                {
                  "epoch": 0.6325682270016266,
                  "grad_norm": 14.473613739013672,
                  "learning_rate": 2.280048197610202e-05,
                  "loss": 1.0786,
                  "step": 3500
                },
                {
                  "epoch": 0.7229351165732876,
                  "grad_norm": 14.484065055847168,
                  "learning_rate": 2.129430665729491e-05,
                  "loss": 1.0182,
                  "step": 4000
                },
                {
                  "epoch": 0.8133020061449485,
                  "grad_norm": 9.05624008178711,
                  "learning_rate": 1.9788131338487802e-05,
                  "loss": 0.9765,
                  "step": 4500
                },
                {
                  "epoch": 0.9036688957166095,
                  "grad_norm": 7.84603214263916,
                  "learning_rate": 1.8281956019680694e-05,
                  "loss": 0.9832,
                  "step": 5000
                },
                {
                  "epoch": 0.9940357852882704,
                  "grad_norm": 7.242658615112305,
                  "learning_rate": 1.6778793051511194e-05,
                  "loss": 0.9785,
                  "step": 5500
                },
                {
                  "epoch": 1.0,
                  "eval_exact_match": 79.54588457899716,
                  "eval_f1": 87.38884839572394,
                  "eval_runtime": 24.697,
                  "eval_samples_per_second": 436.652,
                  "eval_steps_per_second": 54.581,
                  "step": 5533
                },
                {
                  "epoch": 1.0844026748599314,
                  "grad_norm": 4.611917972564697,
                  "learning_rate": 1.5272617732704086e-05,
                  "loss": 0.6138,
                  "step": 6000
                },
                {
                  "epoch": 1.1747695644315923,
                  "grad_norm": 8.442094802856445,
                  "learning_rate": 1.3766442413896979e-05,
                  "loss": 0.5699,
                  "step": 6500
                },
                {
                  "epoch": 1.2651364540032533,
                  "grad_norm": 11.44664478302002,
                  "learning_rate": 1.226026709508987e-05,
                  "loss": 0.5844,
                  "step": 7000
                },
                {
                  "epoch": 1.3555033435749142,
                  "grad_norm": 16.390321731567383,
                  "learning_rate": 1.075409177628276e-05,
                  "loss": 0.5716,
                  "step": 7500
                },
                {
                  "epoch": 1.4458702331465751,
                  "grad_norm": 6.882226467132568,
                  "learning_rate": 9.247916457475651e-06,
                  "loss": 0.565,
                  "step": 8000
                },
                {
                  "epoch": 1.536237122718236,
                  "grad_norm": 12.319623947143555,
                  "learning_rate": 7.741741138668541e-06,
                  "loss": 0.5694,
                  "step": 8500
                },
                {
                  "epoch": 1.626604012289897,
                  "grad_norm": 17.51512908935547,
                  "learning_rate": 6.235565819861432e-06,
                  "loss": 0.5406,
                  "step": 9000
                },
                {
                  "epoch": 1.7169709018615578,
                  "grad_norm": 10.136330604553223,
                  "learning_rate": 4.729390501054323e-06,
                  "loss": 0.5407,
                  "step": 9500
                },
                {
                  "epoch": 1.807337791433219,
                  "grad_norm": 28.308433532714844,
                  "learning_rate": 3.2232151822472135e-06,
                  "loss": 0.5475,
                  "step": 10000
                },
                {
                  "epoch": 1.8977046810048797,
                  "grad_norm": 13.076071739196777,
                  "learning_rate": 1.723064564715333e-06,
                  "loss": 0.5357,
                  "step": 10500
                },
                {
                  "epoch": 1.9880715705765408,
                  "grad_norm": 4.829589366912842,
                  "learning_rate": 2.1688924590822374e-07,
                  "loss": 0.5379,
                  "step": 11000
                },
                {
                  "epoch": 2.0,
                  "eval_exact_match": 80.14191106906338,
                  "eval_f1": 88.11141318257872,
                  "eval_runtime": 29.0429,
                  "eval_samples_per_second": 371.313,
                  "eval_steps_per_second": 46.414,
                  "step": 11066
                },
                {
                  "epoch": 2.0,
                  "step": 11066,
                  "total_flos": 3.4696551139946496e+16,
                  "train_loss": 0.9569326887160039,
                  "train_runtime": 888.9442,
                  "train_samples_per_second": 199.167,
                  "train_steps_per_second": 12.448
                }
              ],
              "logging_steps": 500,
              "max_steps": 11066,
              "num_input_tokens_seen": 0,
              "num_train_epochs": 2,
              "save_steps": 30000,
              "stateful_callbacks": {
                "TrainerControl": {
                  "args": {
                    "should_epoch_stop": false,
                    "should_evaluate": false,
                    "should_log": false,
                    "should_save": true,
                    "should_training_stop": true
                  },
                  "attributes": {}
                }
              },
              "total_flos": 3.4696551139946496e+16,
              "train_batch_size": 16,
              "trial_name": null,
              "trial_params": null
            }
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.15137180700094,
      "eval_f1": 88.08320943523762,
      "eval_runtime": 25.3391,
      "eval_samples": 10784,
      "eval_samples_per_second": 425.587,
      "eval_steps_per_second": 53.198,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9572848036128488,
      "train_runtime": 880.9718,
      "train_samples": 88524,
      "train_samples_per_second": 200.969,
      "train_steps_per_second": 12.561,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.378055572509766,
            "learning_rate": 1.3468834688346885e-05,
            "loss": 3.7361,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.619705200195312,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4916,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.991274356842041,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2982,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.659272193908691,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1969,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.61731719970703,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1063,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.091402053833008,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0742,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.306344985961914,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0778,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 17.598508834838867,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0174,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 12.632411003112793,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9819,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 8.4591703414917,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9826,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.1565446853637695,
            "learning_rate": 1.678180540214881e-05,
            "loss": 0.9788,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.8391674550615,
            "eval_f1": 87.67341306663296,
            "eval_runtime": 25.3495,
            "eval_samples_per_second": 425.413,
            "eval_steps_per_second": 53.177,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.153524398803711,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.6132,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.991726398468018,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.572,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 8.15306568145752,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5843,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 16.398574829101562,
            "learning_rate": 1.0760116477557988e-05,
            "loss": 0.569,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 8.5364990234375,
            "learning_rate": 9.25394115875088e-06,
            "loss": 0.5681,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 9.491279602050781,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.5713,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.639896392822266,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5379,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.261998176574707,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.5431,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 31.497802734375,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5462,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 13.179563522338867,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5341,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.642459392547607,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5388,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.15137180700094,
            "eval_f1": 88.08320943523762,
            "eval_runtime": 26.2138,
            "eval_samples_per_second": 411.386,
            "eval_steps_per_second": 51.423,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9572848036128488,
            "train_runtime": 880.9718,
            "train_samples_per_second": 200.969,
            "train_steps_per_second": 12.561
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.39735099337749,
      "eval_f1": 88.26193070185434,
      "eval_runtime": 24.7843,
      "eval_samples": 10784,
      "eval_samples_per_second": 435.114,
      "eval_steps_per_second": 54.389,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9579892474791035,
      "train_runtime": 877.7784,
      "train_samples": 88524,
      "train_samples_per_second": 201.7,
      "train_steps_per_second": 12.607,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.73027992248535,
            "learning_rate": 1.3468834688346885e-05,
            "loss": 3.7344,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 17.32892417907715,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.491,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.822413444519043,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2995,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.96012020111084,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1974,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.658287048339844,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1087,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 17.797809600830078,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0725,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 16.084205627441406,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0813,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.695768356323242,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0196,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.475481033325195,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9769,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 8.000458717346191,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9838,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.926672458648682,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9812,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.81078524124882,
            "eval_f1": 87.3829608287492,
            "eval_runtime": 24.9433,
            "eval_samples_per_second": 432.341,
            "eval_steps_per_second": 54.043,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.345836639404297,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.6141,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 8.301691055297852,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5737,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 8.567277908325195,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5825,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.65341854095459,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5725,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.858814716339111,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5675,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 11.84564208984375,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.5701,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 20.4185848236084,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5426,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.457695960998535,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5426,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 29.76484489440918,
            "learning_rate": 3.226227532884828e-06,
            "loss": 0.5491,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 14.383371353149414,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5353,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 8.356414794921875,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5393,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.39735099337749,
            "eval_f1": 88.26193070185434,
            "eval_runtime": 26.8947,
            "eval_samples_per_second": 400.972,
            "eval_steps_per_second": 50.121,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9579892474791035,
            "train_runtime": 877.7784,
            "train_samples_per_second": 201.7,
            "train_steps_per_second": 12.607
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.47303689687796,
      "eval_f1": 88.38073779826986,
      "eval_runtime": 25.1036,
      "eval_samples": 10784,
      "eval_samples_per_second": 429.58,
      "eval_steps_per_second": 53.698,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9582519786344522,
      "train_runtime": 879.444,
      "train_samples": 88524,
      "train_samples_per_second": 201.318,
      "train_steps_per_second": 12.583,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.93972396850586,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7334,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.208951950073242,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4901,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.967984676361084,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2994,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.988887786865234,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1998,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 16.290422439575195,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1065,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 16.307342529296875,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0766,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.699399948120117,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0791,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.306854248046875,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0194,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 12.24069881439209,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9761,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.466348648071289,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9858,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 7.130587577819824,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9778,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.91485335856197,
            "eval_f1": 87.61877908728583,
            "eval_runtime": 24.6199,
            "eval_samples_per_second": 438.019,
            "eval_steps_per_second": 54.752,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.84652042388916,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6158,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.22929859161377,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5711,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 11.45192813873291,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.585,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 14.841804504394531,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5728,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.407027244567871,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5676,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.720779418945312,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.5721,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.253080368041992,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5432,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.436376571655273,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5422,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 19.958772659301758,
            "learning_rate": 3.226227532884828e-06,
            "loss": 0.5505,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 13.695585250854492,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5391,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.4455060958862305,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5382,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.47303689687796,
            "eval_f1": 88.38073779826986,
            "eval_runtime": 28.605,
            "eval_samples_per_second": 376.997,
            "eval_steps_per_second": 47.125,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9582519786344522,
            "train_runtime": 879.444,
            "train_samples_per_second": 201.318,
            "train_steps_per_second": 12.583
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.06622516556291,
      "eval_f1": 88.15204181714624,
      "eval_runtime": 25.4581,
      "eval_samples": 10784,
      "eval_samples_per_second": 423.599,
      "eval_steps_per_second": 52.95,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.957188110034418,
      "train_runtime": 882.2773,
      "train_samples": 88524,
      "train_samples_per_second": 200.672,
      "train_steps_per_second": 12.543,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.621538162231445,
            "learning_rate": 1.3468834688346885e-05,
            "loss": 3.7361,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.00578498840332,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4903,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.798703193664551,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2963,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.637988090515137,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.198,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 15.631966590881348,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.1062,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.262089729309082,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.0752,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.451202392578125,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.0768,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.41475772857666,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.0165,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.159294128417969,
            "learning_rate": 1.979415603976303e-05,
            "loss": 0.9798,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.845202445983887,
            "learning_rate": 1.828798072095592e-05,
            "loss": 0.9827,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.575112819671631,
            "learning_rate": 1.678180540214881e-05,
            "loss": 0.9798,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.71617786187322,
            "eval_f1": 87.50857197559901,
            "eval_runtime": 25.5664,
            "eval_samples_per_second": 421.803,
            "eval_steps_per_second": 52.725,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.8782124519348145,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.6139,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.8760175704956055,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5755,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 11.412193298339844,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5843,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.610147476196289,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5678,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.272150993347168,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5666,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.748716354370117,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.5693,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 20.994037628173828,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.5431,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.642258644104004,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.538,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 21.48499298095703,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5494,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 14.375547409057617,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5339,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.828319549560547,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5376,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.06622516556291,
            "eval_f1": 88.15204181714624,
            "eval_runtime": 25.769,
            "eval_samples_per_second": 418.487,
            "eval_steps_per_second": 52.311,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.957188110034418,
            "train_runtime": 882.2773,
            "train_samples_per_second": 200.672,
            "train_steps_per_second": 12.543
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 80.1135288552507,
      "eval_f1": 88.04636878737311,
      "eval_runtime": 24.5297,
      "eval_samples": 10784,
      "eval_samples_per_second": 439.63,
      "eval_steps_per_second": 54.954,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9578519707753347,
      "train_runtime": 867.5996,
      "train_samples": 88524,
      "train_samples_per_second": 204.066,
      "train_steps_per_second": 12.755,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.808948516845703,
            "learning_rate": 1.3468834688346885e-05,
            "loss": 3.7338,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.031679153442383,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.4915,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.584958553314209,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.299,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 10.217307090759277,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1994,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 15.980931282043457,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1085,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.30007266998291,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0732,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.22984790802002,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0805,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 10.27163314819336,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0185,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 9.628520965576172,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9801,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.802574157714844,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9854,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.739511489868164,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.9791,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.7918637653737,
            "eval_f1": 87.64762129383932,
            "eval_runtime": 24.5739,
            "eval_samples_per_second": 438.84,
            "eval_steps_per_second": 54.855,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.09036922454834,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6123,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.884123802185059,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5718,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 12.728127479553223,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5865,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.68663787841797,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5691,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.358592510223389,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5665,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.966147422790527,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.572,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.58833885192871,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5412,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 10.244438171386719,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5426,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 27.47149658203125,
            "learning_rate": 3.226227532884828e-06,
            "loss": 0.5456,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 14.031039237976074,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.5358,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 3.785381555557251,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.5402,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 80.1135288552507,
            "eval_f1": 88.04636878737311,
            "eval_runtime": 24.9703,
            "eval_samples_per_second": 431.872,
            "eval_steps_per_second": 53.984,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9578519707753347,
            "train_runtime": 867.5996,
            "train_samples_per_second": 204.066,
            "train_steps_per_second": 12.755
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 79.93377483443709,
      "eval_f1": 87.94858552561679,
      "eval_runtime": 26.0046,
      "eval_samples": 10784,
      "eval_samples_per_second": 414.696,
      "eval_steps_per_second": 51.837,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.9565968374738033,
      "train_runtime": 882.7935,
      "train_samples": 88524,
      "train_samples_per_second": 200.554,
      "train_steps_per_second": 12.535,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.93972396850586,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7334,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 16.13945198059082,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4895,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 7.158801078796387,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.2961,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.0177001953125,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.1992,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 15.786497116088867,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.1079,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 15.04368782043457,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.0726,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 14.059527397155762,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.0778,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 13.370981216430664,
            "learning_rate": 2.129430665729491e-05,
            "loss": 1.0176,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 12.445979118347168,
            "learning_rate": 1.9788131338487802e-05,
            "loss": 0.9757,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 8.895296096801758,
            "learning_rate": 1.8281956019680694e-05,
            "loss": 0.9845,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 6.632136821746826,
            "learning_rate": 1.6775780700873582e-05,
            "loss": 0.9804,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 80.00946073793756,
            "eval_f1": 87.57227218808505,
            "eval_runtime": 25.5657,
            "eval_samples_per_second": 421.816,
            "eval_steps_per_second": 52.727,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.454482555389404,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6131,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 8.431736946105957,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.5694,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 9.88959789276123,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5808,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 18.149803161621094,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5697,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 5.857861518859863,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5654,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.639801979064941,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.569,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 19.27424430847168,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5392,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.665932655334473,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5427,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 29.027271270751953,
            "learning_rate": 3.226227532884828e-06,
            "loss": 0.546,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 14.692028045654297,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.5345,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.144003391265869,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.5394,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.93377483443709,
            "eval_f1": 87.94858552561679,
            "eval_runtime": 25.8928,
            "eval_samples_per_second": 416.487,
            "eval_steps_per_second": 52.061,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.9565968374738033,
            "train_runtime": 882.7935,
            "train_samples_per_second": 200.554,
            "train_steps_per_second": 12.535
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 79.71617786187322,
      "eval_f1": 87.81733550444812,
      "eval_runtime": 26.3331,
      "eval_samples": 10784,
      "eval_samples_per_second": 409.522,
      "eval_steps_per_second": 51.19,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 0.956819034109662,
      "train_runtime": 872.1147,
      "train_samples": 88524,
      "train_samples_per_second": 203.01,
      "train_steps_per_second": 12.689,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 16.97054672241211,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 3.7323,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 15.906083106994629,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.4907,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 6.574071884155273,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.3108,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 11.180577278137207,
            "learning_rate": 2.732202028316096e-05,
            "loss": 1.203,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 15.299187660217285,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.1132,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 14.21117115020752,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.0769,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.89580249786377,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.0746,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 14.48190975189209,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.0179,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 12.98005199432373,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 0.9743,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 7.282332897186279,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 0.9812,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.443305969238281,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 0.976,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.33774834437087,
            "eval_f1": 87.0929223179457,
            "eval_runtime": 24.8881,
            "eval_samples_per_second": 433.299,
            "eval_steps_per_second": 54.162,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.139185428619385,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.6104,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 4.868732929229736,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.5694,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 18.03872299194336,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.5799,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 12.297418594360352,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.5688,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.301563262939453,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.5639,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 9.839132308959961,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.566,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 17.668333053588867,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.5351,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 9.754462242126465,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.5407,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 22.16532325744629,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.5498,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 14.37446403503418,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.5385,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 4.710879802703857,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.5368,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 79.71617786187322,
            "eval_f1": 87.81733550444812,
            "eval_runtime": 26.8036,
            "eval_samples_per_second": 402.334,
            "eval_steps_per_second": 50.292,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 0.956819034109662,
            "train_runtime": 872.1147,
            "train_samples_per_second": 203.01,
            "train_steps_per_second": 12.689
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    }
  ],
  "none": [
    {
      "eval_exact_match": 81.23935666982024,
      "eval_f1": 88.60067057966513,
      "eval_runtime": 35.333,
      "eval_samples": 10784,
      "eval_samples_per_second": 305.211,
      "eval_steps_per_second": 38.151,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.1232203982222388,
      "train_runtime": 2301.3687,
      "train_samples": 88524,
      "train_samples_per_second": 76.932,
      "train_steps_per_second": 4.808,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 19.551671981811523,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0369,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 15.07003402709961,
            "learning_rate": 2.7046070460704608e-05,
            "loss": 1.7463,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 10.080854415893555,
            "learning_rate": 2.882217090069284e-05,
            "loss": 1.4493,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 14.226163864135742,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.315,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.741500854492188,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.2163,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 18.11707305908203,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.1799,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 10.022160530090332,
            "learning_rate": 2.280048197610202e-05,
            "loss": 1.1666,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 18.534526824951172,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.112,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 11.65049934387207,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 1.0785,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 11.681205749511719,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 1.0804,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 10.963529586791992,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 1.065,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.5837275307474,
            "eval_f1": 87.24357487547645,
            "eval_runtime": 34.9593,
            "eval_samples_per_second": 308.473,
            "eval_steps_per_second": 38.559,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 7.665724754333496,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.7911,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 12.859699249267578,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.7648,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 26.84337615966797,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.7955,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 14.122027397155762,
            "learning_rate": 1.0760116477557988e-05,
            "loss": 0.757,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 11.49516773223877,
            "learning_rate": 9.25394115875088e-06,
            "loss": 0.7585,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 15.497098922729492,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.7724,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 23.091876983642578,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.7432,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 17.139202117919922,
            "learning_rate": 4.738427552967166e-06,
            "loss": 0.7391,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 17.89323616027832,
            "learning_rate": 3.2322522341600563e-06,
            "loss": 0.7348,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 19.437835693359375,
            "learning_rate": 1.726076915352947e-06,
            "loss": 0.7365,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 15.552765846252441,
            "learning_rate": 2.1990159654583795e-07,
            "loss": 0.7301,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.23935666982024,
            "eval_f1": 88.60067057966513,
            "eval_runtime": 35.0563,
            "eval_samples_per_second": 307.619,
            "eval_steps_per_second": 38.452,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.1232203982222388,
            "train_runtime": 2301.3687,
            "train_samples_per_second": 76.932,
            "train_steps_per_second": 4.808
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.05960264900662,
      "eval_f1": 88.40404935770465,
      "eval_runtime": 24.9619,
      "eval_samples": 10784,
      "eval_samples_per_second": 432.018,
      "eval_steps_per_second": 54.002,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.122898927761335,
      "train_runtime": 894.4454,
      "train_samples": 88524,
      "train_samples_per_second": 197.942,
      "train_steps_per_second": 12.372,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.056703567504883,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0307,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 22.005577087402344,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7452,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.575654983520508,
            "learning_rate": 2.882819560196807e-05,
            "loss": 1.4379,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 16.35205841064453,
            "learning_rate": 2.732202028316096e-05,
            "loss": 1.3137,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.84917640686035,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.2199,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 20.564937591552734,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.1689,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.9036283493042,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1768,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.54120922088623,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.1118,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 19.95261001586914,
            "learning_rate": 1.979415603976303e-05,
            "loss": 1.0808,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 11.204278945922852,
            "learning_rate": 1.828798072095592e-05,
            "loss": 1.0752,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.290088653564453,
            "learning_rate": 1.678180540214881e-05,
            "loss": 1.0627,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.62157048249763,
            "eval_f1": 87.33268882108514,
            "eval_runtime": 24.7534,
            "eval_samples_per_second": 435.657,
            "eval_steps_per_second": 54.457,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.92534875869751,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.7981,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.213603973388672,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.7695,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 11.301461219787598,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.7918,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.4050235748291,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.7662,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.205687046051025,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.7649,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 12.136030197143555,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.7748,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.64482879638672,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.7428,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 15.451959609985352,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.7326,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.204273223876953,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.7321,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 21.975053787231445,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.7309,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 15.587657928466797,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7352,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.05960264900662,
            "eval_f1": 88.40404935770465,
            "eval_runtime": 25.1206,
            "eval_samples_per_second": 429.288,
            "eval_steps_per_second": 53.661,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.122898927761335,
            "train_runtime": 894.4454,
            "train_samples_per_second": 197.942,
            "train_steps_per_second": 12.372
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.22043519394512,
      "eval_f1": 88.49742798703949,
      "eval_runtime": 25.0921,
      "eval_samples": 10784,
      "eval_samples_per_second": 429.776,
      "eval_steps_per_second": 53.722,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.1226027716397593,
      "train_runtime": 892.7066,
      "train_samples": 88524,
      "train_samples_per_second": 198.327,
      "train_steps_per_second": 12.396,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.056703567504883,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0307,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 22.005577087402344,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7452,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.575654983520508,
            "learning_rate": 2.882819560196807e-05,
            "loss": 1.4379,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 16.364362716674805,
            "learning_rate": 2.732202028316096e-05,
            "loss": 1.3136,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.80570411682129,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.2199,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 20.364364624023438,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.1695,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.928024291992188,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1777,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.166719436645508,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.1125,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 22.258928298950195,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 1.0812,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 9.69505500793457,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 1.0749,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.96765422821045,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 1.0621,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.62157048249763,
            "eval_f1": 87.34374246202765,
            "eval_runtime": 24.7018,
            "eval_samples_per_second": 436.568,
            "eval_steps_per_second": 54.571,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.008917331695557,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.7982,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.492492198944092,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.769,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 13.69709587097168,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.7895,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.414180755615234,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.7656,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.461254119873047,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.765,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 11.737079620361328,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.7721,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 22.243534088134766,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.7405,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 14.80224323272705,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.7321,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.610599517822266,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.7318,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 20.881757736206055,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.732,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 14.937773704528809,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7352,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.22043519394512,
            "eval_f1": 88.49742798703949,
            "eval_runtime": 25.7572,
            "eval_samples_per_second": 418.679,
            "eval_steps_per_second": 52.335,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.1226027716397593,
            "train_runtime": 892.7066,
            "train_samples_per_second": 198.327,
            "train_steps_per_second": 12.396
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.2961210974456,
      "eval_f1": 88.56836695986927,
      "eval_runtime": 26.427,
      "eval_samples": 10784,
      "eval_samples_per_second": 408.067,
      "eval_steps_per_second": 51.008,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.1227511432316082,
      "train_runtime": 905.5348,
      "train_samples": 88524,
      "train_samples_per_second": 195.518,
      "train_steps_per_second": 12.22,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.056703567504883,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0307,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 22.005577087402344,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7452,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.575654983520508,
            "learning_rate": 2.882819560196807e-05,
            "loss": 1.4379,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 16.353076934814453,
            "learning_rate": 2.732202028316096e-05,
            "loss": 1.3136,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.811704635620117,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.22,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 20.22840118408203,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.169,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.859354019165039,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1776,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.6668701171875,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.1113,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 19.90221405029297,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 1.0794,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 9.65070915222168,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 1.0744,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.717496871948242,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 1.0624,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.48912015137181,
            "eval_f1": 87.21648774866833,
            "eval_runtime": 25.3088,
            "eval_samples_per_second": 426.097,
            "eval_steps_per_second": 53.262,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.161889553070068,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.7973,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 6.820932388305664,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.7697,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 12.741549491882324,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.7899,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 16.609220504760742,
            "learning_rate": 1.075409177628276e-05,
            "loss": 0.7657,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.115572452545166,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.7664,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 14.155333518981934,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.7744,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 22.357114791870117,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.7406,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 16.442312240600586,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.7325,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.90642547607422,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.7331,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 21.493810653686523,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.7325,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 14.871956825256348,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7351,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.2961210974456,
            "eval_f1": 88.56836695986927,
            "eval_runtime": 25.7598,
            "eval_samples_per_second": 418.636,
            "eval_steps_per_second": 52.33,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.1227511432316082,
            "train_runtime": 905.5348,
            "train_samples_per_second": 195.518,
            "train_steps_per_second": 12.22
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.05960264900662,
      "eval_f1": 88.46257018773991,
      "eval_runtime": 25.7242,
      "eval_samples": 10784,
      "eval_samples_per_second": 419.217,
      "eval_steps_per_second": 52.402,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.1231824863502093,
      "train_runtime": 906.8034,
      "train_samples": 88524,
      "train_samples_per_second": 195.244,
      "train_steps_per_second": 12.203,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.20880699157715,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0329,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 23.395925521850586,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7478,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 12.036659240722656,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.4399,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 16.064237594604492,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.3141,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 18.1103458404541,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.2207,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 19.867454528808594,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.1711,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.942493438720703,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1799,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.429121017456055,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.1104,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 27.786964416503906,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 1.0808,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.002388954162598,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 1.0712,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.212494850158691,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 1.0629,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.84862819299906,
            "eval_f1": 87.50381207785655,
            "eval_runtime": 25.4616,
            "eval_samples_per_second": 423.54,
            "eval_steps_per_second": 52.943,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.4874587059021,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.7986,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 9.173672676086426,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.7677,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 11.206415176391602,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.7882,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.513137817382812,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.7675,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.169229507446289,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.7659,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 11.948219299316406,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.7745,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 22.629377365112305,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.7402,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 14.926573753356934,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.7334,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.93611717224121,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.7312,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 19.769086837768555,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.7355,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 13.736186981201172,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7349,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.05960264900662,
            "eval_f1": 88.46257018773991,
            "eval_runtime": 26.324,
            "eval_samples_per_second": 409.665,
            "eval_steps_per_second": 51.208,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.1231824863502093,
            "train_runtime": 906.8034,
            "train_samples_per_second": 195.244,
            "train_steps_per_second": 12.203
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.10690633869442,
      "eval_f1": 88.43967115207764,
      "eval_runtime": 25.5973,
      "eval_samples": 10784,
      "eval_samples_per_second": 421.295,
      "eval_steps_per_second": 52.662,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.122899535851519,
      "train_runtime": 907.4001,
      "train_samples": 88524,
      "train_samples_per_second": 195.116,
      "train_steps_per_second": 12.195,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.056703567504883,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0307,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 22.005577087402344,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7452,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.575654983520508,
            "learning_rate": 2.882819560196807e-05,
            "loss": 1.4379,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 16.35205841064453,
            "learning_rate": 2.732202028316096e-05,
            "loss": 1.3137,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.84917640686035,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.2199,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 20.564937591552734,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.1689,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.9036283493042,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1768,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.54120922088623,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.1118,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 19.95261001586914,
            "learning_rate": 1.979415603976303e-05,
            "loss": 1.0808,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 11.204278945922852,
            "learning_rate": 1.828798072095592e-05,
            "loss": 1.0752,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.290088653564453,
            "learning_rate": 1.678180540214881e-05,
            "loss": 1.0627,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.62157048249763,
            "eval_f1": 87.33268882108514,
            "eval_runtime": 25.3248,
            "eval_samples_per_second": 425.828,
            "eval_steps_per_second": 53.229,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.92534875869751,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.7981,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.213603973388672,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.7695,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 11.301461219787598,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.7918,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.4050235748291,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.7662,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.205687046051025,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.7649,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 12.136030197143555,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.7748,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.64482879638672,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.7428,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 15.451959609985352,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.7326,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.204273223876953,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.7321,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 21.99186134338379,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.7309,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 15.592541694641113,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7352,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.10690633869442,
            "eval_f1": 88.43967115207764,
            "eval_runtime": 26.3678,
            "eval_samples_per_second": 408.983,
            "eval_steps_per_second": 51.123,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.122899535851519,
            "train_runtime": 907.4001,
            "train_samples_per_second": 195.116,
            "train_steps_per_second": 12.195
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.35288552507096,
      "eval_f1": 88.53961136004754,
      "eval_runtime": 26.0096,
      "eval_samples": 10784,
      "eval_samples_per_second": 414.616,
      "eval_steps_per_second": 51.827,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.1229017948169249,
      "train_runtime": 915.0319,
      "train_samples": 88524,
      "train_samples_per_second": 193.488,
      "train_steps_per_second": 12.094,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.056703567504883,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0307,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 21.950042724609375,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7451,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 12.120466232299805,
            "learning_rate": 2.8825183251330457e-05,
            "loss": 1.4376,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 15.638259887695312,
            "learning_rate": 2.731900793252335e-05,
            "loss": 1.3148,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.384429931640625,
            "learning_rate": 2.581283261371624e-05,
            "loss": 1.2212,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 20.38904571533203,
            "learning_rate": 2.4306657294909128e-05,
            "loss": 1.1698,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.213428497314453,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1763,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.74742317199707,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.11,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 16.591943740844727,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 1.082,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.519133567810059,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 1.0744,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 8.818862915039062,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 1.0617,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.66887417218543,
            "eval_f1": 87.46500772812672,
            "eval_runtime": 25.9136,
            "eval_samples_per_second": 416.152,
            "eval_steps_per_second": 52.019,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.192744255065918,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.7988,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.099094390869141,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.7685,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 12.040245056152344,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.7875,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.1778564453125,
            "learning_rate": 1.075409177628276e-05,
            "loss": 0.768,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 6.815602779388428,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.7672,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 11.010525703430176,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.7754,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.417938232421875,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.7424,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 14.745862007141113,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.7312,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 25.107051849365234,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.7315,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 20.209850311279297,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.7338,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.557198524475098,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7354,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.35288552507096,
            "eval_f1": 88.53961136004754,
            "eval_runtime": 26.3947,
            "eval_samples_per_second": 408.566,
            "eval_steps_per_second": 51.071,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.1229017948169249,
            "train_runtime": 915.0319,
            "train_samples_per_second": 193.488,
            "train_steps_per_second": 12.094
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.05960264900662,
      "eval_f1": 88.46106366864618,
      "eval_runtime": 25.0206,
      "eval_samples": 10784,
      "eval_samples_per_second": 431.004,
      "eval_steps_per_second": 53.876,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.1228209150305024,
      "train_runtime": 888.8315,
      "train_samples": 88524,
      "train_samples_per_second": 199.192,
      "train_steps_per_second": 12.45,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.056703567504883,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0307,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 22.005577087402344,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7452,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.656709671020508,
            "learning_rate": 2.882819560196807e-05,
            "loss": 1.4379,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 16.336469650268555,
            "learning_rate": 2.732202028316096e-05,
            "loss": 1.3147,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 18.51882553100586,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.2209,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 21.294021606445312,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.1699,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.591248512268066,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1756,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.772385597229004,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.1099,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 22.1096134185791,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 1.081,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 13.464593887329102,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 1.0738,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.106196403503418,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 1.0619,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.40397350993378,
            "eval_f1": 87.17785212000848,
            "eval_runtime": 24.516,
            "eval_samples_per_second": 439.876,
            "eval_steps_per_second": 54.985,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.931835174560547,
            "learning_rate": 1.52756300833417e-05,
            "loss": 0.8,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.215985298156738,
            "learning_rate": 1.3769454764534593e-05,
            "loss": 0.7669,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 13.451970100402832,
            "learning_rate": 1.2263279445727483e-05,
            "loss": 0.7876,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 18.341201782226562,
            "learning_rate": 1.0757104126920374e-05,
            "loss": 0.7669,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.299136161804199,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.7659,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.501770973205566,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.7729,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.55362892150879,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.7425,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 15.260982513427734,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.7326,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.47458267211914,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.7337,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 20.37004852294922,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.7345,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 13.867838859558105,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7359,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.05960264900662,
            "eval_f1": 88.46106366864618,
            "eval_runtime": 24.9555,
            "eval_samples_per_second": 432.13,
            "eval_steps_per_second": 54.016,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.1228209150305024,
            "train_runtime": 888.8315,
            "train_samples_per_second": 199.192,
            "train_steps_per_second": 12.45
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.16367076631977,
      "eval_f1": 88.40248133317695,
      "eval_runtime": 25.1892,
      "eval_samples": 10784,
      "eval_samples_per_second": 428.12,
      "eval_steps_per_second": 53.515,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.1226712072949157,
      "train_runtime": 885.7218,
      "train_samples": 88524,
      "train_samples_per_second": 199.891,
      "train_steps_per_second": 12.494,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.056703567504883,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0307,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 22.005577087402344,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7452,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.575654983520508,
            "learning_rate": 2.882819560196807e-05,
            "loss": 1.4379,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 16.35205841064453,
            "learning_rate": 2.732202028316096e-05,
            "loss": 1.3137,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.864850997924805,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.2199,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 20.336658477783203,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.1698,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 13.043607711791992,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1784,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 16.024333953857422,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.1121,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 21.11090850830078,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 1.0814,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 10.20607852935791,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 1.0747,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.626121520996094,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 1.0626,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.7445600756859,
            "eval_f1": 87.39209956998208,
            "eval_runtime": 24.775,
            "eval_samples_per_second": 435.278,
            "eval_steps_per_second": 54.41,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 4.976696491241455,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.798,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 7.511473655700684,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.7681,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 11.644062995910645,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.79,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 17.489273071289062,
            "learning_rate": 1.075409177628276e-05,
            "loss": 0.7652,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.3402204513549805,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.7648,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 14.774436950683594,
            "learning_rate": 7.74776583994377e-06,
            "loss": 0.7737,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.582382202148438,
            "learning_rate": 6.241590521136661e-06,
            "loss": 0.7395,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 16.08328628540039,
            "learning_rate": 4.735415202329551e-06,
            "loss": 0.7317,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 24.56939697265625,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.733,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 20.70954132080078,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.731,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 14.932855606079102,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7359,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.16367076631977,
            "eval_f1": 88.40248133317695,
            "eval_runtime": 26.3574,
            "eval_samples_per_second": 409.145,
            "eval_steps_per_second": 51.143,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.1226712072949157,
            "train_runtime": 885.7218,
            "train_samples_per_second": 199.891,
            "train_steps_per_second": 12.494
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    },
    {
      "eval_exact_match": 81.05014191106906,
      "eval_f1": 88.42580173557117,
      "eval_runtime": 27.535,
      "eval_samples": 10784,
      "eval_samples_per_second": 391.646,
      "eval_steps_per_second": 48.956,
      "total_flos": 3.4696551139946496e+16,
      "train_loss": 1.1231203449800133,
      "train_runtime": 921.4435,
      "train_samples": 88524,
      "train_samples_per_second": 192.142,
      "train_steps_per_second": 12.009,
      "trainer_state": {
        "best_metric": null,
        "best_model_checkpoint": null,
        "epoch": 2.0,
        "eval_steps": 500,
        "global_step": 11066,
        "is_hyper_param_search": false,
        "is_local_process_zero": true,
        "is_world_process_zero": true,
        "log_history": [
          {
            "epoch": 0.09036688957166095,
            "grad_norm": 17.056703567504883,
            "learning_rate": 1.3495934959349594e-05,
            "loss": 4.0307,
            "step": 500
          },
          {
            "epoch": 0.1807337791433219,
            "grad_norm": 21.929283142089844,
            "learning_rate": 2.70189701897019e-05,
            "loss": 1.7451,
            "step": 1000
          },
          {
            "epoch": 0.27110066871498284,
            "grad_norm": 11.912559509277344,
            "learning_rate": 2.882819560196807e-05,
            "loss": 1.4373,
            "step": 1500
          },
          {
            "epoch": 0.3614675582866438,
            "grad_norm": 15.926858901977539,
            "learning_rate": 2.732202028316096e-05,
            "loss": 1.3144,
            "step": 2000
          },
          {
            "epoch": 0.45183444785830473,
            "grad_norm": 17.457622528076172,
            "learning_rate": 2.581584496435385e-05,
            "loss": 1.2206,
            "step": 2500
          },
          {
            "epoch": 0.5422013374299657,
            "grad_norm": 20.0438289642334,
            "learning_rate": 2.430966964554674e-05,
            "loss": 1.1691,
            "step": 3000
          },
          {
            "epoch": 0.6325682270016266,
            "grad_norm": 12.631717681884766,
            "learning_rate": 2.2803494326739632e-05,
            "loss": 1.1775,
            "step": 3500
          },
          {
            "epoch": 0.7229351165732876,
            "grad_norm": 15.685075759887695,
            "learning_rate": 2.1297319007932523e-05,
            "loss": 1.1111,
            "step": 4000
          },
          {
            "epoch": 0.8133020061449485,
            "grad_norm": 20.376384735107422,
            "learning_rate": 1.9791143689125415e-05,
            "loss": 1.0811,
            "step": 4500
          },
          {
            "epoch": 0.9036688957166095,
            "grad_norm": 9.931756973266602,
            "learning_rate": 1.8284968370318306e-05,
            "loss": 1.0747,
            "step": 5000
          },
          {
            "epoch": 0.9940357852882704,
            "grad_norm": 9.780746459960938,
            "learning_rate": 1.6778793051511194e-05,
            "loss": 1.0629,
            "step": 5500
          },
          {
            "epoch": 1.0,
            "eval_exact_match": 79.63103122043519,
            "eval_f1": 87.31860437326752,
            "eval_runtime": 25.8026,
            "eval_samples_per_second": 417.942,
            "eval_steps_per_second": 52.243,
            "step": 5533
          },
          {
            "epoch": 1.0844026748599314,
            "grad_norm": 5.252377510070801,
            "learning_rate": 1.5272617732704086e-05,
            "loss": 0.802,
            "step": 6000
          },
          {
            "epoch": 1.1747695644315923,
            "grad_norm": 12.49450397491455,
            "learning_rate": 1.3766442413896979e-05,
            "loss": 0.767,
            "step": 6500
          },
          {
            "epoch": 1.2651364540032533,
            "grad_norm": 13.582756996154785,
            "learning_rate": 1.226026709508987e-05,
            "loss": 0.7896,
            "step": 7000
          },
          {
            "epoch": 1.3555033435749142,
            "grad_norm": 15.986721992492676,
            "learning_rate": 1.075409177628276e-05,
            "loss": 0.7693,
            "step": 7500
          },
          {
            "epoch": 1.4458702331465751,
            "grad_norm": 7.177356719970703,
            "learning_rate": 9.250928808113265e-06,
            "loss": 0.7652,
            "step": 8000
          },
          {
            "epoch": 1.536237122718236,
            "grad_norm": 10.668347358703613,
            "learning_rate": 7.744753489306155e-06,
            "loss": 0.7747,
            "step": 8500
          },
          {
            "epoch": 1.626604012289897,
            "grad_norm": 21.411375045776367,
            "learning_rate": 6.2385781704990465e-06,
            "loss": 0.7395,
            "step": 9000
          },
          {
            "epoch": 1.7169709018615578,
            "grad_norm": 15.51572322845459,
            "learning_rate": 4.732402851691937e-06,
            "loss": 0.7335,
            "step": 9500
          },
          {
            "epoch": 1.807337791433219,
            "grad_norm": 23.8735408782959,
            "learning_rate": 3.229239883522442e-06,
            "loss": 0.732,
            "step": 10000
          },
          {
            "epoch": 1.8977046810048797,
            "grad_norm": 19.711668014526367,
            "learning_rate": 1.723064564715333e-06,
            "loss": 0.7349,
            "step": 10500
          },
          {
            "epoch": 1.9880715705765408,
            "grad_norm": 12.970662117004395,
            "learning_rate": 2.1688924590822374e-07,
            "loss": 0.7359,
            "step": 11000
          },
          {
            "epoch": 2.0,
            "eval_exact_match": 81.05014191106906,
            "eval_f1": 88.42580173557117,
            "eval_runtime": 30.0385,
            "eval_samples_per_second": 359.006,
            "eval_steps_per_second": 44.876,
            "step": 11066
          },
          {
            "epoch": 2.0,
            "step": 11066,
            "total_flos": 3.4696551139946496e+16,
            "train_loss": 1.1231203449800133,
            "train_runtime": 921.4435,
            "train_samples_per_second": 192.142,
            "train_steps_per_second": 12.009
          }
        ],
        "logging_steps": 500,
        "max_steps": 11066,
        "num_input_tokens_seen": 0,
        "num_train_epochs": 2,
        "save_steps": 30000,
        "stateful_callbacks": {
          "TrainerControl": {
            "args": {
              "should_epoch_stop": false,
              "should_evaluate": false,
              "should_log": false,
              "should_save": true,
              "should_training_stop": true
            },
            "attributes": {}
          }
        },
        "total_flos": 3.4696551139946496e+16,
        "train_batch_size": 16,
        "trial_name": null,
        "trial_params": null
      }
    }
  ]
}