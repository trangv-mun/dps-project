{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "LjNpL4mQkIpU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29189,
     "status": "ok",
     "timestamp": 1733062943955,
     "user": {
      "displayName": "Jennifer Smith",
      "userId": "09576828969092287875"
     },
     "user_tz": 210
    },
    "id": "LjNpL4mQkIpU",
    "outputId": "d4f8d9b8-35df-44df-b46b-54af4ff1b30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3Hi4ISFAkbCb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1397,
     "status": "ok",
     "timestamp": 1733062949829,
     "user": {
      "displayName": "Jennifer Smith",
      "userId": "09576828969092287875"
     },
     "user_tz": 210
    },
    "id": "3Hi4ISFAkbCb",
    "outputId": "e1f9b87a-f256-495d-f798-961a2077e986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/dps-project/scripts\n"
     ]
    }
   ],
   "source": [
    "# go to the colab notebook folder\n",
    "%cd /content/drive/My Drive/Colab Notebooks/dps-project/scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "RFTnxzODkymY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7200,
     "status": "ok",
     "timestamp": 1733062961814,
     "user": {
      "displayName": "Jennifer Smith",
      "userId": "09576828969092287875"
     },
     "user_tz": 210
    },
    "id": "RFTnxzODkymY",
    "outputId": "4a827f81-e2a5-4df5-c6a4-ae305e475ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fCRTPqtnsq-H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 402421,
     "status": "ok",
     "timestamp": 1731890577981,
     "user": {
      "displayName": "Jennifer Smith",
      "userId": "09576828969092287875"
     },
     "user_tz": 210
    },
    "id": "fCRTPqtnsq-H",
    "outputId": "0c8e94c7-352c-40f1-9a96-ce443ca781f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-18 00:36:19.488244: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-18 00:36:19.510089: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-18 00:36:19.516455: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 00:36:19.531958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-18 00:36:20.740450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "11/18/2024 00:36:22 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "11/18/2024 00:36:22 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=epoch,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=3e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./output_qa/runs/Nov18_00-36-22_4edf2a67b5da,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./output_qa,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./output_qa,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=30000,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=666,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "11/18/2024 00:36:25 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f\n",
      "11/18/2024 00:36:25 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f\n",
      "Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f)\n",
      "11/18/2024 00:36:25 - INFO - datasets.builder - Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f)\n",
      "Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f\n",
      "11/18/2024 00:36:25 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f\n",
      "[INFO|configuration_utils.py:679] 2024-11-18 00:36:26,136 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-18 00:36:26,137 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:679] 2024-11-18 00:36:26,225 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-18 00:36:26,226 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-18 00:36:26,227 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-18 00:36:26,227 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-18 00:36:26,227 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-18 00:36:26,227 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-11-18 00:36:26,227 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "[INFO|configuration_utils.py:679] 2024-11-18 00:36:26,228 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-11-18 00:36:26,229 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3937] 2024-11-18 00:36:26,306 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "[INFO|logging.py:343] 2024-11-18 00:36:26,348 >> A pretrained model of type `BertForQuestionAnswering` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n",
      "* `bert.embeddings.LayerNorm.gamma` -> `bert.embeddings.LayerNorm.weight`\n",
      "* `bert.encoder.layer.0.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.0.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.1.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.1.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.10.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.10.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.11.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.11.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.2.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.2.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.3.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.3.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.4.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.4.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.5.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.5.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.6.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.6.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.7.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.7.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.8.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.8.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.9.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `cls.predictions.transform.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.embeddings.LayerNorm.beta` -> `bert.embeddings.LayerNorm.bias`\n",
      "* `bert.encoder.layer.0.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.0.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.1.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.1.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.10.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.10.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.11.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.11.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.2.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.2.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.3.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.3.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.4.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.4.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.5.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.5.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.6.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.6.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.7.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.7.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.8.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.8.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.9.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.9.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `cls.predictions.transform.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n",
      "[INFO|modeling_utils.py:4790] 2024-11-18 00:36:26,423 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:4802] 2024-11-18 00:36:26,423 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-a1dae60a2d63c0f5.arrow\n",
      "11/18/2024 00:36:26 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-a1dae60a2d63c0f5.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-906db2f7c2903d11.arrow\n",
      "11/18/2024 00:36:26 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-906db2f7c2903d11.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-ed02aa2bf1883535.arrow\n",
      "11/18/2024 00:36:26 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-ed02aa2bf1883535.arrow\n",
      "[INFO|trainer.py:699] 2024-11-18 00:36:27,355 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2314] 2024-11-18 00:36:27,639 >> ***** Running training *****\n",
      "[INFO|trainer.py:2315] 2024-11-18 00:36:27,639 >>   Num examples = 5,066\n",
      "[INFO|trainer.py:2316] 2024-11-18 00:36:27,639 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:2317] 2024-11-18 00:36:27,639 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:2320] 2024-11-18 00:36:27,639 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2321] 2024-11-18 00:36:27,639 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2322] 2024-11-18 00:36:27,639 >>   Total optimization steps = 634\n",
      "[INFO|trainer.py:2323] 2024-11-18 00:36:27,640 >>   Number of trainable parameters = 108,893,186\n",
      " 50% 317/634 [01:01<00:55,  5.68it/s][INFO|trainer.py:875] 2024-11-18 00:37:28,896 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4128] 2024-11-18 00:37:28,899 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4130] 2024-11-18 00:37:28,899 >>   Num examples = 10784\n",
      "[INFO|trainer.py:4133] 2024-11-18 00:37:28,899 >>   Batch size = 8\n",
      "\n",
      "  0% 0/1348 [00:00<?, ?it/s]\u001b[A\n",
      "  0% 5/1348 [00:00<00:27, 48.78it/s]\u001b[A\n",
      "  1% 10/1348 [00:00<00:31, 42.04it/s]\u001b[A\n",
      "  1% 15/1348 [00:00<00:33, 39.84it/s]\u001b[A\n",
      "  1% 20/1348 [00:00<00:33, 39.17it/s]\u001b[A\n",
      "  2% 24/1348 [00:00<00:34, 38.66it/s]\u001b[A\n",
      "  2% 28/1348 [00:00<00:34, 38.36it/s]\u001b[A\n",
      "  2% 32/1348 [00:00<00:34, 38.43it/s]\u001b[A\n",
      "  3% 36/1348 [00:00<00:34, 38.08it/s]\u001b[A\n",
      "  3% 40/1348 [00:01<00:34, 37.98it/s]\u001b[A\n",
      "  3% 44/1348 [00:01<00:34, 38.03it/s]\u001b[A\n",
      "  4% 48/1348 [00:01<00:34, 37.70it/s]\u001b[A\n",
      "  4% 52/1348 [00:01<00:34, 37.76it/s]\u001b[A\n",
      "  4% 56/1348 [00:01<00:34, 37.95it/s]\u001b[A\n",
      "  4% 60/1348 [00:01<00:33, 38.17it/s]\u001b[A\n",
      "  5% 64/1348 [00:01<00:33, 38.10it/s]\u001b[A\n",
      "  5% 68/1348 [00:01<00:33, 38.38it/s]\u001b[A\n",
      "  5% 72/1348 [00:01<00:33, 38.53it/s]\u001b[A\n",
      "  6% 76/1348 [00:01<00:32, 38.75it/s]\u001b[A\n",
      "  6% 80/1348 [00:02<00:32, 38.92it/s]\u001b[A\n",
      "  6% 84/1348 [00:02<00:32, 39.03it/s]\u001b[A\n",
      "  7% 88/1348 [00:02<00:32, 38.96it/s]\u001b[A\n",
      "  7% 92/1348 [00:02<00:32, 38.62it/s]\u001b[A\n",
      "  7% 96/1348 [00:02<00:32, 38.34it/s]\u001b[A\n",
      "  7% 100/1348 [00:02<00:32, 38.38it/s]\u001b[A\n",
      "  8% 104/1348 [00:02<00:32, 38.51it/s]\u001b[A\n",
      "  8% 108/1348 [00:02<00:32, 38.45it/s]\u001b[A\n",
      "  8% 112/1348 [00:02<00:32, 38.37it/s]\u001b[A\n",
      "  9% 116/1348 [00:03<00:32, 38.48it/s]\u001b[A\n",
      "  9% 120/1348 [00:03<00:31, 38.73it/s]\u001b[A\n",
      "  9% 124/1348 [00:03<00:31, 38.78it/s]\u001b[A\n",
      "  9% 128/1348 [00:03<00:31, 38.79it/s]\u001b[A\n",
      " 10% 132/1348 [00:03<00:31, 38.58it/s]\u001b[A\n",
      " 10% 136/1348 [00:03<00:31, 38.31it/s]\u001b[A\n",
      " 10% 140/1348 [00:03<00:31, 38.39it/s]\u001b[A\n",
      " 11% 144/1348 [00:03<00:31, 38.47it/s]\u001b[A\n",
      " 11% 148/1348 [00:03<00:31, 38.39it/s]\u001b[A\n",
      " 11% 152/1348 [00:03<00:31, 38.52it/s]\u001b[A\n",
      " 12% 156/1348 [00:04<00:30, 38.78it/s]\u001b[A\n",
      " 12% 160/1348 [00:04<00:30, 38.82it/s]\u001b[A\n",
      " 12% 164/1348 [00:04<00:30, 38.79it/s]\u001b[A\n",
      " 12% 168/1348 [00:04<00:30, 38.79it/s]\u001b[A\n",
      " 13% 172/1348 [00:04<00:30, 38.85it/s]\u001b[A\n",
      " 13% 176/1348 [00:04<00:30, 38.74it/s]\u001b[A\n",
      " 13% 180/1348 [00:04<00:30, 38.75it/s]\u001b[A\n",
      " 14% 184/1348 [00:04<00:30, 38.66it/s]\u001b[A\n",
      " 14% 188/1348 [00:04<00:30, 38.54it/s]\u001b[A\n",
      " 14% 192/1348 [00:04<00:29, 38.71it/s]\u001b[A\n",
      " 15% 196/1348 [00:05<00:29, 38.76it/s]\u001b[A\n",
      " 15% 200/1348 [00:05<00:29, 38.78it/s]\u001b[A\n",
      " 15% 204/1348 [00:05<00:29, 38.75it/s]\u001b[A\n",
      " 15% 208/1348 [00:05<00:29, 38.61it/s]\u001b[A\n",
      " 16% 212/1348 [00:05<00:29, 38.72it/s]\u001b[A\n",
      " 16% 216/1348 [00:05<00:29, 38.79it/s]\u001b[A\n",
      " 16% 220/1348 [00:05<00:29, 38.78it/s]\u001b[A\n",
      " 17% 224/1348 [00:05<00:29, 38.56it/s]\u001b[A\n",
      " 17% 228/1348 [00:05<00:29, 38.61it/s]\u001b[A\n",
      " 17% 232/1348 [00:06<00:28, 38.61it/s]\u001b[A\n",
      " 18% 236/1348 [00:06<00:28, 38.65it/s]\u001b[A\n",
      " 18% 240/1348 [00:06<00:28, 38.72it/s]\u001b[A\n",
      " 18% 244/1348 [00:06<00:28, 38.80it/s]\u001b[A\n",
      " 18% 248/1348 [00:06<00:28, 38.73it/s]\u001b[A\n",
      " 19% 252/1348 [00:06<00:28, 38.64it/s]\u001b[A\n",
      " 19% 256/1348 [00:06<00:28, 38.62it/s]\u001b[A\n",
      " 19% 260/1348 [00:06<00:28, 38.52it/s]\u001b[A\n",
      " 20% 264/1348 [00:06<00:28, 38.59it/s]\u001b[A\n",
      " 20% 268/1348 [00:06<00:27, 38.70it/s]\u001b[A\n",
      " 20% 272/1348 [00:07<00:27, 38.57it/s]\u001b[A\n",
      " 20% 276/1348 [00:07<00:27, 38.58it/s]\u001b[A\n",
      " 21% 280/1348 [00:07<00:27, 38.67it/s]\u001b[A\n",
      " 21% 284/1348 [00:07<00:27, 38.69it/s]\u001b[A\n",
      " 21% 288/1348 [00:07<00:27, 38.68it/s]\u001b[A\n",
      " 22% 292/1348 [00:07<00:27, 38.23it/s]\u001b[A\n",
      " 22% 296/1348 [00:07<00:27, 38.10it/s]\u001b[A\n",
      " 22% 300/1348 [00:07<00:27, 37.96it/s]\u001b[A\n",
      " 23% 304/1348 [00:07<00:27, 38.02it/s]\u001b[A\n",
      " 23% 308/1348 [00:07<00:27, 38.33it/s]\u001b[A\n",
      " 23% 312/1348 [00:08<00:27, 38.26it/s]\u001b[A\n",
      " 23% 316/1348 [00:08<00:26, 38.45it/s]\u001b[A\n",
      " 24% 320/1348 [00:08<00:26, 38.48it/s]\u001b[A\n",
      " 24% 324/1348 [00:08<00:26, 38.07it/s]\u001b[A\n",
      " 24% 328/1348 [00:08<00:26, 38.03it/s]\u001b[A\n",
      " 25% 332/1348 [00:08<00:26, 38.16it/s]\u001b[A\n",
      " 25% 336/1348 [00:08<00:26, 38.38it/s]\u001b[A\n",
      " 25% 340/1348 [00:08<00:26, 38.42it/s]\u001b[A\n",
      " 26% 344/1348 [00:08<00:26, 38.45it/s]\u001b[A\n",
      " 26% 348/1348 [00:09<00:25, 38.46it/s]\u001b[A\n",
      " 26% 352/1348 [00:09<00:25, 38.46it/s]\u001b[A\n",
      " 26% 356/1348 [00:09<00:25, 38.52it/s]\u001b[A\n",
      " 27% 360/1348 [00:09<00:25, 38.49it/s]\u001b[A\n",
      " 27% 364/1348 [00:09<00:25, 38.33it/s]\u001b[A\n",
      " 27% 368/1348 [00:09<00:25, 38.18it/s]\u001b[A\n",
      " 28% 372/1348 [00:09<00:25, 38.38it/s]\u001b[A\n",
      " 28% 376/1348 [00:09<00:25, 38.51it/s]\u001b[A\n",
      " 28% 380/1348 [00:09<00:25, 38.31it/s]\u001b[A\n",
      " 28% 384/1348 [00:09<00:25, 38.30it/s]\u001b[A\n",
      " 29% 388/1348 [00:10<00:25, 38.26it/s]\u001b[A\n",
      " 29% 392/1348 [00:10<00:24, 38.37it/s]\u001b[A\n",
      " 29% 396/1348 [00:10<00:24, 38.12it/s]\u001b[A\n",
      " 30% 400/1348 [00:10<00:24, 38.25it/s]\u001b[A\n",
      " 30% 404/1348 [00:10<00:24, 38.13it/s]\u001b[A\n",
      " 30% 408/1348 [00:10<00:24, 38.15it/s]\u001b[A\n",
      " 31% 412/1348 [00:10<00:24, 37.92it/s]\u001b[A\n",
      " 31% 416/1348 [00:10<00:24, 38.04it/s]\u001b[A\n",
      " 31% 420/1348 [00:10<00:24, 38.12it/s]\u001b[A\n",
      " 31% 424/1348 [00:11<00:24, 38.45it/s]\u001b[A\n",
      " 32% 428/1348 [00:11<00:23, 38.69it/s]\u001b[A\n",
      " 32% 432/1348 [00:11<00:23, 38.51it/s]\u001b[A\n",
      " 32% 436/1348 [00:11<00:23, 38.62it/s]\u001b[A\n",
      " 33% 440/1348 [00:11<00:23, 38.39it/s]\u001b[A\n",
      " 33% 444/1348 [00:11<00:23, 38.28it/s]\u001b[A\n",
      " 33% 448/1348 [00:11<00:23, 38.33it/s]\u001b[A\n",
      " 34% 452/1348 [00:11<00:23, 38.17it/s]\u001b[A\n",
      " 34% 456/1348 [00:11<00:23, 38.10it/s]\u001b[A\n",
      " 34% 460/1348 [00:11<00:23, 38.16it/s]\u001b[A\n",
      " 34% 464/1348 [00:12<00:22, 38.47it/s]\u001b[A\n",
      " 35% 468/1348 [00:12<00:23, 38.11it/s]\u001b[A\n",
      " 35% 472/1348 [00:12<00:22, 38.27it/s]\u001b[A\n",
      " 35% 476/1348 [00:12<00:22, 38.53it/s]\u001b[A\n",
      " 36% 480/1348 [00:12<00:22, 38.58it/s]\u001b[A\n",
      " 36% 484/1348 [00:12<00:22, 38.52it/s]\u001b[A\n",
      " 36% 488/1348 [00:12<00:22, 38.31it/s]\u001b[A\n",
      " 36% 492/1348 [00:12<00:22, 38.11it/s]\u001b[A\n",
      " 37% 496/1348 [00:12<00:22, 38.28it/s]\u001b[A\n",
      " 37% 500/1348 [00:12<00:22, 38.39it/s]\u001b[A\n",
      " 37% 504/1348 [00:13<00:22, 38.21it/s]\u001b[A\n",
      " 38% 508/1348 [00:13<00:21, 38.31it/s]\u001b[A\n",
      " 38% 512/1348 [00:13<00:21, 38.35it/s]\u001b[A\n",
      " 38% 516/1348 [00:13<00:21, 38.39it/s]\u001b[A\n",
      " 39% 520/1348 [00:13<00:21, 38.47it/s]\u001b[A\n",
      " 39% 524/1348 [00:13<00:21, 38.15it/s]\u001b[A\n",
      " 39% 528/1348 [00:13<00:21, 37.85it/s]\u001b[A\n",
      " 39% 532/1348 [00:13<00:21, 38.06it/s]\u001b[A\n",
      " 40% 536/1348 [00:13<00:21, 37.92it/s]\u001b[A\n",
      " 40% 540/1348 [00:14<00:21, 37.78it/s]\u001b[A\n",
      " 40% 544/1348 [00:14<00:21, 37.94it/s]\u001b[A\n",
      " 41% 548/1348 [00:14<00:20, 38.15it/s]\u001b[A\n",
      " 41% 552/1348 [00:14<00:21, 37.89it/s]\u001b[A\n",
      " 41% 556/1348 [00:14<00:20, 37.94it/s]\u001b[A\n",
      " 42% 560/1348 [00:14<00:20, 38.11it/s]\u001b[A\n",
      " 42% 564/1348 [00:14<00:20, 38.17it/s]\u001b[A\n",
      " 42% 568/1348 [00:14<00:20, 38.10it/s]\u001b[A\n",
      " 42% 572/1348 [00:14<00:20, 38.02it/s]\u001b[A\n",
      " 43% 576/1348 [00:14<00:20, 38.26it/s]\u001b[A\n",
      " 43% 580/1348 [00:15<00:20, 38.37it/s]\u001b[A\n",
      " 43% 584/1348 [00:15<00:19, 38.40it/s]\u001b[A\n",
      " 44% 588/1348 [00:15<00:19, 38.47it/s]\u001b[A\n",
      " 44% 592/1348 [00:15<00:19, 38.20it/s]\u001b[A\n",
      " 44% 596/1348 [00:15<00:19, 38.37it/s]\u001b[A\n",
      " 45% 600/1348 [00:15<00:19, 38.36it/s]\u001b[A\n",
      " 45% 604/1348 [00:15<00:19, 38.18it/s]\u001b[A\n",
      " 45% 608/1348 [00:15<00:19, 38.12it/s]\u001b[A\n",
      " 45% 612/1348 [00:15<00:19, 38.12it/s]\u001b[A\n",
      " 46% 616/1348 [00:16<00:19, 38.27it/s]\u001b[A\n",
      " 46% 620/1348 [00:16<00:19, 37.60it/s]\u001b[A\n",
      " 46% 624/1348 [00:16<00:19, 37.97it/s]\u001b[A\n",
      " 47% 628/1348 [00:16<00:18, 38.04it/s]\u001b[A\n",
      " 47% 632/1348 [00:16<00:18, 37.94it/s]\u001b[A\n",
      " 47% 636/1348 [00:16<00:18, 38.15it/s]\u001b[A\n",
      " 47% 640/1348 [00:16<00:18, 38.11it/s]\u001b[A\n",
      " 48% 644/1348 [00:16<00:18, 38.17it/s]\u001b[A\n",
      " 48% 648/1348 [00:16<00:18, 37.75it/s]\u001b[A\n",
      " 48% 652/1348 [00:16<00:18, 37.92it/s]\u001b[A\n",
      " 49% 656/1348 [00:17<00:18, 38.03it/s]\u001b[A\n",
      " 49% 660/1348 [00:17<00:18, 38.15it/s]\u001b[A\n",
      " 49% 664/1348 [00:17<00:17, 38.08it/s]\u001b[A\n",
      " 50% 668/1348 [00:17<00:17, 38.00it/s]\u001b[A\n",
      " 50% 672/1348 [00:17<00:17, 38.16it/s]\u001b[A\n",
      " 50% 676/1348 [00:17<00:17, 38.24it/s]\u001b[A\n",
      " 50% 680/1348 [00:17<00:17, 38.01it/s]\u001b[A\n",
      " 51% 684/1348 [00:17<00:17, 37.84it/s]\u001b[A\n",
      " 51% 688/1348 [00:17<00:17, 38.05it/s]\u001b[A\n",
      " 51% 692/1348 [00:18<00:17, 37.80it/s]\u001b[A\n",
      " 52% 696/1348 [00:18<00:17, 38.06it/s]\u001b[A\n",
      " 52% 700/1348 [00:18<00:17, 37.96it/s]\u001b[A\n",
      " 52% 704/1348 [00:18<00:16, 38.01it/s]\u001b[A\n",
      " 53% 708/1348 [00:18<00:16, 38.00it/s]\u001b[A\n",
      " 53% 712/1348 [00:18<00:16, 38.10it/s]\u001b[A\n",
      " 53% 716/1348 [00:18<00:16, 38.00it/s]\u001b[A\n",
      " 53% 720/1348 [00:18<00:16, 38.05it/s]\u001b[A\n",
      " 54% 724/1348 [00:18<00:16, 37.92it/s]\u001b[A\n",
      " 54% 728/1348 [00:18<00:16, 38.01it/s]\u001b[A\n",
      " 54% 732/1348 [00:19<00:16, 38.25it/s]\u001b[A\n",
      " 55% 736/1348 [00:19<00:15, 38.36it/s]\u001b[A\n",
      " 55% 740/1348 [00:19<00:15, 38.52it/s]\u001b[A\n",
      " 55% 744/1348 [00:19<00:15, 38.22it/s]\u001b[A\n",
      " 55% 748/1348 [00:19<00:15, 38.22it/s]\u001b[A\n",
      " 56% 752/1348 [00:19<00:15, 38.40it/s]\u001b[A\n",
      " 56% 756/1348 [00:19<00:15, 38.36it/s]\u001b[A\n",
      " 56% 760/1348 [00:19<00:15, 37.89it/s]\u001b[A\n",
      " 57% 764/1348 [00:19<00:15, 37.90it/s]\u001b[A\n",
      " 57% 768/1348 [00:20<00:15, 37.95it/s]\u001b[A\n",
      " 57% 772/1348 [00:20<00:15, 38.03it/s]\u001b[A\n",
      " 58% 776/1348 [00:20<00:15, 37.98it/s]\u001b[A\n",
      " 58% 780/1348 [00:20<00:14, 38.00it/s]\u001b[A\n",
      " 58% 784/1348 [00:20<00:14, 38.03it/s]\u001b[A\n",
      " 58% 788/1348 [00:20<00:14, 38.27it/s]\u001b[A\n",
      " 59% 792/1348 [00:20<00:14, 38.20it/s]\u001b[A\n",
      " 59% 796/1348 [00:20<00:14, 38.17it/s]\u001b[A\n",
      " 59% 800/1348 [00:20<00:14, 38.14it/s]\u001b[A\n",
      " 60% 804/1348 [00:20<00:14, 38.27it/s]\u001b[A\n",
      " 60% 808/1348 [00:21<00:14, 38.12it/s]\u001b[A\n",
      " 60% 812/1348 [00:21<00:14, 37.95it/s]\u001b[A\n",
      " 61% 816/1348 [00:21<00:13, 38.09it/s]\u001b[A\n",
      " 61% 820/1348 [00:21<00:13, 38.15it/s]\u001b[A\n",
      " 61% 824/1348 [00:21<00:13, 37.91it/s]\u001b[A\n",
      " 61% 828/1348 [00:21<00:13, 37.92it/s]\u001b[A\n",
      " 62% 832/1348 [00:21<00:13, 38.00it/s]\u001b[A\n",
      " 62% 836/1348 [00:21<00:13, 37.99it/s]\u001b[A\n",
      " 62% 840/1348 [00:21<00:13, 38.07it/s]\u001b[A\n",
      " 63% 844/1348 [00:22<00:13, 38.20it/s]\u001b[A\n",
      " 63% 848/1348 [00:22<00:13, 38.29it/s]\u001b[A\n",
      " 63% 852/1348 [00:22<00:13, 38.14it/s]\u001b[A\n",
      " 64% 856/1348 [00:22<00:12, 38.09it/s]\u001b[A\n",
      " 64% 860/1348 [00:22<00:12, 37.95it/s]\u001b[A\n",
      " 64% 864/1348 [00:22<00:12, 38.08it/s]\u001b[A\n",
      " 64% 868/1348 [00:22<00:12, 37.91it/s]\u001b[A\n",
      " 65% 872/1348 [00:22<00:12, 37.76it/s]\u001b[A\n",
      " 65% 876/1348 [00:22<00:12, 37.93it/s]\u001b[A\n",
      " 65% 880/1348 [00:22<00:12, 37.75it/s]\u001b[A\n",
      " 66% 884/1348 [00:23<00:12, 37.95it/s]\u001b[A\n",
      " 66% 888/1348 [00:23<00:12, 37.84it/s]\u001b[A\n",
      " 66% 892/1348 [00:23<00:11, 38.06it/s]\u001b[A\n",
      " 66% 896/1348 [00:23<00:11, 38.16it/s]\u001b[A\n",
      " 67% 900/1348 [00:23<00:11, 38.15it/s]\u001b[A\n",
      " 67% 904/1348 [00:23<00:11, 38.07it/s]\u001b[A\n",
      " 67% 908/1348 [00:23<00:11, 38.08it/s]\u001b[A\n",
      " 68% 912/1348 [00:23<00:11, 38.05it/s]\u001b[A\n",
      " 68% 916/1348 [00:23<00:11, 38.00it/s]\u001b[A\n",
      " 68% 920/1348 [00:24<00:11, 38.07it/s]\u001b[A\n",
      " 69% 924/1348 [00:24<00:11, 38.22it/s]\u001b[A\n",
      " 69% 928/1348 [00:24<00:10, 38.20it/s]\u001b[A\n",
      " 69% 932/1348 [00:24<00:10, 38.09it/s]\u001b[A\n",
      " 69% 936/1348 [00:24<00:10, 38.07it/s]\u001b[A\n",
      " 70% 940/1348 [00:24<00:10, 38.05it/s]\u001b[A\n",
      " 70% 944/1348 [00:24<00:10, 37.94it/s]\u001b[A\n",
      " 70% 948/1348 [00:24<00:10, 37.93it/s]\u001b[A\n",
      " 71% 952/1348 [00:24<00:10, 37.97it/s]\u001b[A\n",
      " 71% 956/1348 [00:24<00:10, 38.12it/s]\u001b[A\n",
      " 71% 960/1348 [00:25<00:10, 38.14it/s]\u001b[A\n",
      " 72% 964/1348 [00:25<00:10, 38.14it/s]\u001b[A\n",
      " 72% 968/1348 [00:25<00:09, 38.11it/s]\u001b[A\n",
      " 72% 972/1348 [00:25<00:09, 38.12it/s]\u001b[A\n",
      " 72% 976/1348 [00:25<00:09, 37.96it/s]\u001b[A\n",
      " 73% 980/1348 [00:25<00:09, 38.01it/s]\u001b[A\n",
      " 73% 984/1348 [00:25<00:09, 38.10it/s]\u001b[A\n",
      " 73% 988/1348 [00:25<00:09, 37.98it/s]\u001b[A\n",
      " 74% 992/1348 [00:25<00:09, 37.97it/s]\u001b[A\n",
      " 74% 996/1348 [00:26<00:09, 37.80it/s]\u001b[A\n",
      " 74% 1000/1348 [00:26<00:09, 38.01it/s]\u001b[A\n",
      " 74% 1004/1348 [00:26<00:09, 38.19it/s]\u001b[A\n",
      " 75% 1008/1348 [00:26<00:08, 38.20it/s]\u001b[A\n",
      " 75% 1012/1348 [00:26<00:08, 37.81it/s]\u001b[A\n",
      " 75% 1016/1348 [00:26<00:08, 38.04it/s]\u001b[A\n",
      " 76% 1020/1348 [00:26<00:08, 38.12it/s]\u001b[A\n",
      " 76% 1024/1348 [00:26<00:08, 37.97it/s]\u001b[A\n",
      " 76% 1028/1348 [00:26<00:08, 37.91it/s]\u001b[A\n",
      " 77% 1032/1348 [00:26<00:08, 37.92it/s]\u001b[A\n",
      " 77% 1036/1348 [00:27<00:08, 37.90it/s]\u001b[A\n",
      " 77% 1040/1348 [00:27<00:08, 37.95it/s]\u001b[A\n",
      " 77% 1044/1348 [00:27<00:07, 38.04it/s]\u001b[A\n",
      " 78% 1048/1348 [00:27<00:07, 38.05it/s]\u001b[A\n",
      " 78% 1052/1348 [00:27<00:07, 37.88it/s]\u001b[A\n",
      " 78% 1056/1348 [00:27<00:07, 37.32it/s]\u001b[A\n",
      " 79% 1060/1348 [00:27<00:07, 37.46it/s]\u001b[A\n",
      " 79% 1064/1348 [00:27<00:07, 37.52it/s]\u001b[A\n",
      " 79% 1068/1348 [00:27<00:07, 37.42it/s]\u001b[A\n",
      " 80% 1072/1348 [00:28<00:07, 37.47it/s]\u001b[A\n",
      " 80% 1076/1348 [00:28<00:07, 37.40it/s]\u001b[A\n",
      " 80% 1080/1348 [00:28<00:07, 37.55it/s]\u001b[A\n",
      " 80% 1084/1348 [00:28<00:07, 37.62it/s]\u001b[A\n",
      " 81% 1088/1348 [00:28<00:06, 37.84it/s]\u001b[A\n",
      " 81% 1092/1348 [00:28<00:06, 37.70it/s]\u001b[A\n",
      " 81% 1096/1348 [00:28<00:06, 37.79it/s]\u001b[A\n",
      " 82% 1100/1348 [00:28<00:06, 37.76it/s]\u001b[A\n",
      " 82% 1104/1348 [00:28<00:06, 37.75it/s]\u001b[A\n",
      " 82% 1108/1348 [00:28<00:06, 37.92it/s]\u001b[A\n",
      " 82% 1112/1348 [00:29<00:06, 38.04it/s]\u001b[A\n",
      " 83% 1116/1348 [00:29<00:06, 38.04it/s]\u001b[A\n",
      " 83% 1120/1348 [00:29<00:06, 37.91it/s]\u001b[A\n",
      " 83% 1124/1348 [00:29<00:05, 38.12it/s]\u001b[A\n",
      " 84% 1128/1348 [00:29<00:05, 38.05it/s]\u001b[A\n",
      " 84% 1132/1348 [00:29<00:05, 37.88it/s]\u001b[A\n",
      " 84% 1136/1348 [00:29<00:05, 37.79it/s]\u001b[A\n",
      " 85% 1140/1348 [00:29<00:05, 37.85it/s]\u001b[A\n",
      " 85% 1144/1348 [00:29<00:05, 37.64it/s]\u001b[A\n",
      " 85% 1148/1348 [00:30<00:05, 37.68it/s]\u001b[A\n",
      " 85% 1152/1348 [00:30<00:05, 37.82it/s]\u001b[A\n",
      " 86% 1156/1348 [00:30<00:05, 37.75it/s]\u001b[A\n",
      " 86% 1160/1348 [00:30<00:04, 37.98it/s]\u001b[A\n",
      " 86% 1164/1348 [00:30<00:04, 38.03it/s]\u001b[A\n",
      " 87% 1168/1348 [00:30<00:04, 38.02it/s]\u001b[A\n",
      " 87% 1172/1348 [00:30<00:04, 37.68it/s]\u001b[A\n",
      " 87% 1176/1348 [00:30<00:04, 37.53it/s]\u001b[A\n",
      " 88% 1180/1348 [00:30<00:04, 37.60it/s]\u001b[A\n",
      " 88% 1184/1348 [00:30<00:04, 37.49it/s]\u001b[A\n",
      " 88% 1188/1348 [00:31<00:04, 37.55it/s]\u001b[A\n",
      " 88% 1192/1348 [00:31<00:04, 37.67it/s]\u001b[A\n",
      " 89% 1196/1348 [00:31<00:04, 37.68it/s]\u001b[A\n",
      " 89% 1200/1348 [00:31<00:03, 37.73it/s]\u001b[A\n",
      " 89% 1204/1348 [00:31<00:03, 38.03it/s]\u001b[A\n",
      " 90% 1208/1348 [00:31<00:03, 37.96it/s]\u001b[A\n",
      " 90% 1212/1348 [00:31<00:03, 37.71it/s]\u001b[A\n",
      " 90% 1216/1348 [00:31<00:03, 37.80it/s]\u001b[A\n",
      " 91% 1220/1348 [00:31<00:03, 37.82it/s]\u001b[A\n",
      " 91% 1224/1348 [00:32<00:03, 37.72it/s]\u001b[A\n",
      " 91% 1228/1348 [00:32<00:03, 37.73it/s]\u001b[A\n",
      " 91% 1232/1348 [00:32<00:03, 37.99it/s]\u001b[A\n",
      " 92% 1236/1348 [00:32<00:02, 38.05it/s]\u001b[A\n",
      " 92% 1240/1348 [00:32<00:02, 38.19it/s]\u001b[A\n",
      " 92% 1244/1348 [00:32<00:02, 38.10it/s]\u001b[A\n",
      " 93% 1248/1348 [00:32<00:02, 38.10it/s]\u001b[A\n",
      " 93% 1252/1348 [00:32<00:02, 38.09it/s]\u001b[A\n",
      " 93% 1256/1348 [00:32<00:02, 37.84it/s]\u001b[A\n",
      " 93% 1260/1348 [00:32<00:02, 37.72it/s]\u001b[A\n",
      " 94% 1264/1348 [00:33<00:02, 37.83it/s]\u001b[A\n",
      " 94% 1268/1348 [00:33<00:02, 37.70it/s]\u001b[A\n",
      " 94% 1272/1348 [00:33<00:02, 37.72it/s]\u001b[A\n",
      " 95% 1276/1348 [00:33<00:01, 37.98it/s]\u001b[A\n",
      " 95% 1280/1348 [00:33<00:01, 38.14it/s]\u001b[A\n",
      " 95% 1284/1348 [00:33<00:01, 38.02it/s]\u001b[A\n",
      " 96% 1288/1348 [00:33<00:01, 37.83it/s]\u001b[A\n",
      " 96% 1292/1348 [00:33<00:01, 37.93it/s]\u001b[A\n",
      " 96% 1296/1348 [00:33<00:01, 37.97it/s]\u001b[A\n",
      " 96% 1300/1348 [00:34<00:01, 38.04it/s]\u001b[A\n",
      " 97% 1304/1348 [00:34<00:01, 37.98it/s]\u001b[A\n",
      " 97% 1308/1348 [00:34<00:01, 38.01it/s]\u001b[A\n",
      " 97% 1312/1348 [00:34<00:00, 37.72it/s]\u001b[A\n",
      " 98% 1316/1348 [00:34<00:00, 37.62it/s]\u001b[A\n",
      " 98% 1320/1348 [00:34<00:00, 37.75it/s]\u001b[A\n",
      " 98% 1324/1348 [00:34<00:00, 37.65it/s]\u001b[A\n",
      " 99% 1328/1348 [00:34<00:00, 37.66it/s]\u001b[A\n",
      " 99% 1332/1348 [00:34<00:00, 37.44it/s]\u001b[A\n",
      " 99% 1336/1348 [00:35<00:00, 37.41it/s]\u001b[A\n",
      " 99% 1340/1348 [00:35<00:00, 37.55it/s]\u001b[A\n",
      "100% 1344/1348 [00:35<00:00, 37.64it/s]\u001b[A\n",
      "100% 1348/1348 [00:45<00:00, 37.64it/s]\u001b[A11/18/2024 00:38:16 - INFO - utils_qa - Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 34/10570 [00:00<00:31, 332.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 69/10570 [00:00<00:30, 342.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 105/10570 [00:00<00:30, 348.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 142/10570 [00:00<00:29, 354.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 178/10570 [00:00<00:29, 349.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 213/10570 [00:00<00:30, 342.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 248/10570 [00:00<00:32, 320.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 281/10570 [00:00<00:38, 266.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 315/10570 [00:01<00:35, 284.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 351/10570 [00:01<00:33, 304.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 386/10570 [00:01<00:32, 316.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 419/10570 [00:01<00:31, 318.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 454/10570 [00:01<00:31, 325.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 489/10570 [00:01<00:30, 332.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 523/10570 [00:01<00:30, 332.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 557/10570 [00:01<00:29, 334.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 592/10570 [00:01<00:29, 336.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 626/10570 [00:01<00:30, 331.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 661/10570 [00:02<00:29, 335.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 697/10570 [00:02<00:29, 340.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 732/10570 [00:02<00:29, 336.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 766/10570 [00:02<00:29, 334.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 800/10570 [00:02<00:30, 325.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 833/10570 [00:02<00:30, 317.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 867/10570 [00:02<00:29, 323.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 901/10570 [00:02<00:29, 325.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 934/10570 [00:02<00:30, 317.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 967/10570 [00:02<00:30, 318.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 1000/10570 [00:03<00:29, 319.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1033/10570 [00:03<00:29, 320.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1066/10570 [00:03<00:29, 322.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1099/10570 [00:03<00:30, 314.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1133/10570 [00:03<00:29, 322.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1168/10570 [00:03<00:28, 327.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1203/10570 [00:03<00:28, 332.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1238/10570 [00:03<00:27, 337.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1272/10570 [00:03<00:27, 332.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1307/10570 [00:04<00:27, 337.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1341/10570 [00:04<00:27, 337.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1375/10570 [00:04<00:27, 336.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1409/10570 [00:04<00:27, 333.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1443/10570 [00:04<00:27, 331.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1477/10570 [00:04<00:27, 329.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1512/10570 [00:04<00:27, 333.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1546/10570 [00:04<00:26, 334.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1580/10570 [00:04<00:26, 336.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1614/10570 [00:04<00:26, 335.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1648/10570 [00:05<00:26, 335.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1684/10570 [00:05<00:25, 342.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1719/10570 [00:05<00:25, 341.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1754/10570 [00:05<00:26, 338.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1789/10570 [00:05<00:25, 341.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1824/10570 [00:05<00:25, 340.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1859/10570 [00:05<00:26, 323.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1892/10570 [00:05<00:27, 320.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1925/10570 [00:05<00:27, 318.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 1957/10570 [00:05<00:27, 310.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 1989/10570 [00:06<00:27, 310.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2021/10570 [00:06<00:28, 302.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2052/10570 [00:06<00:27, 304.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2084/10570 [00:06<00:27, 306.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2118/10570 [00:06<00:26, 314.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2150/10570 [00:06<00:29, 287.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2180/10570 [00:06<00:29, 285.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2210/10570 [00:06<00:29, 287.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2241/10570 [00:06<00:28, 292.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2275/10570 [00:07<00:27, 305.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2309/10570 [00:07<00:26, 314.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2343/10570 [00:07<00:25, 321.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2377/10570 [00:07<00:25, 325.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2410/10570 [00:07<00:25, 325.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2444/10570 [00:07<00:24, 328.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2477/10570 [00:07<00:24, 325.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2510/10570 [00:07<00:26, 308.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2542/10570 [00:07<00:25, 309.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2574/10570 [00:07<00:25, 309.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2609/10570 [00:08<00:24, 318.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2643/10570 [00:08<00:24, 324.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2678/10570 [00:08<00:24, 328.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2712/10570 [00:08<00:23, 331.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2746/10570 [00:08<00:23, 333.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2782/10570 [00:08<00:22, 339.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2817/10570 [00:08<00:22, 340.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2852/10570 [00:08<00:22, 337.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2886/10570 [00:08<00:23, 332.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2920/10570 [00:09<00:22, 332.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2954/10570 [00:09<00:22, 333.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2988/10570 [00:09<00:22, 333.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3022/10570 [00:09<00:22, 333.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3056/10570 [00:09<00:22, 334.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3090/10570 [00:09<00:22, 330.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3124/10570 [00:09<00:22, 330.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3158/10570 [00:09<00:22, 327.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3191/10570 [00:09<00:22, 326.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3224/10570 [00:09<00:22, 326.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3257/10570 [00:10<00:22, 325.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3290/10570 [00:10<00:22, 324.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3324/10570 [00:10<00:22, 326.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3357/10570 [00:10<00:22, 325.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3391/10570 [00:10<00:21, 327.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3424/10570 [00:10<00:21, 327.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3457/10570 [00:10<00:21, 324.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3490/10570 [00:10<00:21, 322.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3523/10570 [00:10<00:21, 322.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3556/10570 [00:10<00:21, 324.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3589/10570 [00:11<00:21, 321.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3622/10570 [00:11<00:21, 323.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3656/10570 [00:11<00:21, 325.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3690/10570 [00:11<00:20, 327.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3723/10570 [00:11<00:20, 327.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3756/10570 [00:11<00:20, 324.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3789/10570 [00:11<00:20, 325.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3822/10570 [00:11<00:21, 321.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3855/10570 [00:11<00:20, 320.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3888/10570 [00:11<00:20, 323.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3921/10570 [00:12<00:20, 318.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3954/10570 [00:12<00:20, 319.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 3986/10570 [00:12<00:20, 317.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4018/10570 [00:12<00:20, 317.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4051/10570 [00:12<00:20, 317.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4085/10570 [00:12<00:20, 322.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4118/10570 [00:12<00:20, 316.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4150/10570 [00:12<00:23, 270.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4179/10570 [00:12<00:24, 265.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4207/10570 [00:13<00:27, 232.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4238/10570 [00:13<00:25, 250.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4265/10570 [00:13<00:27, 233.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4290/10570 [00:13<00:32, 194.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4312/10570 [00:13<00:34, 181.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4345/10570 [00:13<00:28, 215.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4378/10570 [00:13<00:25, 243.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4411/10570 [00:14<00:23, 264.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4445/10570 [00:14<00:21, 283.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4479/10570 [00:14<00:20, 298.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4511/10570 [00:14<00:20, 301.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4543/10570 [00:14<00:19, 305.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4576/10570 [00:14<00:19, 309.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4608/10570 [00:14<00:19, 300.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4641/10570 [00:14<00:19, 304.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4672/10570 [00:14<00:20, 294.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4707/10570 [00:14<00:19, 307.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4741/10570 [00:15<00:18, 314.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4773/10570 [00:15<00:19, 301.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4806/10570 [00:15<00:18, 308.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4840/10570 [00:15<00:18, 316.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4872/10570 [00:15<00:19, 297.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4906/10570 [00:15<00:18, 307.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4940/10570 [00:15<00:17, 314.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4973/10570 [00:15<00:17, 316.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 5005/10570 [00:15<00:17, 316.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5038/10570 [00:16<00:17, 318.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5072/10570 [00:16<00:17, 321.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5105/10570 [00:16<00:16, 321.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5139/10570 [00:16<00:16, 325.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5172/10570 [00:16<00:16, 318.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5204/10570 [00:16<00:17, 306.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5237/10570 [00:16<00:17, 311.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5270/10570 [00:16<00:16, 315.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5305/10570 [00:16<00:16, 322.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5338/10570 [00:16<00:16, 324.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5371/10570 [00:17<00:16, 324.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5405/10570 [00:17<00:15, 327.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5438/10570 [00:17<00:15, 327.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5471/10570 [00:17<00:16, 305.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5502/10570 [00:17<00:17, 295.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5534/10570 [00:17<00:16, 300.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5567/10570 [00:17<00:16, 306.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5600/10570 [00:17<00:15, 312.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5632/10570 [00:17<00:15, 311.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5664/10570 [00:18<00:16, 300.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5698/10570 [00:18<00:15, 311.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5732/10570 [00:18<00:15, 316.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5765/10570 [00:18<00:15, 318.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5797/10570 [00:18<00:15, 316.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5830/10570 [00:18<00:14, 319.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5862/10570 [00:18<00:14, 319.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5896/10570 [00:18<00:14, 323.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5929/10570 [00:18<00:14, 322.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5962/10570 [00:18<00:14, 322.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 5995/10570 [00:19<00:14, 309.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6027/10570 [00:19<00:15, 296.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6058/10570 [00:19<00:15, 297.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6090/10570 [00:19<00:14, 303.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6123/10570 [00:19<00:14, 309.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6156/10570 [00:19<00:13, 315.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6189/10570 [00:19<00:13, 318.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6221/10570 [00:19<00:13, 318.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6253/10570 [00:19<00:14, 304.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6286/10570 [00:20<00:13, 310.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6320/10570 [00:20<00:13, 316.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6353/10570 [00:20<00:13, 317.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6385/10570 [00:20<00:13, 305.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6418/10570 [00:20<00:13, 311.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6452/10570 [00:20<00:12, 319.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6485/10570 [00:20<00:12, 321.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6518/10570 [00:20<00:13, 310.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6550/10570 [00:20<00:13, 302.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6581/10570 [00:20<00:13, 295.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6611/10570 [00:21<00:13, 288.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6641/10570 [00:21<00:13, 289.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6671/10570 [00:21<00:13, 287.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6700/10570 [00:21<00:13, 283.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6732/10570 [00:21<00:13, 293.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6766/10570 [00:21<00:12, 306.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6799/10570 [00:21<00:12, 311.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6831/10570 [00:21<00:11, 312.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6863/10570 [00:21<00:11, 312.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6896/10570 [00:21<00:11, 315.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6929/10570 [00:22<00:11, 319.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6963/10570 [00:22<00:11, 323.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6997/10570 [00:22<00:10, 327.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7030/10570 [00:22<00:10, 327.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7063/10570 [00:22<00:10, 326.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7096/10570 [00:22<00:10, 325.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7129/10570 [00:22<00:10, 326.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7163/10570 [00:22<00:10, 328.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7196/10570 [00:22<00:10, 324.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7229/10570 [00:23<00:10, 321.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7262/10570 [00:23<00:10, 318.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7295/10570 [00:23<00:10, 320.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7328/10570 [00:23<00:10, 321.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7361/10570 [00:23<00:10, 293.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7393/10570 [00:23<00:10, 299.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7427/10570 [00:23<00:10, 310.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7459/10570 [00:23<00:09, 312.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7492/10570 [00:23<00:09, 315.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7525/10570 [00:23<00:09, 319.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7558/10570 [00:24<00:09, 320.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7592/10570 [00:24<00:09, 323.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7625/10570 [00:24<00:09, 320.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7658/10570 [00:24<00:09, 306.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7691/10570 [00:24<00:09, 311.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7724/10570 [00:24<00:09, 315.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7756/10570 [00:24<00:09, 305.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7787/10570 [00:24<00:09, 305.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7819/10570 [00:24<00:08, 308.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7851/10570 [00:25<00:08, 311.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7885/10570 [00:25<00:08, 317.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7919/10570 [00:25<00:08, 322.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7953/10570 [00:25<00:08, 324.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 7986/10570 [00:25<00:08, 322.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8019/10570 [00:25<00:07, 324.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8052/10570 [00:25<00:07, 317.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8086/10570 [00:25<00:07, 321.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8119/10570 [00:25<00:07, 322.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8152/10570 [00:25<00:07, 306.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8183/10570 [00:26<00:08, 295.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8213/10570 [00:26<00:08, 286.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8242/10570 [00:26<00:08, 280.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8271/10570 [00:26<00:08, 277.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8299/10570 [00:26<00:08, 274.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8331/10570 [00:26<00:07, 285.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8364/10570 [00:26<00:07, 298.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8398/10570 [00:26<00:07, 309.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8430/10570 [00:26<00:06, 311.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8464/10570 [00:27<00:06, 319.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8497/10570 [00:27<00:06, 321.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8530/10570 [00:27<00:06, 320.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8563/10570 [00:27<00:06, 315.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8596/10570 [00:27<00:06, 318.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8630/10570 [00:27<00:05, 323.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8663/10570 [00:27<00:05, 323.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8697/10570 [00:27<00:05, 327.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8730/10570 [00:27<00:05, 324.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8763/10570 [00:27<00:05, 316.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8795/10570 [00:28<00:05, 317.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8828/10570 [00:28<00:05, 320.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8861/10570 [00:28<00:05, 322.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8894/10570 [00:28<00:05, 323.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8927/10570 [00:28<00:05, 324.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8960/10570 [00:28<00:04, 325.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8994/10570 [00:28<00:04, 327.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 9027/10570 [00:28<00:04, 327.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9060/10570 [00:28<00:04, 325.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9093/10570 [00:28<00:04, 320.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9126/10570 [00:29<00:04, 321.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9159/10570 [00:29<00:04, 322.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9192/10570 [00:29<00:04, 322.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9225/10570 [00:29<00:04, 315.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9260/10570 [00:29<00:04, 322.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9293/10570 [00:29<00:04, 314.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9326/10570 [00:29<00:03, 316.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9358/10570 [00:29<00:03, 317.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9390/10570 [00:29<00:03, 314.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9423/10570 [00:30<00:03, 317.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9457/10570 [00:30<00:03, 321.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9490/10570 [00:30<00:03, 322.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9523/10570 [00:30<00:03, 323.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9557/10570 [00:30<00:03, 327.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9590/10570 [00:30<00:03, 324.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9623/10570 [00:30<00:02, 317.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9656/10570 [00:30<00:02, 318.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9689/10570 [00:30<00:02, 321.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9722/10570 [00:30<00:02, 321.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9756/10570 [00:31<00:02, 326.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9790/10570 [00:31<00:02, 327.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9824/10570 [00:31<00:02, 329.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9857/10570 [00:31<00:02, 324.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9891/10570 [00:31<00:02, 327.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9924/10570 [00:31<00:01, 328.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9958/10570 [00:31<00:01, 330.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 9992/10570 [00:31<00:01, 324.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10026/10570 [00:31<00:01, 327.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10059/10570 [00:31<00:01, 324.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10092/10570 [00:32<00:01, 322.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10126/10570 [00:32<00:01, 326.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10159/10570 [00:32<00:01, 326.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10192/10570 [00:32<00:01, 316.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10226/10570 [00:32<00:01, 322.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10259/10570 [00:32<00:00, 323.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10292/10570 [00:32<00:00, 324.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10325/10570 [00:32<00:00, 325.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10358/10570 [00:32<00:00, 326.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10391/10570 [00:32<00:00, 325.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10424/10570 [00:33<00:00, 325.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10457/10570 [00:33<00:00, 325.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10490/10570 [00:33<00:00, 323.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10524/10570 [00:33<00:00, 327.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10570/10570 [00:33<00:00, 315.27it/s]\n",
      "11/18/2024 00:38:50 - INFO - utils_qa - Saving predictions to ./output_qa/eval_predictions.json.\n",
      "11/18/2024 00:38:50 - INFO - utils_qa - Saving nbest_preds to ./output_qa/eval_nbest_predictions.json.\n",
      "                                     \n",
      "\u001b[A{'eval_exact_match': 58.85525070955534, 'eval_f1': 70.51326127279906, 'eval_runtime': 35.4001, 'eval_samples_per_second': 304.632, 'eval_steps_per_second': 38.079, 'epoch': 1.0}\n",
      " 50% 317/634 [02:27<00:55,  5.68it/s]\n",
      "100% 1348/1348 [01:26<00:00, 37.64it/s]\u001b[A\n",
      "{'loss': 2.4549, 'grad_norm': 15.61973762512207, 'learning_rate': 7.157894736842105e-06, 'epoch': 1.58}\n",
      "100% 634/634 [03:30<00:00,  5.63it/s][INFO|trainer.py:3812] 2024-11-18 00:39:58,352 >> Saving model checkpoint to ./output_qa/checkpoint-634\n",
      "[INFO|configuration_utils.py:414] 2024-11-18 00:39:58,358 >> Configuration saved in ./output_qa/checkpoint-634/config.json\n",
      "[INFO|modeling_utils.py:3035] 2024-11-18 00:39:59,644 >> Model weights saved in ./output_qa/checkpoint-634/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-18 00:39:59,649 >> tokenizer config file saved in ./output_qa/checkpoint-634/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-18 00:39:59,652 >> Special tokens file saved in ./output_qa/checkpoint-634/special_tokens_map.json\n",
      "[INFO|trainer.py:875] 2024-11-18 00:40:01,877 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4128] 2024-11-18 00:40:01,880 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4130] 2024-11-18 00:40:01,881 >>   Num examples = 10784\n",
      "[INFO|trainer.py:4133] 2024-11-18 00:40:01,881 >>   Batch size = 8\n",
      "\n",
      "  0% 0/1348 [00:00<?, ?it/s]\u001b[A\n",
      "  0% 6/1348 [00:00<00:27, 48.33it/s]\u001b[A\n",
      "  1% 11/1348 [00:00<00:31, 42.98it/s]\u001b[A\n",
      "  1% 16/1348 [00:00<00:32, 41.26it/s]\u001b[A\n",
      "  2% 21/1348 [00:00<00:32, 40.61it/s]\u001b[A\n",
      "  2% 26/1348 [00:00<00:33, 39.99it/s]\u001b[A\n",
      "  2% 31/1348 [00:00<00:33, 39.68it/s]\u001b[A\n",
      "  3% 35/1348 [00:00<00:33, 39.39it/s]\u001b[A\n",
      "  3% 39/1348 [00:00<00:33, 39.06it/s]\u001b[A\n",
      "  3% 43/1348 [00:01<00:33, 38.77it/s]\u001b[A\n",
      "  3% 47/1348 [00:01<00:33, 38.73it/s]\u001b[A\n",
      "  4% 51/1348 [00:01<00:33, 38.70it/s]\u001b[A\n",
      "  4% 55/1348 [00:01<00:33, 38.85it/s]\u001b[A\n",
      "  4% 59/1348 [00:01<00:33, 38.91it/s]\u001b[A\n",
      "  5% 63/1348 [00:01<00:32, 39.04it/s]\u001b[A\n",
      "  5% 67/1348 [00:01<00:32, 39.15it/s]\u001b[A\n",
      "  5% 71/1348 [00:01<00:32, 39.19it/s]\u001b[A\n",
      "  6% 75/1348 [00:01<00:32, 39.11it/s]\u001b[A\n",
      "  6% 79/1348 [00:01<00:32, 38.81it/s]\u001b[A\n",
      "  6% 83/1348 [00:02<00:32, 38.81it/s]\u001b[A\n",
      "  6% 87/1348 [00:02<00:32, 38.88it/s]\u001b[A\n",
      "  7% 91/1348 [00:02<00:32, 38.90it/s]\u001b[A\n",
      "  7% 95/1348 [00:02<00:32, 38.97it/s]\u001b[A\n",
      "  7% 99/1348 [00:02<00:32, 38.84it/s]\u001b[A\n",
      "  8% 103/1348 [00:02<00:32, 38.80it/s]\u001b[A\n",
      "  8% 107/1348 [00:02<00:32, 38.40it/s]\u001b[A\n",
      "  8% 111/1348 [00:02<00:31, 38.70it/s]\u001b[A\n",
      "  9% 115/1348 [00:02<00:31, 38.75it/s]\u001b[A\n",
      "  9% 119/1348 [00:03<00:31, 38.61it/s]\u001b[A\n",
      "  9% 123/1348 [00:03<00:31, 38.55it/s]\u001b[A\n",
      "  9% 127/1348 [00:03<00:31, 38.63it/s]\u001b[A\n",
      " 10% 131/1348 [00:03<00:31, 38.64it/s]\u001b[A\n",
      " 10% 135/1348 [00:03<00:31, 38.83it/s]\u001b[A\n",
      " 10% 139/1348 [00:03<00:31, 38.93it/s]\u001b[A\n",
      " 11% 143/1348 [00:03<00:31, 38.57it/s]\u001b[A\n",
      " 11% 147/1348 [00:03<00:31, 37.95it/s]\u001b[A\n",
      " 11% 151/1348 [00:03<00:31, 38.21it/s]\u001b[A\n",
      " 11% 155/1348 [00:03<00:31, 37.67it/s]\u001b[A\n",
      " 12% 159/1348 [00:04<00:31, 37.19it/s]\u001b[A\n",
      " 12% 163/1348 [00:04<00:31, 37.42it/s]\u001b[A\n",
      " 12% 167/1348 [00:04<00:31, 37.71it/s]\u001b[A\n",
      " 13% 171/1348 [00:04<00:30, 38.06it/s]\u001b[A\n",
      " 13% 175/1348 [00:04<00:30, 37.99it/s]\u001b[A\n",
      " 13% 179/1348 [00:04<00:30, 37.77it/s]\u001b[A\n",
      " 14% 183/1348 [00:04<00:30, 38.02it/s]\u001b[A\n",
      " 14% 187/1348 [00:04<00:30, 38.09it/s]\u001b[A\n",
      " 14% 191/1348 [00:04<00:30, 38.02it/s]\u001b[A\n",
      " 14% 195/1348 [00:05<00:30, 37.89it/s]\u001b[A\n",
      " 15% 199/1348 [00:05<00:30, 38.25it/s]\u001b[A\n",
      " 15% 203/1348 [00:05<00:29, 38.25it/s]\u001b[A\n",
      " 15% 207/1348 [00:05<00:29, 38.64it/s]\u001b[A\n",
      " 16% 211/1348 [00:05<00:29, 38.78it/s]\u001b[A\n",
      " 16% 215/1348 [00:05<00:29, 38.97it/s]\u001b[A\n",
      " 16% 219/1348 [00:05<00:28, 38.94it/s]\u001b[A\n",
      " 17% 223/1348 [00:05<00:29, 38.76it/s]\u001b[A\n",
      " 17% 227/1348 [00:05<00:29, 38.61it/s]\u001b[A\n",
      " 17% 231/1348 [00:05<00:29, 38.33it/s]\u001b[A\n",
      " 17% 235/1348 [00:06<00:28, 38.57it/s]\u001b[A\n",
      " 18% 239/1348 [00:06<00:28, 38.70it/s]\u001b[A\n",
      " 18% 243/1348 [00:06<00:28, 38.60it/s]\u001b[A\n",
      " 18% 247/1348 [00:06<00:28, 38.72it/s]\u001b[A\n",
      " 19% 251/1348 [00:06<00:28, 38.88it/s]\u001b[A\n",
      " 19% 255/1348 [00:06<00:28, 38.81it/s]\u001b[A\n",
      " 19% 259/1348 [00:06<00:28, 38.70it/s]\u001b[A\n",
      " 20% 263/1348 [00:06<00:28, 38.63it/s]\u001b[A\n",
      " 20% 267/1348 [00:06<00:28, 38.40it/s]\u001b[A\n",
      " 20% 271/1348 [00:06<00:28, 38.45it/s]\u001b[A\n",
      " 20% 275/1348 [00:07<00:27, 38.54it/s]\u001b[A\n",
      " 21% 279/1348 [00:07<00:27, 38.78it/s]\u001b[A\n",
      " 21% 283/1348 [00:07<00:27, 38.26it/s]\u001b[A\n",
      " 21% 287/1348 [00:07<00:27, 38.07it/s]\u001b[A\n",
      " 22% 291/1348 [00:07<00:27, 38.13it/s]\u001b[A\n",
      " 22% 295/1348 [00:07<00:28, 37.16it/s]\u001b[A\n",
      " 22% 299/1348 [00:07<00:28, 37.19it/s]\u001b[A\n",
      " 22% 303/1348 [00:07<00:28, 37.19it/s]\u001b[A\n",
      " 23% 307/1348 [00:07<00:28, 37.16it/s]\u001b[A\n",
      " 23% 311/1348 [00:08<00:27, 37.09it/s]\u001b[A\n",
      " 23% 315/1348 [00:08<00:27, 37.02it/s]\u001b[A\n",
      " 24% 319/1348 [00:08<00:27, 37.37it/s]\u001b[A\n",
      " 24% 323/1348 [00:08<00:27, 37.78it/s]\u001b[A\n",
      " 24% 327/1348 [00:08<00:26, 37.92it/s]\u001b[A\n",
      " 25% 331/1348 [00:08<00:26, 37.72it/s]\u001b[A\n",
      " 25% 335/1348 [00:08<00:26, 37.64it/s]\u001b[A\n",
      " 25% 339/1348 [00:08<00:27, 36.85it/s]\u001b[A\n",
      " 25% 343/1348 [00:08<00:27, 37.09it/s]\u001b[A\n",
      " 26% 347/1348 [00:09<00:26, 37.39it/s]\u001b[A\n",
      " 26% 351/1348 [00:09<00:26, 37.62it/s]\u001b[A\n",
      " 26% 355/1348 [00:09<00:26, 37.93it/s]\u001b[A\n",
      " 27% 359/1348 [00:09<00:26, 37.77it/s]\u001b[A\n",
      " 27% 363/1348 [00:09<00:25, 38.03it/s]\u001b[A\n",
      " 27% 367/1348 [00:09<00:25, 37.74it/s]\u001b[A\n",
      " 28% 371/1348 [00:09<00:26, 37.28it/s]\u001b[A\n",
      " 28% 375/1348 [00:09<00:25, 37.70it/s]\u001b[A\n",
      " 28% 379/1348 [00:09<00:26, 37.25it/s]\u001b[A\n",
      " 28% 383/1348 [00:09<00:25, 37.78it/s]\u001b[A\n",
      " 29% 387/1348 [00:10<00:25, 38.14it/s]\u001b[A\n",
      " 29% 391/1348 [00:10<00:24, 38.33it/s]\u001b[A\n",
      " 29% 395/1348 [00:10<00:24, 38.40it/s]\u001b[A\n",
      " 30% 399/1348 [00:10<00:24, 38.38it/s]\u001b[A\n",
      " 30% 403/1348 [00:10<00:24, 38.26it/s]\u001b[A\n",
      " 30% 407/1348 [00:10<00:24, 38.36it/s]\u001b[A\n",
      " 30% 411/1348 [00:10<00:24, 38.49it/s]\u001b[A\n",
      " 31% 415/1348 [00:10<00:24, 38.42it/s]\u001b[A\n",
      " 31% 419/1348 [00:10<00:24, 38.61it/s]\u001b[A\n",
      " 31% 423/1348 [00:11<00:23, 38.56it/s]\u001b[A\n",
      " 32% 427/1348 [00:11<00:23, 38.73it/s]\u001b[A\n",
      " 32% 431/1348 [00:11<00:23, 38.77it/s]\u001b[A\n",
      " 32% 435/1348 [00:11<00:23, 38.77it/s]\u001b[A\n",
      " 33% 439/1348 [00:11<00:23, 38.70it/s]\u001b[A\n",
      " 33% 443/1348 [00:11<00:23, 38.58it/s]\u001b[A\n",
      " 33% 447/1348 [00:11<00:23, 38.37it/s]\u001b[A\n",
      " 33% 451/1348 [00:11<00:23, 38.17it/s]\u001b[A\n",
      " 34% 455/1348 [00:11<00:23, 38.06it/s]\u001b[A\n",
      " 34% 459/1348 [00:11<00:23, 38.10it/s]\u001b[A\n",
      " 34% 463/1348 [00:12<00:23, 38.15it/s]\u001b[A\n",
      " 35% 467/1348 [00:12<00:22, 38.48it/s]\u001b[A\n",
      " 35% 471/1348 [00:12<00:22, 38.58it/s]\u001b[A\n",
      " 35% 475/1348 [00:12<00:22, 38.03it/s]\u001b[A\n",
      " 36% 479/1348 [00:12<00:22, 38.07it/s]\u001b[A\n",
      " 36% 483/1348 [00:12<00:26, 32.95it/s]\u001b[A\n",
      " 36% 487/1348 [00:12<00:24, 34.71it/s]\u001b[A\n",
      " 36% 491/1348 [00:12<00:23, 35.93it/s]\u001b[A\n",
      " 37% 495/1348 [00:12<00:23, 36.52it/s]\u001b[A\n",
      " 37% 499/1348 [00:13<00:23, 36.70it/s]\u001b[A\n",
      " 37% 503/1348 [00:13<00:22, 37.06it/s]\u001b[A\n",
      " 38% 507/1348 [00:13<00:22, 37.67it/s]\u001b[A\n",
      " 38% 511/1348 [00:13<00:21, 38.11it/s]\u001b[A\n",
      " 38% 515/1348 [00:13<00:21, 38.42it/s]\u001b[A\n",
      " 39% 519/1348 [00:13<00:21, 37.91it/s]\u001b[A\n",
      " 39% 523/1348 [00:13<00:21, 37.67it/s]\u001b[A\n",
      " 39% 527/1348 [00:13<00:21, 37.86it/s]\u001b[A\n",
      " 39% 531/1348 [00:13<00:21, 37.77it/s]\u001b[A\n",
      " 40% 535/1348 [00:13<00:21, 37.82it/s]\u001b[A\n",
      " 40% 539/1348 [00:14<00:21, 38.21it/s]\u001b[A\n",
      " 40% 543/1348 [00:14<00:21, 38.21it/s]\u001b[A\n",
      " 41% 547/1348 [00:14<00:21, 37.88it/s]\u001b[A\n",
      " 41% 551/1348 [00:14<00:20, 37.95it/s]\u001b[A\n",
      " 41% 555/1348 [00:14<00:20, 37.95it/s]\u001b[A\n",
      " 41% 559/1348 [00:14<00:20, 37.72it/s]\u001b[A\n",
      " 42% 563/1348 [00:14<00:20, 37.86it/s]\u001b[A\n",
      " 42% 567/1348 [00:14<00:20, 38.05it/s]\u001b[A\n",
      " 42% 571/1348 [00:14<00:20, 38.02it/s]\u001b[A\n",
      " 43% 575/1348 [00:15<00:20, 38.34it/s]\u001b[A\n",
      " 43% 579/1348 [00:15<00:20, 38.33it/s]\u001b[A\n",
      " 43% 583/1348 [00:15<00:19, 38.31it/s]\u001b[A\n",
      " 44% 587/1348 [00:15<00:19, 38.55it/s]\u001b[A\n",
      " 44% 591/1348 [00:15<00:19, 38.54it/s]\u001b[A\n",
      " 44% 595/1348 [00:15<00:19, 38.63it/s]\u001b[A\n",
      " 44% 599/1348 [00:15<00:19, 38.38it/s]\u001b[A\n",
      " 45% 603/1348 [00:15<00:19, 38.27it/s]\u001b[A\n",
      " 45% 607/1348 [00:15<00:19, 38.34it/s]\u001b[A\n",
      " 45% 611/1348 [00:15<00:19, 38.52it/s]\u001b[A\n",
      " 46% 615/1348 [00:16<00:19, 38.58it/s]\u001b[A\n",
      " 46% 619/1348 [00:16<00:19, 38.36it/s]\u001b[A\n",
      " 46% 623/1348 [00:16<00:18, 38.35it/s]\u001b[A\n",
      " 47% 627/1348 [00:16<00:18, 38.43it/s]\u001b[A\n",
      " 47% 631/1348 [00:16<00:18, 38.65it/s]\u001b[A\n",
      " 47% 635/1348 [00:16<00:18, 38.80it/s]\u001b[A\n",
      " 47% 639/1348 [00:16<00:18, 38.51it/s]\u001b[A\n",
      " 48% 643/1348 [00:16<00:18, 38.58it/s]\u001b[A\n",
      " 48% 647/1348 [00:16<00:18, 38.06it/s]\u001b[A\n",
      " 48% 651/1348 [00:17<00:18, 37.77it/s]\u001b[A\n",
      " 49% 655/1348 [00:17<00:18, 38.26it/s]\u001b[A\n",
      " 49% 659/1348 [00:17<00:17, 38.43it/s]\u001b[A\n",
      " 49% 663/1348 [00:17<00:17, 38.64it/s]\u001b[A\n",
      " 49% 667/1348 [00:17<00:17, 38.76it/s]\u001b[A\n",
      " 50% 671/1348 [00:17<00:17, 38.52it/s]\u001b[A\n",
      " 50% 675/1348 [00:17<00:17, 38.44it/s]\u001b[A\n",
      " 50% 679/1348 [00:17<00:17, 37.95it/s]\u001b[A\n",
      " 51% 683/1348 [00:17<00:17, 37.66it/s]\u001b[A\n",
      " 51% 687/1348 [00:17<00:17, 37.83it/s]\u001b[A\n",
      " 51% 691/1348 [00:18<00:17, 37.67it/s]\u001b[A\n",
      " 52% 695/1348 [00:18<00:17, 37.85it/s]\u001b[A\n",
      " 52% 699/1348 [00:18<00:17, 37.66it/s]\u001b[A\n",
      " 52% 703/1348 [00:18<00:16, 37.95it/s]\u001b[A\n",
      " 52% 707/1348 [00:18<00:16, 38.24it/s]\u001b[A\n",
      " 53% 711/1348 [00:18<00:16, 38.18it/s]\u001b[A\n",
      " 53% 715/1348 [00:18<00:16, 38.31it/s]\u001b[A\n",
      " 53% 719/1348 [00:18<00:16, 38.35it/s]\u001b[A\n",
      " 54% 723/1348 [00:18<00:16, 38.47it/s]\u001b[A\n",
      " 54% 727/1348 [00:19<00:16, 38.44it/s]\u001b[A\n",
      " 54% 731/1348 [00:19<00:15, 38.65it/s]\u001b[A\n",
      " 55% 735/1348 [00:19<00:15, 38.78it/s]\u001b[A\n",
      " 55% 739/1348 [00:19<00:15, 38.97it/s]\u001b[A\n",
      " 55% 743/1348 [00:19<00:15, 38.99it/s]\u001b[A\n",
      " 55% 747/1348 [00:19<00:15, 38.88it/s]\u001b[A\n",
      " 56% 751/1348 [00:19<00:15, 38.71it/s]\u001b[A\n",
      " 56% 755/1348 [00:19<00:15, 38.53it/s]\u001b[A\n",
      " 56% 759/1348 [00:19<00:15, 38.47it/s]\u001b[A\n",
      " 57% 763/1348 [00:19<00:15, 38.59it/s]\u001b[A\n",
      " 57% 767/1348 [00:20<00:14, 38.77it/s]\u001b[A\n",
      " 57% 771/1348 [00:20<00:14, 38.89it/s]\u001b[A\n",
      " 57% 775/1348 [00:20<00:14, 38.94it/s]\u001b[A\n",
      " 58% 779/1348 [00:20<00:14, 38.98it/s]\u001b[A\n",
      " 58% 783/1348 [00:20<00:14, 38.89it/s]\u001b[A\n",
      " 58% 787/1348 [00:20<00:14, 38.88it/s]\u001b[A\n",
      " 59% 791/1348 [00:20<00:14, 38.83it/s]\u001b[A\n",
      " 59% 795/1348 [00:20<00:14, 38.69it/s]\u001b[A\n",
      " 59% 799/1348 [00:20<00:14, 38.62it/s]\u001b[A\n",
      " 60% 803/1348 [00:20<00:14, 38.36it/s]\u001b[A\n",
      " 60% 807/1348 [00:21<00:14, 38.51it/s]\u001b[A\n",
      " 60% 811/1348 [00:21<00:13, 38.76it/s]\u001b[A\n",
      " 60% 815/1348 [00:21<00:13, 38.82it/s]\u001b[A\n",
      " 61% 819/1348 [00:21<00:13, 38.79it/s]\u001b[A\n",
      " 61% 823/1348 [00:21<00:13, 38.82it/s]\u001b[A\n",
      " 61% 827/1348 [00:21<00:13, 38.68it/s]\u001b[A\n",
      " 62% 831/1348 [00:21<00:13, 38.68it/s]\u001b[A\n",
      " 62% 835/1348 [00:21<00:13, 38.62it/s]\u001b[A\n",
      " 62% 839/1348 [00:21<00:13, 38.44it/s]\u001b[A\n",
      " 63% 843/1348 [00:22<00:13, 38.55it/s]\u001b[A\n",
      " 63% 847/1348 [00:22<00:12, 38.60it/s]\u001b[A\n",
      " 63% 851/1348 [00:22<00:12, 38.76it/s]\u001b[A\n",
      " 63% 855/1348 [00:22<00:12, 38.83it/s]\u001b[A\n",
      " 64% 859/1348 [00:22<00:12, 38.79it/s]\u001b[A\n",
      " 64% 863/1348 [00:22<00:12, 38.77it/s]\u001b[A\n",
      " 64% 867/1348 [00:22<00:12, 38.48it/s]\u001b[A\n",
      " 65% 871/1348 [00:22<00:12, 38.37it/s]\u001b[A\n",
      " 65% 875/1348 [00:22<00:12, 38.45it/s]\u001b[A\n",
      " 65% 879/1348 [00:22<00:12, 38.53it/s]\u001b[A\n",
      " 66% 883/1348 [00:23<00:12, 38.70it/s]\u001b[A\n",
      " 66% 887/1348 [00:23<00:11, 38.85it/s]\u001b[A\n",
      " 66% 891/1348 [00:23<00:11, 38.47it/s]\u001b[A\n",
      " 66% 895/1348 [00:23<00:11, 38.65it/s]\u001b[A\n",
      " 67% 899/1348 [00:23<00:11, 38.67it/s]\u001b[A\n",
      " 67% 903/1348 [00:23<00:11, 38.55it/s]\u001b[A\n",
      " 67% 907/1348 [00:23<00:11, 38.29it/s]\u001b[A\n",
      " 68% 911/1348 [00:23<00:11, 38.32it/s]\u001b[A\n",
      " 68% 915/1348 [00:23<00:11, 38.47it/s]\u001b[A\n",
      " 68% 919/1348 [00:23<00:11, 38.50it/s]\u001b[A\n",
      " 68% 923/1348 [00:24<00:11, 38.63it/s]\u001b[A\n",
      " 69% 927/1348 [00:24<00:10, 38.61it/s]\u001b[A\n",
      " 69% 931/1348 [00:24<00:10, 38.73it/s]\u001b[A\n",
      " 69% 935/1348 [00:24<00:10, 38.82it/s]\u001b[A\n",
      " 70% 939/1348 [00:24<00:10, 38.70it/s]\u001b[A\n",
      " 70% 943/1348 [00:24<00:10, 38.72it/s]\u001b[A\n",
      " 70% 947/1348 [00:24<00:10, 38.69it/s]\u001b[A\n",
      " 71% 951/1348 [00:24<00:10, 38.57it/s]\u001b[A\n",
      " 71% 955/1348 [00:24<00:10, 38.59it/s]\u001b[A\n",
      " 71% 959/1348 [00:25<00:10, 38.54it/s]\u001b[A\n",
      " 71% 963/1348 [00:25<00:09, 38.77it/s]\u001b[A\n",
      " 72% 967/1348 [00:25<00:09, 38.86it/s]\u001b[A\n",
      " 72% 971/1348 [00:25<00:09, 39.06it/s]\u001b[A\n",
      " 72% 975/1348 [00:25<00:09, 39.02it/s]\u001b[A\n",
      " 73% 979/1348 [00:25<00:09, 38.79it/s]\u001b[A\n",
      " 73% 983/1348 [00:25<00:09, 38.78it/s]\u001b[A\n",
      " 73% 987/1348 [00:25<00:09, 38.57it/s]\u001b[A\n",
      " 74% 991/1348 [00:25<00:09, 38.64it/s]\u001b[A\n",
      " 74% 995/1348 [00:25<00:09, 38.70it/s]\u001b[A\n",
      " 74% 999/1348 [00:26<00:09, 38.60it/s]\u001b[A\n",
      " 74% 1003/1348 [00:26<00:08, 38.64it/s]\u001b[A\n",
      " 75% 1007/1348 [00:26<00:08, 38.62it/s]\u001b[A\n",
      " 75% 1011/1348 [00:26<00:08, 38.82it/s]\u001b[A\n",
      " 75% 1015/1348 [00:26<00:08, 38.89it/s]\u001b[A\n",
      " 76% 1019/1348 [00:26<00:08, 38.64it/s]\u001b[A\n",
      " 76% 1023/1348 [00:26<00:08, 38.64it/s]\u001b[A\n",
      " 76% 1027/1348 [00:26<00:08, 38.11it/s]\u001b[A\n",
      " 76% 1031/1348 [00:26<00:08, 38.36it/s]\u001b[A\n",
      " 77% 1035/1348 [00:26<00:08, 38.46it/s]\u001b[A\n",
      " 77% 1039/1348 [00:27<00:07, 38.65it/s]\u001b[A\n",
      " 77% 1043/1348 [00:27<00:07, 38.69it/s]\u001b[A\n",
      " 78% 1047/1348 [00:27<00:07, 38.63it/s]\u001b[A\n",
      " 78% 1051/1348 [00:27<00:07, 38.51it/s]\u001b[A\n",
      " 78% 1055/1348 [00:27<00:07, 38.54it/s]\u001b[A\n",
      " 79% 1059/1348 [00:27<00:07, 38.16it/s]\u001b[A\n",
      " 79% 1063/1348 [00:27<00:07, 38.24it/s]\u001b[A\n",
      " 79% 1067/1348 [00:27<00:07, 38.34it/s]\u001b[A\n",
      " 79% 1071/1348 [00:27<00:07, 38.51it/s]\u001b[A\n",
      " 80% 1075/1348 [00:28<00:07, 38.61it/s]\u001b[A\n",
      " 80% 1079/1348 [00:28<00:06, 38.71it/s]\u001b[A\n",
      " 80% 1083/1348 [00:28<00:06, 38.72it/s]\u001b[A\n",
      " 81% 1087/1348 [00:28<00:06, 38.76it/s]\u001b[A\n",
      " 81% 1091/1348 [00:28<00:06, 38.62it/s]\u001b[A\n",
      " 81% 1095/1348 [00:28<00:06, 38.70it/s]\u001b[A\n",
      " 82% 1099/1348 [00:28<00:06, 38.77it/s]\u001b[A\n",
      " 82% 1103/1348 [00:28<00:06, 38.87it/s]\u001b[A\n",
      " 82% 1107/1348 [00:28<00:06, 38.89it/s]\u001b[A\n",
      " 82% 1111/1348 [00:28<00:06, 38.60it/s]\u001b[A\n",
      " 83% 1115/1348 [00:29<00:06, 38.45it/s]\u001b[A\n",
      " 83% 1119/1348 [00:29<00:05, 38.52it/s]\u001b[A\n",
      " 83% 1123/1348 [00:29<00:05, 38.72it/s]\u001b[A\n",
      " 84% 1127/1348 [00:29<00:05, 38.79it/s]\u001b[A\n",
      " 84% 1131/1348 [00:29<00:05, 38.63it/s]\u001b[A\n",
      " 84% 1135/1348 [00:29<00:05, 38.73it/s]\u001b[A\n",
      " 84% 1139/1348 [00:29<00:05, 38.84it/s]\u001b[A\n",
      " 85% 1143/1348 [00:29<00:05, 38.78it/s]\u001b[A\n",
      " 85% 1147/1348 [00:29<00:05, 38.74it/s]\u001b[A\n",
      " 85% 1151/1348 [00:29<00:05, 38.84it/s]\u001b[A\n",
      " 86% 1155/1348 [00:30<00:04, 38.76it/s]\u001b[A\n",
      " 86% 1159/1348 [00:30<00:04, 38.60it/s]\u001b[A\n",
      " 86% 1163/1348 [00:30<00:04, 38.44it/s]\u001b[A\n",
      " 87% 1167/1348 [00:30<00:04, 38.44it/s]\u001b[A\n",
      " 87% 1171/1348 [00:30<00:04, 38.52it/s]\u001b[A\n",
      " 87% 1175/1348 [00:30<00:04, 38.51it/s]\u001b[A\n",
      " 87% 1179/1348 [00:30<00:04, 38.63it/s]\u001b[A\n",
      " 88% 1183/1348 [00:30<00:04, 38.67it/s]\u001b[A\n",
      " 88% 1187/1348 [00:30<00:04, 38.67it/s]\u001b[A\n",
      " 88% 1191/1348 [00:31<00:04, 38.76it/s]\u001b[A\n",
      " 89% 1195/1348 [00:31<00:03, 38.83it/s]\u001b[A\n",
      " 89% 1199/1348 [00:31<00:03, 38.66it/s]\u001b[A\n",
      " 89% 1203/1348 [00:31<00:03, 38.28it/s]\u001b[A\n",
      " 90% 1207/1348 [00:31<00:03, 38.47it/s]\u001b[A\n",
      " 90% 1211/1348 [00:31<00:03, 38.56it/s]\u001b[A\n",
      " 90% 1215/1348 [00:31<00:03, 38.59it/s]\u001b[A\n",
      " 90% 1219/1348 [00:31<00:03, 38.36it/s]\u001b[A\n",
      " 91% 1223/1348 [00:31<00:03, 38.31it/s]\u001b[A\n",
      " 91% 1227/1348 [00:31<00:03, 38.34it/s]\u001b[A\n",
      " 91% 1231/1348 [00:32<00:03, 38.48it/s]\u001b[A\n",
      " 92% 1235/1348 [00:32<00:02, 38.51it/s]\u001b[A\n",
      " 92% 1239/1348 [00:32<00:02, 38.51it/s]\u001b[A\n",
      " 92% 1243/1348 [00:32<00:02, 38.58it/s]\u001b[A\n",
      " 93% 1247/1348 [00:32<00:02, 38.53it/s]\u001b[A\n",
      " 93% 1251/1348 [00:32<00:02, 38.73it/s]\u001b[A\n",
      " 93% 1255/1348 [00:32<00:02, 38.78it/s]\u001b[A\n",
      " 93% 1259/1348 [00:32<00:02, 38.69it/s]\u001b[A\n",
      " 94% 1263/1348 [00:32<00:02, 38.50it/s]\u001b[A\n",
      " 94% 1267/1348 [00:32<00:02, 38.41it/s]\u001b[A\n",
      " 94% 1271/1348 [00:33<00:01, 38.65it/s]\u001b[A\n",
      " 95% 1275/1348 [00:33<00:01, 38.70it/s]\u001b[A\n",
      " 95% 1279/1348 [00:33<00:01, 38.78it/s]\u001b[A\n",
      " 95% 1283/1348 [00:33<00:01, 38.78it/s]\u001b[A\n",
      " 95% 1287/1348 [00:33<00:01, 38.75it/s]\u001b[A\n",
      " 96% 1291/1348 [00:33<00:01, 38.70it/s]\u001b[A\n",
      " 96% 1295/1348 [00:33<00:01, 38.76it/s]\u001b[A\n",
      " 96% 1299/1348 [00:33<00:01, 38.81it/s]\u001b[A\n",
      " 97% 1303/1348 [00:33<00:01, 38.78it/s]\u001b[A\n",
      " 97% 1307/1348 [00:34<00:01, 38.46it/s]\u001b[A\n",
      " 97% 1311/1348 [00:34<00:00, 38.60it/s]\u001b[A\n",
      " 98% 1315/1348 [00:34<00:00, 38.50it/s]\u001b[A\n",
      " 98% 1319/1348 [00:34<00:00, 38.51it/s]\u001b[A\n",
      " 98% 1323/1348 [00:34<00:00, 38.57it/s]\u001b[A\n",
      " 98% 1327/1348 [00:34<00:00, 38.65it/s]\u001b[A\n",
      " 99% 1331/1348 [00:34<00:00, 38.57it/s]\u001b[A\n",
      " 99% 1335/1348 [00:34<00:00, 38.25it/s]\u001b[A\n",
      " 99% 1339/1348 [00:34<00:00, 38.25it/s]\u001b[A\n",
      "100% 1343/1348 [00:34<00:00, 38.34it/s]\u001b[A\n",
      "100% 1347/1348 [00:35<00:00, 38.38it/s]\u001b[A\n",
      "100% 1348/1348 [00:45<00:00, 38.38it/s]\u001b[A11/18/2024 00:40:49 - INFO - utils_qa - Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 33/10570 [00:00<00:32, 327.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 68/10570 [00:00<00:31, 337.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 103/10570 [00:00<00:30, 343.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 140/10570 [00:00<00:29, 350.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 176/10570 [00:00<00:29, 347.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 211/10570 [00:00<00:30, 342.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 246/10570 [00:00<00:31, 324.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 279/10570 [00:00<00:38, 268.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 313/10570 [00:01<00:35, 285.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 349/10570 [00:01<00:33, 303.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 385/10570 [00:01<00:32, 317.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 418/10570 [00:01<00:33, 303.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 450/10570 [00:01<00:33, 302.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 481/10570 [00:01<00:33, 297.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 512/10570 [00:01<00:34, 292.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 543/10570 [00:01<00:33, 295.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 573/10570 [00:01<00:34, 293.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 603/10570 [00:01<00:34, 285.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 637/10570 [00:02<00:33, 299.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 669/10570 [00:02<00:32, 303.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 703/10570 [00:02<00:31, 314.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 736/10570 [00:02<00:30, 317.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 769/10570 [00:02<00:30, 319.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 802/10570 [00:02<00:30, 315.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 834/10570 [00:02<00:31, 309.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 868/10570 [00:02<00:30, 316.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 901/10570 [00:02<00:30, 320.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 934/10570 [00:03<00:30, 313.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 966/10570 [00:03<00:30, 314.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 998/10570 [00:03<00:31, 306.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1030/10570 [00:03<00:30, 310.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1062/10570 [00:03<00:30, 309.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1094/10570 [00:03<00:30, 311.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1126/10570 [00:03<00:30, 311.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1158/10570 [00:03<00:30, 313.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1193/10570 [00:03<00:29, 323.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1226/10570 [00:03<00:29, 320.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1259/10570 [00:04<00:29, 320.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1292/10570 [00:04<00:29, 316.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1326/10570 [00:04<00:28, 321.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1361/10570 [00:04<00:28, 327.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1394/10570 [00:04<00:28, 323.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1427/10570 [00:04<00:28, 325.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1462/10570 [00:04<00:27, 330.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1496/10570 [00:04<00:27, 332.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1530/10570 [00:04<00:27, 329.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1564/10570 [00:04<00:27, 330.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1598/10570 [00:05<00:27, 332.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1632/10570 [00:05<00:26, 332.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1668/10570 [00:05<00:26, 338.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1703/10570 [00:05<00:26, 340.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1738/10570 [00:05<00:27, 325.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1771/10570 [00:05<00:27, 315.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1803/10570 [00:05<00:28, 311.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1835/10570 [00:05<00:28, 304.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1866/10570 [00:05<00:28, 301.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1898/10570 [00:06<00:28, 305.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1933/10570 [00:06<00:27, 317.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 1968/10570 [00:06<00:26, 324.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2002/10570 [00:06<00:26, 328.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2036/10570 [00:06<00:25, 330.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2070/10570 [00:06<00:25, 332.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2105/10570 [00:06<00:25, 337.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2139/10570 [00:06<00:27, 305.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2172/10570 [00:06<00:27, 310.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2206/10570 [00:06<00:26, 317.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2241/10570 [00:07<00:25, 325.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2275/10570 [00:07<00:25, 327.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2309/10570 [00:07<00:25, 328.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2343/10570 [00:07<00:24, 330.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2377/10570 [00:07<00:25, 326.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2410/10570 [00:07<00:25, 323.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2443/10570 [00:07<00:25, 324.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2476/10570 [00:07<00:25, 321.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2509/10570 [00:07<00:26, 303.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2540/10570 [00:08<00:26, 304.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2571/10570 [00:08<00:26, 302.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2604/10570 [00:08<00:25, 310.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2638/10570 [00:08<00:25, 316.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2672/10570 [00:08<00:24, 321.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2705/10570 [00:08<00:24, 321.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2739/10570 [00:08<00:24, 324.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2774/10570 [00:08<00:23, 330.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2809/10570 [00:08<00:23, 334.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2843/10570 [00:08<00:23, 329.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2876/10570 [00:09<00:23, 327.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2909/10570 [00:09<00:23, 322.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2942/10570 [00:09<00:24, 317.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2974/10570 [00:09<00:25, 302.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 3005/10570 [00:09<00:25, 294.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3035/10570 [00:09<00:25, 293.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3065/10570 [00:09<00:26, 288.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3094/10570 [00:09<00:26, 285.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3123/10570 [00:09<00:26, 284.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3152/10570 [00:10<00:26, 280.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3185/10570 [00:10<00:25, 292.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3219/10570 [00:10<00:24, 303.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3251/10570 [00:10<00:23, 306.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3283/10570 [00:10<00:23, 310.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3317/10570 [00:10<00:22, 318.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3349/10570 [00:10<00:22, 315.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3383/10570 [00:10<00:22, 320.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3416/10570 [00:10<00:22, 321.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3450/10570 [00:10<00:21, 324.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3483/10570 [00:11<00:21, 324.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3516/10570 [00:11<00:21, 325.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3550/10570 [00:11<00:21, 328.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3583/10570 [00:11<00:21, 321.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3616/10570 [00:11<00:21, 322.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3649/10570 [00:11<00:21, 323.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3682/10570 [00:11<00:21, 325.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3715/10570 [00:11<00:20, 326.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3748/10570 [00:11<00:21, 323.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3783/10570 [00:11<00:20, 328.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3816/10570 [00:12<00:20, 325.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3849/10570 [00:12<00:20, 326.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3883/10570 [00:12<00:20, 327.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3916/10570 [00:12<00:20, 327.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3949/10570 [00:12<00:20, 326.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 3983/10570 [00:12<00:19, 329.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4016/10570 [00:12<00:20, 326.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4050/10570 [00:12<00:19, 328.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4083/10570 [00:12<00:19, 329.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4116/10570 [00:12<00:20, 318.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4148/10570 [00:13<00:22, 281.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4177/10570 [00:13<00:24, 264.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4205/10570 [00:13<00:27, 233.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4234/10570 [00:13<00:25, 246.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4261/10570 [00:13<00:25, 246.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4287/10570 [00:13<00:32, 195.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4309/10570 [00:13<00:33, 185.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4342/10570 [00:14<00:28, 217.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4375/10570 [00:14<00:25, 244.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4407/10570 [00:14<00:23, 264.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4441/10570 [00:14<00:21, 283.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4475/10570 [00:14<00:20, 298.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4507/10570 [00:14<00:20, 301.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4538/10570 [00:14<00:19, 303.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4571/10570 [00:14<00:19, 308.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4603/10570 [00:14<00:20, 297.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4635/10570 [00:15<00:19, 302.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4666/10570 [00:15<00:20, 291.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4699/10570 [00:15<00:19, 300.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4730/10570 [00:15<00:19, 300.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4761/10570 [00:15<00:20, 287.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4792/10570 [00:15<00:19, 292.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4826/10570 [00:15<00:18, 305.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4857/10570 [00:15<00:19, 285.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4891/10570 [00:15<00:18, 299.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4924/10570 [00:15<00:18, 307.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4957/10570 [00:16<00:17, 312.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4989/10570 [00:16<00:18, 308.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5021/10570 [00:16<00:18, 293.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5051/10570 [00:16<00:18, 290.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5081/10570 [00:16<00:19, 286.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5110/10570 [00:16<00:19, 286.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5139/10570 [00:16<00:18, 287.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5168/10570 [00:16<00:18, 286.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5197/10570 [00:16<00:18, 285.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5229/10570 [00:17<00:18, 292.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5262/10570 [00:17<00:17, 302.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5296/10570 [00:17<00:16, 312.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5330/10570 [00:17<00:16, 318.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5363/10570 [00:17<00:16, 320.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5396/10570 [00:17<00:15, 323.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5429/10570 [00:17<00:15, 321.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5462/10570 [00:17<00:17, 296.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5493/10570 [00:17<00:17, 289.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5525/10570 [00:17<00:17, 295.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5555/10570 [00:18<00:16, 296.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5585/10570 [00:18<00:17, 292.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5617/10570 [00:18<00:16, 299.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5649/10570 [00:18<00:16, 304.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5680/10570 [00:18<00:16, 296.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5714/10570 [00:18<00:15, 308.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5746/10570 [00:18<00:15, 311.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5779/10570 [00:18<00:15, 314.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5811/10570 [00:18<00:15, 306.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5845/10570 [00:19<00:15, 313.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5877/10570 [00:19<00:14, 315.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5910/10570 [00:19<00:14, 318.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5943/10570 [00:19<00:14, 319.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 5976/10570 [00:19<00:14, 320.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6009/10570 [00:19<00:14, 318.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6041/10570 [00:19<00:14, 317.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6073/10570 [00:19<00:14, 315.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6105/10570 [00:19<00:14, 316.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6138/10570 [00:19<00:13, 319.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6170/10570 [00:20<00:14, 313.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6203/10570 [00:20<00:13, 315.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6235/10570 [00:20<00:14, 302.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6268/10570 [00:20<00:13, 308.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6302/10570 [00:20<00:13, 315.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6335/10570 [00:20<00:13, 317.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6367/10570 [00:20<00:13, 316.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6399/10570 [00:20<00:13, 300.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6433/10570 [00:20<00:13, 310.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6467/10570 [00:20<00:12, 318.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6499/10570 [00:21<00:12, 318.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6531/10570 [00:21<00:12, 318.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6563/10570 [00:21<00:12, 310.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6595/10570 [00:21<00:13, 303.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6628/10570 [00:21<00:12, 308.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6661/10570 [00:21<00:12, 314.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6693/10570 [00:21<00:12, 311.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6725/10570 [00:21<00:12, 310.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6759/10570 [00:21<00:12, 316.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6792/10570 [00:22<00:11, 317.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6824/10570 [00:22<00:11, 315.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6856/10570 [00:22<00:11, 314.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6888/10570 [00:22<00:11, 313.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6920/10570 [00:22<00:11, 315.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6954/10570 [00:22<00:11, 321.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6988/10570 [00:22<00:11, 324.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 7022/10570 [00:22<00:10, 326.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7055/10570 [00:22<00:10, 325.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7088/10570 [00:22<00:10, 326.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7121/10570 [00:23<00:10, 321.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7154/10570 [00:23<00:10, 323.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7187/10570 [00:23<00:10, 323.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7220/10570 [00:23<00:10, 322.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7253/10570 [00:23<00:10, 322.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7286/10570 [00:23<00:10, 323.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7320/10570 [00:23<00:09, 326.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7353/10570 [00:23<00:10, 296.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7386/10570 [00:23<00:10, 302.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7419/10570 [00:24<00:10, 309.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7451/10570 [00:24<00:10, 307.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7483/10570 [00:24<00:10, 308.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7514/10570 [00:24<00:10, 305.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7547/10570 [00:24<00:09, 311.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7581/10570 [00:24<00:09, 317.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7614/10570 [00:24<00:09, 320.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7647/10570 [00:24<00:09, 315.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7679/10570 [00:24<00:09, 303.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7712/10570 [00:24<00:09, 310.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7745/10570 [00:25<00:09, 312.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7777/10570 [00:25<00:09, 303.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7810/10570 [00:25<00:08, 309.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7843/10570 [00:25<00:08, 313.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7876/10570 [00:25<00:08, 317.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7910/10570 [00:25<00:08, 322.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7944/10570 [00:25<00:08, 325.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7977/10570 [00:25<00:08, 323.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8010/10570 [00:25<00:07, 323.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8043/10570 [00:25<00:07, 323.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8076/10570 [00:26<00:07, 322.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8110/10570 [00:26<00:07, 326.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8143/10570 [00:26<00:07, 323.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8176/10570 [00:26<00:07, 319.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8208/10570 [00:26<00:08, 274.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8239/10570 [00:26<00:08, 283.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8271/10570 [00:26<00:07, 291.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8301/10570 [00:26<00:08, 277.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8333/10570 [00:26<00:07, 288.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8365/10570 [00:27<00:07, 296.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8399/10570 [00:27<00:07, 307.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8432/10570 [00:27<00:06, 314.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8466/10570 [00:27<00:06, 319.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8499/10570 [00:27<00:06, 313.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8532/10570 [00:27<00:06, 317.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8565/10570 [00:27<00:06, 319.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8598/10570 [00:27<00:06, 317.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8632/10570 [00:27<00:06, 321.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8665/10570 [00:28<00:05, 319.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8699/10570 [00:28<00:05, 323.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8732/10570 [00:28<00:05, 321.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8765/10570 [00:28<00:05, 318.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8797/10570 [00:28<00:05, 316.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8830/10570 [00:28<00:05, 318.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8863/10570 [00:28<00:05, 319.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8895/10570 [00:28<00:05, 319.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8928/10570 [00:28<00:05, 319.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8961/10570 [00:28<00:05, 320.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8994/10570 [00:29<00:04, 321.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 9027/10570 [00:29<00:05, 306.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9058/10570 [00:29<00:05, 297.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9088/10570 [00:29<00:05, 291.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9118/10570 [00:29<00:05, 285.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9147/10570 [00:29<00:05, 284.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9176/10570 [00:29<00:04, 281.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9205/10570 [00:29<00:04, 280.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9234/10570 [00:29<00:04, 281.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9264/10570 [00:30<00:04, 286.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9297/10570 [00:30<00:04, 297.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9327/10570 [00:30<00:04, 294.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9360/10570 [00:30<00:03, 303.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9392/10570 [00:30<00:03, 307.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9425/10570 [00:30<00:03, 313.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9459/10570 [00:30<00:03, 319.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9492/10570 [00:30<00:03, 321.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9526/10570 [00:30<00:03, 324.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9560/10570 [00:30<00:03, 327.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9593/10570 [00:31<00:02, 326.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9626/10570 [00:31<00:02, 325.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9659/10570 [00:31<00:02, 323.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9693/10570 [00:31<00:02, 326.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9727/10570 [00:31<00:02, 327.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9761/10570 [00:31<00:02, 330.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9795/10570 [00:31<00:02, 328.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9828/10570 [00:31<00:02, 328.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9861/10570 [00:31<00:02, 324.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9894/10570 [00:31<00:02, 323.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9927/10570 [00:32<00:01, 325.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9960/10570 [00:32<00:01, 326.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 9993/10570 [00:32<00:01, 321.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10027/10570 [00:32<00:01, 325.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10060/10570 [00:32<00:01, 325.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10093/10570 [00:32<00:01, 323.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10127/10570 [00:32<00:01, 326.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10160/10570 [00:32<00:01, 326.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10193/10570 [00:32<00:01, 315.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10227/10570 [00:32<00:01, 321.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10260/10570 [00:33<00:00, 321.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10293/10570 [00:33<00:00, 322.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10326/10570 [00:33<00:00, 323.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10359/10570 [00:33<00:00, 321.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10392/10570 [00:33<00:00, 319.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10424/10570 [00:33<00:00, 319.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10457/10570 [00:33<00:00, 319.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10490/10570 [00:33<00:00, 309.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10524/10570 [00:33<00:00, 317.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10570/10570 [00:34<00:00, 310.46it/s]\n",
      "11/18/2024 00:41:23 - INFO - utils_qa - Saving predictions to ./output_qa/eval_predictions.json.\n",
      "11/18/2024 00:41:23 - INFO - utils_qa - Saving nbest_preds to ./output_qa/eval_nbest_predictions.json.\n",
      "                                     \n",
      "\u001b[A{'eval_exact_match': 63.24503311258278, 'eval_f1': 74.4068923050673, 'eval_runtime': 35.1321, 'eval_samples_per_second': 306.956, 'eval_steps_per_second': 38.369, 'epoch': 2.0}\n",
      "100% 634/634 [05:00<00:00,  5.63it/s]\n",
      "100% 1348/1348 [01:25<00:00, 38.38it/s]\u001b[A\n",
      "                                       \u001b[A[INFO|trainer.py:2591] 2024-11-18 00:41:27,914 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 300.2751, 'train_samples_per_second': 33.742, 'train_steps_per_second': 2.111, 'train_loss': 2.2088672144555894, 'epoch': 2.0}\n",
      "100% 634/634 [05:00<00:00,  2.11it/s]\n",
      "[INFO|trainer.py:3812] 2024-11-18 00:41:27,917 >> Saving model checkpoint to ./output_qa\n",
      "[INFO|configuration_utils.py:414] 2024-11-18 00:41:27,974 >> Configuration saved in ./output_qa/config.json\n",
      "[INFO|modeling_utils.py:3035] 2024-11-18 00:41:29,225 >> Model weights saved in ./output_qa/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-11-18 00:41:29,230 >> tokenizer config file saved in ./output_qa/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-11-18 00:41:29,234 >> Special tokens file saved in ./output_qa/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  total_flos               =  1849228GF\n",
      "  train_loss               =     2.2089\n",
      "  train_runtime            = 0:05:00.27\n",
      "  train_samples            =       5066\n",
      "  train_samples_per_second =     33.742\n",
      "  train_steps_per_second   =      2.111\n",
      "11/18/2024 00:41:29 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:875] 2024-11-18 00:41:29,269 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4128] 2024-11-18 00:41:29,272 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4130] 2024-11-18 00:41:29,273 >>   Num examples = 10784\n",
      "[INFO|trainer.py:4133] 2024-11-18 00:41:29,273 >>   Batch size = 8\n",
      "100% 1348/1348 [00:45<00:00, 38.06it/s]11/18/2024 00:42:16 - INFO - utils_qa - Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\n",
      "  0% 34/10570 [00:00<00:31, 331.81it/s]\u001b[A\n",
      "  1% 69/10570 [00:00<00:30, 339.11it/s]\u001b[A\n",
      "  1% 104/10570 [00:00<00:30, 342.99it/s]\u001b[A\n",
      "  1% 140/10570 [00:00<00:29, 349.22it/s]\u001b[A\n",
      "  2% 176/10570 [00:00<00:29, 349.73it/s]\u001b[A\n",
      "  2% 211/10570 [00:00<00:30, 341.80it/s]\u001b[A\n",
      "  2% 246/10570 [00:00<00:36, 279.51it/s]\u001b[A\n",
      "  3% 276/10570 [00:00<00:42, 243.99it/s]\u001b[A\n",
      "  3% 308/10570 [00:01<00:39, 262.20it/s]\u001b[A\n",
      "  3% 343/10570 [00:01<00:35, 284.86it/s]\u001b[A\n",
      "  4% 378/10570 [00:01<00:33, 299.79it/s]\u001b[A\n",
      "  4% 411/10570 [00:01<00:33, 307.05it/s]\u001b[A\n",
      "  4% 446/10570 [00:01<00:31, 317.16it/s]\u001b[A\n",
      "  5% 481/10570 [00:01<00:31, 324.04it/s]\u001b[A\n",
      "  5% 515/10570 [00:01<00:30, 327.11it/s]\u001b[A\n",
      "  5% 550/10570 [00:01<00:30, 332.18it/s]\u001b[A\n",
      "  6% 584/10570 [00:01<00:29, 334.07it/s]\u001b[A\n",
      "  6% 618/10570 [00:01<00:30, 326.73it/s]\u001b[A\n",
      "  6% 653/10570 [00:02<00:29, 330.90it/s]\u001b[A\n",
      "  7% 688/10570 [00:02<00:29, 335.20it/s]\u001b[A\n",
      "  7% 722/10570 [00:02<00:29, 333.60it/s]\u001b[A\n",
      "  7% 756/10570 [00:02<00:29, 328.75it/s]\u001b[A\n",
      "  7% 789/10570 [00:02<00:29, 326.07it/s]\u001b[A\n",
      "  8% 822/10570 [00:02<00:30, 314.92it/s]\u001b[A\n",
      "  8% 854/10570 [00:02<00:30, 313.89it/s]\u001b[A\n",
      "  8% 889/10570 [00:02<00:30, 321.15it/s]\u001b[A\n",
      "  9% 922/10570 [00:02<00:31, 309.41it/s]\u001b[A\n",
      "  9% 956/10570 [00:03<00:30, 315.81it/s]\u001b[A\n",
      "  9% 988/10570 [00:03<00:30, 314.18it/s]\u001b[A\n",
      " 10% 1020/10570 [00:03<00:30, 315.45it/s]\u001b[A\n",
      " 10% 1052/10570 [00:03<00:30, 316.68it/s]\u001b[A\n",
      " 10% 1085/10570 [00:03<00:29, 318.13it/s]\u001b[A\n",
      " 11% 1117/10570 [00:03<00:30, 312.04it/s]\u001b[A\n",
      " 11% 1152/10570 [00:03<00:29, 320.58it/s]\u001b[A\n",
      " 11% 1185/10570 [00:03<00:29, 318.89it/s]\u001b[A\n",
      " 12% 1218/10570 [00:03<00:29, 321.64it/s]\u001b[A\n",
      " 12% 1251/10570 [00:03<00:29, 313.63it/s]\u001b[A\n",
      " 12% 1283/10570 [00:04<00:30, 305.33it/s]\u001b[A\n",
      " 12% 1314/10570 [00:04<00:30, 303.13it/s]\u001b[A\n",
      " 13% 1345/10570 [00:04<00:30, 301.00it/s]\u001b[A\n",
      " 13% 1376/10570 [00:04<00:31, 296.55it/s]\u001b[A\n",
      " 13% 1406/10570 [00:04<00:31, 288.10it/s]\u001b[A\n",
      " 14% 1436/10570 [00:04<00:31, 289.03it/s]\u001b[A\n",
      " 14% 1465/10570 [00:04<00:55, 165.42it/s]\u001b[A\n",
      " 14% 1500/10570 [00:05<00:45, 199.98it/s]\u001b[A\n",
      " 15% 1534/10570 [00:05<00:39, 229.49it/s]\u001b[A\n",
      " 15% 1569/10570 [00:05<00:35, 256.29it/s]\u001b[A\n",
      " 15% 1604/10570 [00:05<00:32, 278.63it/s]\u001b[A\n",
      " 15% 1638/10570 [00:05<00:30, 293.84it/s]\u001b[A\n",
      " 16% 1674/10570 [00:05<00:28, 310.06it/s]\u001b[A\n",
      " 16% 1709/10570 [00:05<00:27, 319.19it/s]\u001b[A\n",
      " 16% 1743/10570 [00:05<00:27, 321.54it/s]\u001b[A\n",
      " 17% 1778/10570 [00:05<00:26, 327.96it/s]\u001b[A\n",
      " 17% 1812/10570 [00:05<00:26, 330.72it/s]\u001b[A\n",
      " 17% 1846/10570 [00:06<00:26, 330.22it/s]\u001b[A\n",
      " 18% 1880/10570 [00:06<00:26, 331.28it/s]\u001b[A\n",
      " 18% 1916/10570 [00:06<00:25, 338.93it/s]\u001b[A\n",
      " 18% 1951/10570 [00:06<00:25, 339.21it/s]\u001b[A\n",
      " 19% 1986/10570 [00:06<00:25, 341.69it/s]\u001b[A\n",
      " 19% 2021/10570 [00:06<00:25, 337.03it/s]\u001b[A\n",
      " 19% 2056/10570 [00:06<00:25, 339.98it/s]\u001b[A\n",
      " 20% 2092/10570 [00:06<00:24, 343.77it/s]\u001b[A\n",
      " 20% 2127/10570 [00:06<00:27, 310.45it/s]\u001b[A\n",
      " 20% 2161/10570 [00:07<00:26, 316.36it/s]\u001b[A\n",
      " 21% 2195/10570 [00:07<00:26, 321.09it/s]\u001b[A\n",
      " 21% 2230/10570 [00:07<00:25, 327.98it/s]\u001b[A\n",
      " 21% 2264/10570 [00:07<00:25, 326.97it/s]\u001b[A\n",
      " 22% 2297/10570 [00:07<00:25, 327.79it/s]\u001b[A\n",
      " 22% 2330/10570 [00:07<00:25, 327.55it/s]\u001b[A\n",
      " 22% 2363/10570 [00:07<00:25, 324.32it/s]\u001b[A\n",
      " 23% 2396/10570 [00:07<00:25, 322.15it/s]\u001b[A\n",
      " 23% 2429/10570 [00:07<00:25, 323.88it/s]\u001b[A\n",
      " 23% 2462/10570 [00:07<00:26, 305.47it/s]\u001b[A\n",
      " 24% 2493/10570 [00:08<00:26, 300.37it/s]\u001b[A\n",
      " 24% 2524/10570 [00:08<00:29, 269.34it/s]\u001b[A\n",
      " 24% 2552/10570 [00:08<00:30, 267.21it/s]\u001b[A\n",
      " 24% 2580/10570 [00:08<00:29, 268.06it/s]\u001b[A\n",
      " 25% 2610/10570 [00:08<00:28, 275.11it/s]\u001b[A\n",
      " 25% 2641/10570 [00:08<00:28, 282.52it/s]\u001b[A\n",
      " 25% 2672/10570 [00:08<00:27, 288.84it/s]\u001b[A\n",
      " 26% 2703/10570 [00:08<00:26, 292.60it/s]\u001b[A\n",
      " 26% 2734/10570 [00:08<00:26, 295.86it/s]\u001b[A\n",
      " 26% 2765/10570 [00:09<00:26, 297.77it/s]\u001b[A\n",
      " 26% 2796/10570 [00:09<00:25, 300.81it/s]\u001b[A\n",
      " 27% 2827/10570 [00:09<00:25, 298.94it/s]\u001b[A\n",
      " 27% 2857/10570 [00:09<00:26, 294.97it/s]\u001b[A\n",
      " 27% 2887/10570 [00:09<00:27, 278.53it/s]\u001b[A\n",
      " 28% 2916/10570 [00:09<00:27, 280.23it/s]\u001b[A\n",
      " 28% 2947/10570 [00:09<00:26, 286.54it/s]\u001b[A\n",
      " 28% 2980/10570 [00:09<00:25, 298.73it/s]\u001b[A\n",
      " 29% 3014/10570 [00:09<00:24, 309.31it/s]\u001b[A\n",
      " 29% 3047/10570 [00:10<00:24, 313.28it/s]\u001b[A\n",
      " 29% 3081/10570 [00:10<00:23, 318.86it/s]\u001b[A\n",
      " 29% 3115/10570 [00:10<00:23, 323.22it/s]\u001b[A\n",
      " 30% 3148/10570 [00:10<00:22, 322.93it/s]\u001b[A\n",
      " 30% 3181/10570 [00:10<00:22, 323.30it/s]\u001b[A\n",
      " 30% 3214/10570 [00:10<00:22, 323.80it/s]\u001b[A\n",
      " 31% 3247/10570 [00:10<00:22, 322.97it/s]\u001b[A\n",
      " 31% 3280/10570 [00:10<00:22, 322.36it/s]\u001b[A\n",
      " 31% 3314/10570 [00:10<00:22, 326.13it/s]\u001b[A\n",
      " 32% 3348/10570 [00:10<00:22, 327.66it/s]\u001b[A\n",
      " 32% 3382/10570 [00:11<00:21, 328.80it/s]\u001b[A\n",
      " 32% 3415/10570 [00:11<00:21, 328.09it/s]\u001b[A\n",
      " 33% 3448/10570 [00:11<00:21, 328.42it/s]\u001b[A\n",
      " 33% 3481/10570 [00:11<00:21, 327.55it/s]\u001b[A\n",
      " 33% 3514/10570 [00:11<00:21, 327.12it/s]\u001b[A\n",
      " 34% 3549/10570 [00:11<00:21, 330.94it/s]\u001b[A\n",
      " 34% 3583/10570 [00:11<00:21, 324.51it/s]\u001b[A\n",
      " 34% 3616/10570 [00:11<00:21, 323.73it/s]\u001b[A\n",
      " 35% 3649/10570 [00:11<00:21, 323.55it/s]\u001b[A\n",
      " 35% 3682/10570 [00:11<00:21, 325.32it/s]\u001b[A\n",
      " 35% 3715/10570 [00:12<00:21, 324.91it/s]\u001b[A\n",
      " 35% 3748/10570 [00:12<00:21, 320.02it/s]\u001b[A\n",
      " 36% 3782/10570 [00:12<00:20, 325.53it/s]\u001b[A\n",
      " 36% 3815/10570 [00:12<00:20, 322.29it/s]\u001b[A\n",
      " 36% 3848/10570 [00:12<00:20, 323.37it/s]\u001b[A\n",
      " 37% 3881/10570 [00:12<00:20, 321.29it/s]\u001b[A\n",
      " 37% 3914/10570 [00:12<00:21, 314.88it/s]\u001b[A\n",
      " 37% 3947/10570 [00:12<00:20, 318.33it/s]\u001b[A\n",
      " 38% 3980/10570 [00:12<00:20, 319.63it/s]\u001b[A\n",
      " 38% 4013/10570 [00:12<00:20, 320.44it/s]\u001b[A\n",
      " 38% 4046/10570 [00:13<00:20, 322.75it/s]\u001b[A\n",
      " 39% 4080/10570 [00:13<00:19, 326.20it/s]\u001b[A\n",
      " 39% 4113/10570 [00:13<00:20, 319.18it/s]\u001b[A\n",
      " 39% 4145/10570 [00:13<00:21, 299.51it/s]\u001b[A\n",
      " 40% 4176/10570 [00:13<00:24, 264.17it/s]\u001b[A\n",
      " 40% 4204/10570 [00:13<00:26, 237.87it/s]\u001b[A\n",
      " 40% 4231/10570 [00:13<00:25, 244.97it/s]\u001b[A\n",
      " 40% 4259/10570 [00:13<00:25, 252.31it/s]\u001b[A\n",
      " 41% 4285/10570 [00:14<00:33, 189.24it/s]\u001b[A\n",
      " 41% 4307/10570 [00:14<00:34, 182.57it/s]\u001b[A\n",
      " 41% 4340/10570 [00:14<00:28, 215.10it/s]\u001b[A\n",
      " 41% 4373/10570 [00:14<00:25, 242.75it/s]\u001b[A\n",
      " 42% 4406/10570 [00:14<00:23, 264.09it/s]\u001b[A\n",
      " 42% 4440/10570 [00:14<00:21, 282.57it/s]\u001b[A\n",
      " 42% 4474/10570 [00:14<00:20, 297.05it/s]\u001b[A\n",
      " 43% 4505/10570 [00:14<00:20, 300.23it/s]\u001b[A\n",
      " 43% 4536/10570 [00:15<00:20, 293.32it/s]\u001b[A\n",
      " 43% 4569/10570 [00:15<00:19, 301.61it/s]\u001b[A\n",
      " 44% 4600/10570 [00:15<00:20, 291.54it/s]\u001b[A\n",
      " 44% 4633/10570 [00:15<00:19, 301.00it/s]\u001b[A\n",
      " 44% 4664/10570 [00:15<00:20, 290.83it/s]\u001b[A\n",
      " 44% 4694/10570 [00:15<00:20, 290.83it/s]\u001b[A\n",
      " 45% 4725/10570 [00:15<00:19, 295.28it/s]\u001b[A\n",
      " 45% 4755/10570 [00:15<00:19, 295.51it/s]\u001b[A\n",
      " 45% 4785/10570 [00:15<00:20, 287.99it/s]\u001b[A\n",
      " 46% 4819/10570 [00:15<00:19, 300.84it/s]\u001b[A\n",
      " 46% 4851/10570 [00:16<00:18, 303.64it/s]\u001b[A\n",
      " 46% 4882/10570 [00:16<00:19, 293.57it/s]\u001b[A\n",
      " 46% 4915/10570 [00:16<00:18, 303.85it/s]\u001b[A\n",
      " 47% 4948/10570 [00:16<00:18, 311.17it/s]\u001b[A\n",
      " 47% 4980/10570 [00:16<00:17, 313.48it/s]\u001b[A\n",
      " 47% 5012/10570 [00:16<00:17, 312.17it/s]\u001b[A\n",
      " 48% 5045/10570 [00:16<00:17, 316.17it/s]\u001b[A\n",
      " 48% 5077/10570 [00:16<00:17, 315.84it/s]\u001b[A\n",
      " 48% 5109/10570 [00:16<00:17, 310.42it/s]\u001b[A\n",
      " 49% 5141/10570 [00:17<00:18, 299.64it/s]\u001b[A\n",
      " 49% 5172/10570 [00:17<00:18, 291.90it/s]\u001b[A\n",
      " 49% 5202/10570 [00:17<00:18, 287.66it/s]\u001b[A\n",
      " 49% 5231/10570 [00:17<00:18, 286.21it/s]\u001b[A\n",
      " 50% 5260/10570 [00:17<00:18, 283.02it/s]\u001b[A\n",
      " 50% 5289/10570 [00:17<00:18, 284.90it/s]\u001b[A\n",
      " 50% 5319/10570 [00:17<00:18, 289.08it/s]\u001b[A\n",
      " 51% 5352/10570 [00:17<00:17, 299.61it/s]\u001b[A\n",
      " 51% 5386/10570 [00:17<00:16, 309.19it/s]\u001b[A\n",
      " 51% 5420/10570 [00:17<00:16, 315.73it/s]\u001b[A\n",
      " 52% 5452/10570 [00:18<00:16, 301.57it/s]\u001b[A\n",
      " 52% 5483/10570 [00:18<00:17, 291.87it/s]\u001b[A\n",
      " 52% 5514/10570 [00:18<00:17, 294.78it/s]\u001b[A\n",
      " 52% 5546/10570 [00:18<00:16, 301.54it/s]\u001b[A\n",
      " 53% 5578/10570 [00:18<00:16, 305.23it/s]\u001b[A\n",
      " 53% 5611/10570 [00:18<00:15, 310.34it/s]\u001b[A\n",
      " 53% 5643/10570 [00:18<00:15, 310.22it/s]\u001b[A\n",
      " 54% 5675/10570 [00:18<00:16, 301.42it/s]\u001b[A\n",
      " 54% 5708/10570 [00:18<00:15, 309.58it/s]\u001b[A\n",
      " 54% 5740/10570 [00:18<00:15, 311.95it/s]\u001b[A\n",
      " 55% 5772/10570 [00:19<00:15, 310.33it/s]\u001b[A\n",
      " 55% 5804/10570 [00:19<00:15, 312.84it/s]\u001b[A\n",
      " 55% 5837/10570 [00:19<00:14, 317.36it/s]\u001b[A\n",
      " 56% 5869/10570 [00:19<00:14, 314.26it/s]\u001b[A\n",
      " 56% 5902/10570 [00:19<00:14, 318.17it/s]\u001b[A\n",
      " 56% 5934/10570 [00:19<00:14, 309.99it/s]\u001b[A\n",
      " 56% 5968/10570 [00:19<00:14, 316.11it/s]\u001b[A\n",
      " 57% 6001/10570 [00:19<00:14, 317.47it/s]\u001b[A\n",
      " 57% 6033/10570 [00:19<00:15, 296.49it/s]\u001b[A\n",
      " 57% 6063/10570 [00:20<00:16, 279.30it/s]\u001b[A\n",
      " 58% 6092/10570 [00:20<00:16, 275.90it/s]\u001b[A\n",
      " 58% 6120/10570 [00:20<00:16, 276.21it/s]\u001b[A\n",
      " 58% 6149/10570 [00:20<00:15, 277.54it/s]\u001b[A\n",
      " 58% 6177/10570 [00:20<00:15, 276.71it/s]\u001b[A\n",
      " 59% 6205/10570 [00:20<00:15, 274.83it/s]\u001b[A\n",
      " 59% 6233/10570 [00:20<00:16, 258.88it/s]\u001b[A\n",
      " 59% 6262/10570 [00:20<00:16, 266.26it/s]\u001b[A\n",
      " 60% 6293/10570 [00:20<00:15, 277.65it/s]\u001b[A\n",
      " 60% 6326/10570 [00:21<00:14, 290.20it/s]\u001b[A\n",
      " 60% 6359/10570 [00:21<00:14, 299.80it/s]\u001b[A\n",
      " 60% 6390/10570 [00:21<00:14, 290.87it/s]\u001b[A\n",
      " 61% 6423/10570 [00:21<00:13, 302.00it/s]\u001b[A\n",
      " 61% 6457/10570 [00:21<00:13, 311.71it/s]\u001b[A\n",
      " 61% 6489/10570 [00:21<00:13, 313.49it/s]\u001b[A\n",
      " 62% 6521/10570 [00:21<00:12, 312.11it/s]\u001b[A\n",
      " 62% 6553/10570 [00:21<00:12, 312.82it/s]\u001b[A\n",
      " 62% 6585/10570 [00:21<00:12, 310.99it/s]\u001b[A\n",
      " 63% 6617/10570 [00:21<00:12, 310.05it/s]\u001b[A\n",
      " 63% 6650/10570 [00:22<00:12, 314.92it/s]\u001b[A\n",
      " 63% 6682/10570 [00:22<00:12, 311.34it/s]\u001b[A\n",
      " 64% 6714/10570 [00:22<00:12, 303.96it/s]\u001b[A\n",
      " 64% 6747/10570 [00:22<00:12, 309.83it/s]\u001b[A\n",
      " 64% 6780/10570 [00:22<00:12, 314.45it/s]\u001b[A\n",
      " 64% 6812/10570 [00:22<00:11, 315.53it/s]\u001b[A\n",
      " 65% 6844/10570 [00:22<00:11, 314.20it/s]\u001b[A\n",
      " 65% 6876/10570 [00:22<00:12, 305.79it/s]\u001b[A\n",
      " 65% 6908/10570 [00:22<00:11, 306.92it/s]\u001b[A\n",
      " 66% 6942/10570 [00:22<00:11, 315.32it/s]\u001b[A\n",
      " 66% 6975/10570 [00:23<00:11, 318.30it/s]\u001b[A\n",
      " 66% 7008/10570 [00:23<00:11, 320.69it/s]\u001b[A\n",
      " 67% 7041/10570 [00:23<00:10, 323.20it/s]\u001b[A\n",
      " 67% 7074/10570 [00:23<00:10, 323.62it/s]\u001b[A\n",
      " 67% 7107/10570 [00:23<00:10, 323.84it/s]\u001b[A\n",
      " 68% 7141/10570 [00:23<00:10, 327.67it/s]\u001b[A\n",
      " 68% 7174/10570 [00:23<00:10, 319.10it/s]\u001b[A\n",
      " 68% 7206/10570 [00:23<00:10, 317.88it/s]\u001b[A\n",
      " 68% 7239/10570 [00:23<00:10, 319.03it/s]\u001b[A\n",
      " 69% 7271/10570 [00:24<00:10, 314.20it/s]\u001b[A\n",
      " 69% 7304/10570 [00:24<00:10, 317.12it/s]\u001b[A\n",
      " 69% 7336/10570 [00:24<00:10, 303.15it/s]\u001b[A\n",
      " 70% 7367/10570 [00:24<00:10, 297.12it/s]\u001b[A\n",
      " 70% 7397/10570 [00:24<00:10, 292.69it/s]\u001b[A\n",
      " 70% 7431/10570 [00:24<00:10, 304.61it/s]\u001b[A\n",
      " 71% 7463/10570 [00:24<00:10, 307.07it/s]\u001b[A\n",
      " 71% 7494/10570 [00:24<00:10, 305.06it/s]\u001b[A\n",
      " 71% 7528/10570 [00:24<00:09, 313.13it/s]\u001b[A\n",
      " 72% 7561/10570 [00:24<00:09, 316.54it/s]\u001b[A\n",
      " 72% 7595/10570 [00:25<00:09, 321.05it/s]\u001b[A\n",
      " 72% 7628/10570 [00:25<00:09, 322.98it/s]\u001b[A\n",
      " 72% 7661/10570 [00:25<00:09, 300.18it/s]\u001b[A\n",
      " 73% 7695/10570 [00:25<00:09, 309.59it/s]\u001b[A\n",
      " 73% 7728/10570 [00:25<00:09, 315.06it/s]\u001b[A\n",
      " 73% 7760/10570 [00:25<00:09, 303.62it/s]\u001b[A\n",
      " 74% 7792/10570 [00:25<00:09, 307.63it/s]\u001b[A\n",
      " 74% 7824/10570 [00:25<00:08, 309.43it/s]\u001b[A\n",
      " 74% 7856/10570 [00:25<00:08, 312.28it/s]\u001b[A\n",
      " 75% 7889/10570 [00:26<00:08, 316.52it/s]\u001b[A\n",
      " 75% 7923/10570 [00:26<00:08, 320.86it/s]\u001b[A\n",
      " 75% 7956/10570 [00:26<00:08, 318.88it/s]\u001b[A\n",
      " 76% 7989/10570 [00:26<00:08, 319.29it/s]\u001b[A\n",
      " 76% 8021/10570 [00:26<00:08, 317.78it/s]\u001b[A\n",
      " 76% 8053/10570 [00:26<00:08, 314.41it/s]\u001b[A\n",
      " 76% 8086/10570 [00:26<00:07, 317.38it/s]\u001b[A\n",
      " 77% 8120/10570 [00:26<00:07, 321.71it/s]\u001b[A\n",
      " 77% 8153/10570 [00:26<00:07, 309.99it/s]\u001b[A\n",
      " 77% 8185/10570 [00:26<00:07, 298.17it/s]\u001b[A\n",
      " 78% 8215/10570 [00:27<00:08, 286.79it/s]\u001b[A\n",
      " 78% 8246/10570 [00:27<00:07, 292.80it/s]\u001b[A\n",
      " 78% 8276/10570 [00:27<00:07, 287.12it/s]\u001b[A\n",
      " 79% 8306/10570 [00:27<00:07, 289.45it/s]\u001b[A\n",
      " 79% 8337/10570 [00:27<00:07, 295.00it/s]\u001b[A\n",
      " 79% 8370/10570 [00:27<00:07, 304.26it/s]\u001b[A\n",
      " 79% 8403/10570 [00:27<00:06, 311.76it/s]\u001b[A\n",
      " 80% 8436/10570 [00:27<00:06, 314.63it/s]\u001b[A\n",
      " 80% 8468/10570 [00:27<00:06, 315.86it/s]\u001b[A\n",
      " 80% 8500/10570 [00:27<00:06, 316.72it/s]\u001b[A\n",
      " 81% 8533/10570 [00:28<00:06, 317.98it/s]\u001b[A\n",
      " 81% 8566/10570 [00:28<00:06, 318.70it/s]\u001b[A\n",
      " 81% 8598/10570 [00:28<00:06, 310.58it/s]\u001b[A\n",
      " 82% 8631/10570 [00:28<00:06, 315.74it/s]\u001b[A\n",
      " 82% 8663/10570 [00:28<00:06, 316.34it/s]\u001b[A\n",
      " 82% 8697/10570 [00:28<00:05, 321.64it/s]\u001b[A\n",
      " 83% 8730/10570 [00:28<00:05, 319.53it/s]\u001b[A\n",
      " 83% 8762/10570 [00:28<00:05, 318.16it/s]\u001b[A\n",
      " 83% 8794/10570 [00:28<00:05, 315.17it/s]\u001b[A\n",
      " 84% 8827/10570 [00:29<00:05, 317.02it/s]\u001b[A\n",
      " 84% 8860/10570 [00:29<00:05, 319.91it/s]\u001b[A\n",
      " 84% 8893/10570 [00:29<00:05, 320.85it/s]\u001b[A\n",
      " 84% 8926/10570 [00:29<00:05, 322.87it/s]\u001b[A\n",
      " 85% 8959/10570 [00:29<00:04, 322.99it/s]\u001b[A\n",
      " 85% 8992/10570 [00:29<00:04, 324.17it/s]\u001b[A\n",
      " 85% 9025/10570 [00:29<00:04, 324.84it/s]\u001b[A\n",
      " 86% 9058/10570 [00:29<00:04, 314.68it/s]\u001b[A\n",
      " 86% 9090/10570 [00:29<00:04, 313.64it/s]\u001b[A\n",
      " 86% 9123/10570 [00:29<00:04, 316.16it/s]\u001b[A\n",
      " 87% 9155/10570 [00:30<00:04, 316.77it/s]\u001b[A\n",
      " 87% 9188/10570 [00:30<00:04, 318.31it/s]\u001b[A\n",
      " 87% 9221/10570 [00:30<00:04, 319.50it/s]\u001b[A\n",
      " 88% 9254/10570 [00:30<00:04, 321.57it/s]\u001b[A\n",
      " 88% 9287/10570 [00:30<00:03, 321.30it/s]\u001b[A\n",
      " 88% 9320/10570 [00:30<00:03, 320.57it/s]\u001b[A\n",
      " 88% 9353/10570 [00:30<00:03, 321.34it/s]\u001b[A\n",
      " 89% 9386/10570 [00:30<00:03, 322.58it/s]\u001b[A\n",
      " 89% 9419/10570 [00:30<00:03, 322.57it/s]\u001b[A\n",
      " 89% 9452/10570 [00:30<00:03, 323.98it/s]\u001b[A\n",
      " 90% 9485/10570 [00:31<00:03, 324.55it/s]\u001b[A\n",
      " 90% 9518/10570 [00:31<00:03, 323.92it/s]\u001b[A\n",
      " 90% 9552/10570 [00:31<00:03, 327.96it/s]\u001b[A\n",
      " 91% 9585/10570 [00:31<00:03, 316.09it/s]\u001b[A\n",
      " 91% 9618/10570 [00:31<00:02, 319.96it/s]\u001b[A\n",
      " 91% 9651/10570 [00:31<00:02, 322.26it/s]\u001b[A\n",
      " 92% 9684/10570 [00:31<00:02, 323.79it/s]\u001b[A\n",
      " 92% 9718/10570 [00:31<00:02, 327.73it/s]\u001b[A\n",
      " 92% 9751/10570 [00:31<00:02, 325.63it/s]\u001b[A\n",
      " 93% 9784/10570 [00:32<00:02, 324.53it/s]\u001b[A\n",
      " 93% 9817/10570 [00:32<00:02, 325.17it/s]\u001b[A\n",
      " 93% 9850/10570 [00:32<00:02, 319.74it/s]\u001b[A\n",
      " 94% 9883/10570 [00:32<00:02, 320.93it/s]\u001b[A\n",
      " 94% 9916/10570 [00:32<00:02, 321.16it/s]\u001b[A\n",
      " 94% 9950/10570 [00:32<00:01, 323.65it/s]\u001b[A\n",
      " 94% 9983/10570 [00:32<00:01, 318.92it/s]\u001b[A\n",
      " 95% 10016/10570 [00:32<00:01, 321.09it/s]\u001b[A\n",
      " 95% 10050/10570 [00:32<00:01, 324.73it/s]\u001b[A\n",
      " 95% 10083/10570 [00:32<00:01, 322.50it/s]\u001b[A\n",
      " 96% 10116/10570 [00:33<00:01, 323.26it/s]\u001b[A\n",
      " 96% 10149/10570 [00:33<00:01, 324.94it/s]\u001b[A\n",
      " 96% 10182/10570 [00:33<00:01, 313.82it/s]\u001b[A\n",
      " 97% 10214/10570 [00:33<00:01, 314.18it/s]\u001b[A\n",
      " 97% 10246/10570 [00:33<00:01, 315.34it/s]\u001b[A\n",
      " 97% 10279/10570 [00:33<00:00, 317.22it/s]\u001b[A\n",
      " 98% 10312/10570 [00:33<00:00, 319.52it/s]\u001b[A\n",
      " 98% 10344/10570 [00:33<00:00, 319.23it/s]\u001b[A\n",
      " 98% 10376/10570 [00:33<00:00, 317.12it/s]\u001b[A\n",
      " 98% 10408/10570 [00:33<00:00, 317.41it/s]\u001b[A\n",
      " 99% 10440/10570 [00:34<00:00, 318.16it/s]\u001b[A\n",
      " 99% 10472/10570 [00:34<00:00, 314.46it/s]\u001b[A\n",
      " 99% 10506/10570 [00:34<00:00, 319.35it/s]\u001b[A\n",
      "100% 10570/10570 [00:34<00:00, 306.73it/s]\n",
      "11/18/2024 00:42:51 - INFO - utils_qa - Saving predictions to ./output_qa/eval_predictions.json.\n",
      "11/18/2024 00:42:51 - INFO - utils_qa - Saving nbest_preds to ./output_qa/eval_nbest_predictions.json.\n",
      "100% 1348/1348 [01:26<00:00, 15.61it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        2.0\n",
      "  eval_exact_match        =     63.245\n",
      "  eval_f1                 =    74.4069\n",
      "  eval_runtime            = 0:00:35.10\n",
      "  eval_samples            =      10784\n",
      "  eval_samples_per_second =    307.172\n",
      "  eval_steps_per_second   =     38.397\n",
      "[INFO|modelcard.py:449] 2024-11-18 00:42:55,926 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'squad', 'type': 'squad'}}\n"
     ]
    }
   ],
   "source": [
    "!bash run_low_resource_squad.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fvLAKK3O_T_",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "collapsed": true,
    "id": "8fvLAKK3O_T_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-01 17:11:26.256793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-01 17:11:26.277719: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-01 17:11:26.284160: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 17:11:26.299018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-01 17:11:27.489932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "12/01/2024 17:11:29 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "12/01/2024 17:11:29 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=epoch,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=3e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./output_qa/mix/runs/Dec01_17-11-29_808554d2b6e7,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./output_qa/mix,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./output_qa/mix,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=30000,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=666,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n",
      "Overwrite dataset info from restored data version if exists.\n",
      "12/01/2024 17:11:37 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f\n",
      "12/01/2024 17:11:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f\n",
      "Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f)\n",
      "12/01/2024 17:11:37 - INFO - datasets.builder - Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f)\n",
      "Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f\n",
      "12/01/2024 17:11:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f\n",
      "[INFO|configuration_utils.py:679] 2024-12-01 17:11:37,326 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-12-01 17:11:37,328 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:679] 2024-12-01 17:11:37,579 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-12-01 17:11:37,580 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-12-01 17:11:37,581 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-12-01 17:11:37,581 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-12-01 17:11:37,581 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-12-01 17:11:37,581 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2024-12-01 17:11:37,581 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "[INFO|configuration_utils.py:679] 2024-12-01 17:11:37,581 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "[INFO|configuration_utils.py:746] 2024-12-01 17:11:37,582 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3937] 2024-12-01 17:11:37,658 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "[INFO|logging.py:343] 2024-12-01 17:11:37,699 >> A pretrained model of type `BertForQuestionAnswering` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n",
      "* `bert.embeddings.LayerNorm.gamma` -> `bert.embeddings.LayerNorm.weight`\n",
      "* `bert.encoder.layer.0.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.0.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.1.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.1.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.10.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.10.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.11.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.11.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.2.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.2.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.3.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.3.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.4.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.4.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.5.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.5.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.6.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.6.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.7.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.7.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.8.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.8.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.9.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `cls.predictions.transform.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.embeddings.LayerNorm.beta` -> `bert.embeddings.LayerNorm.bias`\n",
      "* `bert.encoder.layer.0.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.0.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.1.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.1.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.10.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.10.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.11.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.11.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.2.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.2.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.3.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.3.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.4.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.4.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.5.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.5.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.6.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.6.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.7.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.7.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.8.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.8.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.9.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.9.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `cls.predictions.transform.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n",
      "[INFO|modeling_utils.py:4790] 2024-12-01 17:11:37,740 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:4802] 2024-12-01 17:11:37,740 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-21e0c987f58325fc.arrow\n",
      "12/01/2024 17:11:37 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-21e0c987f58325fc.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-a41fa33d5a91c4f9.arrow\n",
      "12/01/2024 17:11:37 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-a41fa33d5a91c4f9.arrow\n",
      "[INFO|trainer.py:699] 2024-12-01 17:11:39,460 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2314] 2024-12-01 17:11:39,728 >> ***** Running training *****\n",
      "[INFO|trainer.py:2315] 2024-12-01 17:11:39,728 >>   Num examples = 88,524\n",
      "[INFO|trainer.py:2316] 2024-12-01 17:11:39,728 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:2317] 2024-12-01 17:11:39,728 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:2320] 2024-12-01 17:11:39,728 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2321] 2024-12-01 17:11:39,728 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2322] 2024-12-01 17:11:39,728 >>   Total optimization steps = 16,599\n",
      "[INFO|trainer.py:2323] 2024-12-01 17:11:39,729 >>   Number of trainable parameters = 108,893,186\n",
      "{'loss': 4.0966, 'grad_norm': 16.970603942871094, 'learning_rate': 9e-06, 'epoch': 0.09}\n",
      "{'loss': 1.6163, 'grad_norm': 19.81815528869629, 'learning_rate': 1.8036144578313255e-05, 'epoch': 0.18}\n",
      "{'loss': 1.3354, 'grad_norm': 8.269113540649414, 'learning_rate': 2.705421686746988e-05, 'epoch': 0.27}\n",
      "{'loss': 1.2418, 'grad_norm': 11.791980743408203, 'learning_rate': 2.932324787469041e-05, 'epoch': 0.36}\n",
      "{'loss': 1.1394, 'grad_norm': 16.01339340209961, 'learning_rate': 2.8319164602717718e-05, 'epoch': 0.45}\n",
      "{'loss': 1.1006, 'grad_norm': 13.313071250915527, 'learning_rate': 2.731508133074503e-05, 'epoch': 0.54}\n",
      "{'loss': 1.1024, 'grad_norm': 12.890798568725586, 'learning_rate': 2.6313006225316287e-05, 'epoch': 0.63}\n",
      "{'loss': 1.0448, 'grad_norm': 18.51945686340332, 'learning_rate': 2.53089229533436e-05, 'epoch': 0.72}\n",
      "{'loss': 0.9986, 'grad_norm': 10.123761177062988, 'learning_rate': 2.430483968137091e-05, 'epoch': 0.81}\n",
      "{'loss': 1.0022, 'grad_norm': 8.207571983337402, 'learning_rate': 2.330075640939822e-05, 'epoch': 0.9}\n",
      "{'loss': 1.0006, 'grad_norm': 7.288400650024414, 'learning_rate': 2.2296673137425528e-05, 'epoch': 0.99}\n",
      " 33% 5532/16599 [05:58<11:54, 15.48it/s][INFO|trainer.py:875] 2024-12-01 17:17:37,811 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4128] 2024-12-01 17:17:37,814 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4130] 2024-12-01 17:17:37,814 >>   Num examples = 10784\n",
      "[INFO|trainer.py:4133] 2024-12-01 17:17:37,814 >>   Batch size = 8\n",
      "\n",
      "  0% 0/1348 [00:00<?, ?it/s]\u001b[A\n",
      "  1% 7/1348 [00:00<00:21, 62.86it/s]\u001b[A\n",
      "  1% 14/1348 [00:00<00:28, 47.57it/s]\u001b[A\n",
      "  1% 20/1348 [00:00<00:26, 50.19it/s]\u001b[A\n",
      "  2% 26/1348 [00:00<00:25, 51.46it/s]\u001b[A\n",
      "  2% 32/1348 [00:00<00:25, 52.35it/s]\u001b[A\n",
      "  3% 38/1348 [00:00<00:25, 52.14it/s]\u001b[A\n",
      "  3% 44/1348 [00:00<00:24, 52.31it/s]\u001b[A\n",
      "  4% 50/1348 [00:00<00:24, 52.48it/s]\u001b[A\n",
      "  4% 56/1348 [00:01<00:24, 52.53it/s]\u001b[A\n",
      "  5% 62/1348 [00:01<00:24, 52.39it/s]\u001b[A\n",
      "  5% 68/1348 [00:01<00:24, 52.59it/s]\u001b[A\n",
      "  5% 74/1348 [00:01<00:24, 52.95it/s]\u001b[A\n",
      "  6% 80/1348 [00:01<00:23, 52.89it/s]\u001b[A\n",
      "  6% 86/1348 [00:01<00:24, 52.33it/s]\u001b[A\n",
      "  7% 92/1348 [00:01<00:23, 52.63it/s]\u001b[A\n",
      "  7% 98/1348 [00:01<00:23, 52.85it/s]\u001b[A\n",
      "  8% 104/1348 [00:01<00:23, 53.03it/s]\u001b[A\n",
      "  8% 110/1348 [00:02<00:23, 52.71it/s]\u001b[A\n",
      "  9% 116/1348 [00:02<00:23, 52.46it/s]\u001b[A\n",
      "  9% 122/1348 [00:02<00:23, 52.89it/s]\u001b[A\n",
      "  9% 128/1348 [00:02<00:22, 53.16it/s]\u001b[A\n",
      " 10% 134/1348 [00:02<00:23, 52.24it/s]\u001b[A\n",
      " 10% 140/1348 [00:02<00:22, 52.65it/s]\u001b[A\n",
      " 11% 146/1348 [00:02<00:22, 53.03it/s]\u001b[A\n",
      " 11% 152/1348 [00:02<00:22, 52.53it/s]\u001b[A\n",
      " 12% 158/1348 [00:03<00:22, 52.74it/s]\u001b[A\n",
      " 12% 164/1348 [00:03<00:22, 53.04it/s]\u001b[A\n",
      " 13% 170/1348 [00:03<00:22, 53.02it/s]\u001b[A\n",
      " 13% 176/1348 [00:03<00:21, 53.56it/s]\u001b[A\n",
      " 14% 182/1348 [00:03<00:21, 53.78it/s]\u001b[A\n",
      " 14% 188/1348 [00:03<00:21, 53.21it/s]\u001b[A\n",
      " 14% 194/1348 [00:03<00:21, 53.40it/s]\u001b[A\n",
      " 15% 200/1348 [00:03<00:21, 53.74it/s]\u001b[A\n",
      " 15% 206/1348 [00:03<00:21, 53.50it/s]\u001b[A\n",
      " 16% 212/1348 [00:04<00:21, 53.64it/s]\u001b[A\n",
      " 16% 218/1348 [00:04<00:20, 54.02it/s]\u001b[A\n",
      " 17% 224/1348 [00:04<00:20, 54.05it/s]\u001b[A\n",
      " 17% 230/1348 [00:04<00:20, 54.33it/s]\u001b[A\n",
      " 18% 236/1348 [00:04<00:20, 54.02it/s]\u001b[A\n",
      " 18% 242/1348 [00:04<00:20, 54.12it/s]\u001b[A\n",
      " 18% 248/1348 [00:04<00:20, 54.39it/s]\u001b[A\n",
      " 19% 254/1348 [00:04<00:20, 54.43it/s]\u001b[A\n",
      " 19% 260/1348 [00:04<00:20, 54.05it/s]\u001b[A\n",
      " 20% 266/1348 [00:05<00:20, 54.08it/s]\u001b[A\n",
      " 20% 272/1348 [00:05<00:19, 54.14it/s]\u001b[A\n",
      " 21% 278/1348 [00:05<00:19, 54.35it/s]\u001b[A\n",
      " 21% 284/1348 [00:05<00:19, 53.83it/s]\u001b[A\n",
      " 22% 290/1348 [00:05<00:19, 53.68it/s]\u001b[A\n",
      " 22% 296/1348 [00:05<00:19, 53.49it/s]\u001b[A\n",
      " 22% 302/1348 [00:05<00:19, 53.46it/s]\u001b[A\n",
      " 23% 308/1348 [00:05<00:19, 53.85it/s]\u001b[A\n",
      " 23% 314/1348 [00:05<00:19, 53.74it/s]\u001b[A\n",
      " 24% 320/1348 [00:06<00:19, 54.05it/s]\u001b[A\n",
      " 24% 326/1348 [00:06<00:19, 53.58it/s]\u001b[A\n",
      " 25% 332/1348 [00:06<00:18, 53.81it/s]\u001b[A\n",
      " 25% 338/1348 [00:06<00:18, 53.79it/s]\u001b[A\n",
      " 26% 344/1348 [00:06<00:18, 53.72it/s]\u001b[A\n",
      " 26% 350/1348 [00:06<00:18, 53.37it/s]\u001b[A\n",
      " 26% 356/1348 [00:06<00:18, 53.49it/s]\u001b[A\n",
      " 27% 362/1348 [00:06<00:18, 53.64it/s]\u001b[A\n",
      " 27% 368/1348 [00:06<00:18, 54.00it/s]\u001b[A\n",
      " 28% 374/1348 [00:07<00:18, 53.84it/s]\u001b[A\n",
      " 28% 380/1348 [00:07<00:17, 54.09it/s]\u001b[A\n",
      " 29% 386/1348 [00:07<00:17, 53.98it/s]\u001b[A\n",
      " 29% 392/1348 [00:07<00:17, 54.08it/s]\u001b[A\n",
      " 30% 398/1348 [00:07<00:17, 53.29it/s]\u001b[A\n",
      " 30% 404/1348 [00:07<00:17, 52.77it/s]\u001b[A\n",
      " 30% 410/1348 [00:07<00:17, 53.07it/s]\u001b[A\n",
      " 31% 416/1348 [00:07<00:17, 53.14it/s]\u001b[A\n",
      " 31% 422/1348 [00:07<00:17, 53.46it/s]\u001b[A\n",
      " 32% 428/1348 [00:08<00:17, 53.66it/s]\u001b[A\n",
      " 32% 434/1348 [00:08<00:16, 53.99it/s]\u001b[A\n",
      " 33% 440/1348 [00:08<00:17, 53.33it/s]\u001b[A\n",
      " 33% 446/1348 [00:08<00:16, 53.55it/s]\u001b[A\n",
      " 34% 452/1348 [00:08<00:16, 53.65it/s]\u001b[A\n",
      " 34% 458/1348 [00:08<00:16, 53.14it/s]\u001b[A\n",
      " 34% 464/1348 [00:08<00:16, 53.60it/s]\u001b[A\n",
      " 35% 470/1348 [00:08<00:16, 53.94it/s]\u001b[A\n",
      " 35% 476/1348 [00:08<00:16, 54.24it/s]\u001b[A\n",
      " 36% 482/1348 [00:09<00:15, 54.62it/s]\u001b[A\n",
      " 36% 488/1348 [00:09<00:15, 54.57it/s]\u001b[A\n",
      " 37% 494/1348 [00:09<00:15, 54.80it/s]\u001b[A\n",
      " 37% 500/1348 [00:09<00:15, 55.05it/s]\u001b[A\n",
      " 38% 506/1348 [00:09<00:15, 54.69it/s]\u001b[A\n",
      " 38% 512/1348 [00:09<00:15, 54.17it/s]\u001b[A\n",
      " 38% 518/1348 [00:09<00:15, 54.28it/s]\u001b[A\n",
      " 39% 524/1348 [00:09<00:15, 53.69it/s]\u001b[A\n",
      " 39% 530/1348 [00:09<00:15, 53.78it/s]\u001b[A\n",
      " 40% 536/1348 [00:10<00:15, 53.72it/s]\u001b[A\n",
      " 40% 542/1348 [00:10<00:15, 53.72it/s]\u001b[A\n",
      " 41% 548/1348 [00:10<00:14, 54.05it/s]\u001b[A\n",
      " 41% 554/1348 [00:10<00:14, 53.98it/s]\u001b[A\n",
      " 42% 560/1348 [00:10<00:14, 53.95it/s]\u001b[A\n",
      " 42% 566/1348 [00:10<00:14, 53.08it/s]\u001b[A\n",
      " 42% 572/1348 [00:10<00:14, 53.69it/s]\u001b[A\n",
      " 43% 578/1348 [00:10<00:14, 53.81it/s]\u001b[A\n",
      " 43% 584/1348 [00:10<00:14, 54.00it/s]\u001b[A\n",
      " 44% 590/1348 [00:11<00:14, 54.14it/s]\u001b[A\n",
      " 44% 596/1348 [00:11<00:13, 54.29it/s]\u001b[A\n",
      " 45% 602/1348 [00:11<00:13, 54.28it/s]\u001b[A\n",
      " 45% 608/1348 [00:11<00:13, 54.31it/s]\u001b[A\n",
      " 46% 614/1348 [00:11<00:13, 53.50it/s]\u001b[A\n",
      " 46% 620/1348 [00:11<00:13, 53.12it/s]\u001b[A\n",
      " 46% 626/1348 [00:11<00:13, 53.47it/s]\u001b[A\n",
      " 47% 632/1348 [00:11<00:13, 53.94it/s]\u001b[A\n",
      " 33% 5533/16599 [06:10<11:54, 15.48it/s]\n",
      " 48% 644/1348 [00:12<00:12, 54.50it/s]\u001b[A\n",
      " 48% 650/1348 [00:12<00:12, 54.35it/s]\u001b[A\n",
      " 49% 656/1348 [00:12<00:12, 54.49it/s]\u001b[A\n",
      " 49% 662/1348 [00:12<00:12, 54.71it/s]\u001b[A\n",
      " 50% 668/1348 [00:12<00:12, 54.37it/s]\u001b[A\n",
      " 50% 674/1348 [00:12<00:12, 54.00it/s]\u001b[A\n",
      " 50% 680/1348 [00:12<00:12, 53.98it/s]\u001b[A\n",
      " 51% 686/1348 [00:12<00:12, 54.31it/s]\u001b[A\n",
      " 51% 692/1348 [00:12<00:12, 53.58it/s]\u001b[A\n",
      " 52% 698/1348 [00:13<00:12, 53.25it/s]\u001b[A\n",
      " 52% 704/1348 [00:13<00:12, 52.83it/s]\u001b[A\n",
      " 53% 710/1348 [00:13<00:12, 52.65it/s]\u001b[A\n",
      " 53% 716/1348 [00:13<00:11, 52.80it/s]\u001b[A\n",
      " 54% 722/1348 [00:13<00:11, 52.74it/s]\u001b[A\n",
      " 54% 728/1348 [00:13<00:11, 52.32it/s]\u001b[A\n",
      " 54% 734/1348 [00:13<00:11, 52.53it/s]\u001b[A\n",
      " 55% 740/1348 [00:13<00:11, 52.67it/s]\u001b[A\n",
      " 55% 746/1348 [00:13<00:11, 52.82it/s]\u001b[A\n",
      " 56% 752/1348 [00:14<00:11, 52.78it/s]\u001b[A\n",
      " 56% 758/1348 [00:14<00:11, 52.88it/s]\u001b[A\n",
      " 57% 764/1348 [00:14<00:11, 52.74it/s]\u001b[A\n",
      " 57% 770/1348 [00:14<00:11, 52.48it/s]\u001b[A\n",
      " 58% 776/1348 [00:14<00:10, 52.14it/s]\u001b[A\n",
      " 58% 782/1348 [00:14<00:10, 52.32it/s]\u001b[A\n",
      " 58% 788/1348 [00:14<00:10, 52.52it/s]\u001b[A\n",
      " 59% 794/1348 [00:14<00:10, 52.62it/s]\u001b[A\n",
      " 59% 800/1348 [00:14<00:10, 52.75it/s]\u001b[A\n",
      " 60% 806/1348 [00:15<00:10, 52.58it/s]\u001b[A\n",
      " 60% 812/1348 [00:15<00:10, 52.65it/s]\u001b[A\n",
      " 61% 818/1348 [00:15<00:10, 52.80it/s]\u001b[A\n",
      " 61% 824/1348 [00:15<00:09, 52.89it/s]\u001b[A\n",
      " 62% 830/1348 [00:15<00:09, 53.35it/s]\u001b[A\n",
      " 62% 836/1348 [00:15<00:09, 53.92it/s]\u001b[A\n",
      " 62% 842/1348 [00:15<00:09, 54.19it/s]\u001b[A\n",
      " 63% 848/1348 [00:15<00:09, 54.06it/s]\u001b[A\n",
      " 63% 854/1348 [00:15<00:09, 54.30it/s]\u001b[A\n",
      " 64% 860/1348 [00:16<00:09, 54.06it/s]\u001b[A\n",
      " 64% 866/1348 [00:16<00:08, 54.21it/s]\u001b[A\n",
      " 65% 872/1348 [00:16<00:08, 54.36it/s]\u001b[A\n",
      " 65% 878/1348 [00:16<00:08, 53.71it/s]\u001b[A\n",
      " 66% 884/1348 [00:16<00:08, 53.88it/s]\u001b[A\n",
      " 66% 890/1348 [00:16<00:08, 54.03it/s]\u001b[A\n",
      " 66% 896/1348 [00:16<00:08, 54.33it/s]\u001b[A\n",
      " 67% 902/1348 [00:16<00:08, 54.25it/s]\u001b[A\n",
      " 67% 908/1348 [00:16<00:08, 54.12it/s]\u001b[A\n",
      " 68% 914/1348 [00:17<00:07, 54.27it/s]\u001b[A\n",
      " 68% 920/1348 [00:17<00:07, 54.45it/s]\u001b[A\n",
      " 69% 926/1348 [00:17<00:07, 54.22it/s]\u001b[A\n",
      " 69% 932/1348 [00:17<00:07, 54.34it/s]\u001b[A\n",
      " 70% 938/1348 [00:17<00:07, 54.32it/s]\u001b[A\n",
      " 70% 944/1348 [00:17<00:07, 54.33it/s]\u001b[A\n",
      " 70% 950/1348 [00:17<00:07, 54.37it/s]\u001b[A\n",
      " 71% 956/1348 [00:17<00:07, 54.67it/s]\u001b[A\n",
      " 71% 962/1348 [00:17<00:07, 54.74it/s]\u001b[A\n",
      " 72% 968/1348 [00:18<00:06, 54.72it/s]\u001b[A\n",
      " 72% 974/1348 [00:18<00:06, 54.86it/s]\u001b[A\n",
      " 73% 980/1348 [00:18<00:06, 53.61it/s]\u001b[A\n",
      " 73% 986/1348 [00:18<00:06, 53.80it/s]\u001b[A\n",
      " 74% 992/1348 [00:18<00:06, 54.17it/s]\u001b[A\n",
      " 74% 998/1348 [00:18<00:06, 53.90it/s]\u001b[A\n",
      " 74% 1004/1348 [00:18<00:06, 54.12it/s]\u001b[A\n",
      " 75% 1010/1348 [00:18<00:06, 54.23it/s]\u001b[A\n",
      " 75% 1016/1348 [00:18<00:06, 54.26it/s]\u001b[A\n",
      " 76% 1022/1348 [00:19<00:06, 54.30it/s]\u001b[A\n",
      " 76% 1028/1348 [00:19<00:05, 54.37it/s]\u001b[A\n",
      " 77% 1034/1348 [00:19<00:05, 54.21it/s]\u001b[A\n",
      " 77% 1040/1348 [00:19<00:05, 54.06it/s]\u001b[A\n",
      " 78% 1046/1348 [00:19<00:05, 53.86it/s]\u001b[A\n",
      " 78% 1052/1348 [00:19<00:05, 54.26it/s]\u001b[A\n",
      " 78% 1058/1348 [00:19<00:05, 54.01it/s]\u001b[A\n",
      " 79% 1064/1348 [00:19<00:05, 53.17it/s]\u001b[A\n",
      " 79% 1070/1348 [00:19<00:05, 52.83it/s]\u001b[A\n",
      " 80% 1076/1348 [00:20<00:05, 52.97it/s]\u001b[A\n",
      " 80% 1082/1348 [00:20<00:04, 53.49it/s]\u001b[A\n",
      " 81% 1088/1348 [00:20<00:04, 53.36it/s]\u001b[A\n",
      " 81% 1094/1348 [00:20<00:04, 53.59it/s]\u001b[A\n",
      " 82% 1100/1348 [00:20<00:04, 53.78it/s]\u001b[A\n",
      " 82% 1106/1348 [00:20<00:04, 53.91it/s]\u001b[A\n",
      " 82% 1112/1348 [00:20<00:04, 54.11it/s]\u001b[A\n",
      " 83% 1118/1348 [00:20<00:04, 54.11it/s]\u001b[A\n",
      " 83% 1124/1348 [00:20<00:04, 54.26it/s]\u001b[A\n",
      " 84% 1130/1348 [00:21<00:04, 54.44it/s]\u001b[A\n",
      " 84% 1136/1348 [00:21<00:03, 54.21it/s]\u001b[A\n",
      " 85% 1142/1348 [00:21<00:03, 54.35it/s]\u001b[A\n",
      " 85% 1148/1348 [00:21<00:03, 53.87it/s]\u001b[A\n",
      " 86% 1154/1348 [00:21<00:03, 54.15it/s]\u001b[A\n",
      " 86% 1160/1348 [00:21<00:03, 54.29it/s]\u001b[A\n",
      " 86% 1166/1348 [00:21<00:03, 54.32it/s]\u001b[A\n",
      " 87% 1172/1348 [00:21<00:03, 54.16it/s]\u001b[A\n",
      " 87% 1178/1348 [00:21<00:03, 54.17it/s]\u001b[A\n",
      " 88% 1184/1348 [00:22<00:03, 53.73it/s]\u001b[A\n",
      " 88% 1190/1348 [00:22<00:02, 53.96it/s]\u001b[A\n",
      " 89% 1196/1348 [00:22<00:02, 54.10it/s]\u001b[A\n",
      " 89% 1202/1348 [00:22<00:02, 53.94it/s]\u001b[A\n",
      " 90% 1208/1348 [00:22<00:02, 54.12it/s]\u001b[A\n",
      " 90% 1214/1348 [00:22<00:02, 54.23it/s]\u001b[A\n",
      " 91% 1220/1348 [00:22<00:02, 54.13it/s]\u001b[A\n",
      " 91% 1226/1348 [00:22<00:02, 53.89it/s]\u001b[A\n",
      " 91% 1232/1348 [00:22<00:02, 53.92it/s]\u001b[A\n",
      " 92% 1238/1348 [00:23<00:02, 54.21it/s]\u001b[A\n",
      " 92% 1244/1348 [00:23<00:01, 54.32it/s]\u001b[A\n",
      " 93% 1250/1348 [00:23<00:01, 54.49it/s]\u001b[A\n",
      " 93% 1256/1348 [00:23<00:01, 54.17it/s]\u001b[A\n",
      " 94% 1262/1348 [00:23<00:01, 54.16it/s]\u001b[A\n",
      " 94% 1268/1348 [00:23<00:01, 54.36it/s]\u001b[A\n",
      " 95% 1274/1348 [00:23<00:01, 53.18it/s]\u001b[A\n",
      " 95% 1280/1348 [00:23<00:01, 53.47it/s]\u001b[A\n",
      " 95% 1286/1348 [00:23<00:01, 53.81it/s]\u001b[A\n",
      " 96% 1292/1348 [00:24<00:01, 54.04it/s]\u001b[A\n",
      " 96% 1298/1348 [00:24<00:00, 54.29it/s]\u001b[A\n",
      " 97% 1304/1348 [00:24<00:00, 54.53it/s]\u001b[A\n",
      " 97% 1310/1348 [00:24<00:00, 53.34it/s]\u001b[A\n",
      " 98% 1316/1348 [00:24<00:00, 53.75it/s]\u001b[A\n",
      " 98% 1322/1348 [00:24<00:00, 53.62it/s]\u001b[A\n",
      " 99% 1328/1348 [00:24<00:00, 53.60it/s]\u001b[A\n",
      " 99% 1334/1348 [00:24<00:00, 53.56it/s]\u001b[A\n",
      " 99% 1340/1348 [00:24<00:00, 53.47it/s]\u001b[A\n",
      "100% 1346/1348 [00:25<00:00, 53.88it/s]\u001b[A\n",
      "100% 1348/1348 [00:36<00:00, 53.88it/s]\u001b[A12/01/2024 17:18:15 - INFO - utils_qa - Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 33/10570 [00:00<00:32, 321.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 68/10570 [00:00<00:31, 335.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 103/10570 [00:00<00:30, 338.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 139/10570 [00:00<00:30, 343.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 174/10570 [00:00<00:30, 340.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 209/10570 [00:00<00:31, 332.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 243/10570 [00:00<00:32, 320.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 276/10570 [00:00<00:38, 264.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 308/10570 [00:01<00:36, 278.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 343/10570 [00:01<00:34, 296.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 378/10570 [00:01<00:33, 308.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 410/10570 [00:01<00:32, 311.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 443/10570 [00:01<00:32, 316.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 476/10570 [00:01<00:31, 318.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 510/10570 [00:01<00:30, 324.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 544/10570 [00:01<00:30, 328.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 578/10570 [00:01<00:30, 328.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 611/10570 [00:01<00:30, 328.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 645/10570 [00:02<00:30, 330.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 680/10570 [00:02<00:29, 334.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 714/10570 [00:02<00:29, 331.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 748/10570 [00:02<00:29, 327.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 781/10570 [00:02<00:30, 323.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 814/10570 [00:02<00:31, 313.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 846/10570 [00:02<00:31, 313.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 878/10570 [00:02<00:30, 313.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 911/10570 [00:02<00:30, 316.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 944/10570 [00:02<00:30, 318.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 977/10570 [00:03<00:30, 319.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1010/10570 [00:03<00:29, 320.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1043/10570 [00:03<00:29, 320.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1076/10570 [00:03<00:29, 320.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1109/10570 [00:03<00:30, 311.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1143/10570 [00:03<00:29, 318.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1178/10570 [00:03<00:28, 326.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1212/10570 [00:03<00:28, 329.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1247/10570 [00:03<00:27, 333.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1281/10570 [00:03<00:27, 331.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1316/10570 [00:04<00:27, 335.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1350/10570 [00:04<00:27, 334.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1384/10570 [00:04<00:27, 333.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1418/10570 [00:04<00:27, 331.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1452/10570 [00:04<00:27, 331.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1486/10570 [00:04<00:27, 330.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1521/10570 [00:04<00:27, 333.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1555/10570 [00:04<00:26, 335.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1590/10570 [00:04<00:26, 336.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1624/10570 [00:05<00:26, 335.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1659/10570 [00:05<00:26, 339.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1694/10570 [00:05<00:25, 341.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1729/10570 [00:05<00:25, 341.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1764/10570 [00:05<00:26, 337.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1799/10570 [00:05<00:25, 338.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1833/10570 [00:05<00:25, 338.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1867/10570 [00:05<00:25, 337.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1903/10570 [00:05<00:25, 341.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1938/10570 [00:05<00:25, 341.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 1973/10570 [00:06<00:25, 341.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2008/10570 [00:06<00:25, 340.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2043/10570 [00:06<00:25, 339.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2078/10570 [00:06<00:24, 340.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2113/10570 [00:06<00:24, 340.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2148/10570 [00:06<00:27, 309.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2181/10570 [00:06<00:26, 314.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2216/10570 [00:06<00:25, 324.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2249/10570 [00:06<00:25, 322.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2283/10570 [00:07<00:25, 325.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2317/10570 [00:07<00:25, 327.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2351/10570 [00:07<00:24, 328.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2384/10570 [00:07<00:25, 327.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2418/10570 [00:07<00:24, 329.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2452/10570 [00:07<00:25, 321.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2486/10570 [00:07<00:24, 326.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2519/10570 [00:07<00:25, 310.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2551/10570 [00:07<00:25, 309.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2583/10570 [00:07<00:25, 312.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2617/10570 [00:08<00:24, 319.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2652/10570 [00:08<00:24, 327.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2686/10570 [00:08<00:23, 330.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2720/10570 [00:08<00:23, 331.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2755/10570 [00:08<00:23, 334.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2791/10570 [00:08<00:22, 340.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2826/10570 [00:08<00:22, 341.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2861/10570 [00:08<00:22, 338.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2895/10570 [00:08<00:22, 334.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2929/10570 [00:08<00:22, 334.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2963/10570 [00:09<00:22, 333.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2997/10570 [00:09<00:22, 332.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3031/10570 [00:09<00:22, 334.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3065/10570 [00:09<00:22, 331.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3099/10570 [00:09<00:22, 332.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3133/10570 [00:09<00:22, 330.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3167/10570 [00:09<00:22, 327.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3200/10570 [00:09<00:22, 326.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3233/10570 [00:09<00:22, 325.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3266/10570 [00:09<00:22, 326.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3300/10570 [00:10<00:22, 327.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3334/10570 [00:10<00:21, 329.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3367/10570 [00:10<00:21, 329.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3401/10570 [00:10<00:21, 330.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3435/10570 [00:10<00:21, 327.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3468/10570 [00:10<00:21, 327.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3501/10570 [00:10<00:21, 326.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3534/10570 [00:10<00:21, 327.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3567/10570 [00:10<00:21, 326.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3600/10570 [00:11<00:21, 324.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3633/10570 [00:11<00:21, 324.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3667/10570 [00:11<00:21, 326.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3700/10570 [00:11<00:20, 327.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3734/10570 [00:11<00:20, 328.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3767/10570 [00:11<00:20, 328.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3800/10570 [00:11<00:20, 327.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3834/10570 [00:11<00:20, 328.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3868/10570 [00:11<00:20, 328.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3901/10570 [00:11<00:20, 326.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3934/10570 [00:12<00:20, 326.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 3967/10570 [00:12<00:20, 327.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4000/10570 [00:12<00:20, 327.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4033/10570 [00:12<00:19, 327.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4067/10570 [00:12<00:19, 330.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4101/10570 [00:12<00:19, 325.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4134/10570 [00:12<00:20, 318.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4166/10570 [00:12<00:24, 262.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4194/10570 [00:12<00:26, 244.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4220/10570 [00:13<00:26, 237.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4251/10570 [00:13<00:24, 255.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4278/10570 [00:13<00:31, 202.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4301/10570 [00:13<00:34, 181.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4325/10570 [00:13<00:32, 194.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4357/10570 [00:13<00:27, 224.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4389/10570 [00:13<00:24, 247.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4421/10570 [00:13<00:23, 265.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4453/10570 [00:14<00:21, 280.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4486/10570 [00:14<00:20, 292.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4517/10570 [00:14<00:20, 290.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4548/10570 [00:14<00:20, 294.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4579/10570 [00:14<00:20, 298.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4610/10570 [00:14<00:20, 289.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4641/10570 [00:14<00:20, 294.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4671/10570 [00:14<00:20, 282.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4704/10570 [00:14<00:19, 295.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4737/10570 [00:15<00:19, 302.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4768/10570 [00:15<00:19, 290.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4800/10570 [00:15<00:19, 296.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4835/10570 [00:15<00:18, 309.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4867/10570 [00:15<00:19, 292.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4900/10570 [00:15<00:18, 301.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4933/10570 [00:15<00:18, 308.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4965/10570 [00:15<00:18, 311.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4997/10570 [00:15<00:17, 311.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5029/10570 [00:15<00:17, 313.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5062/10570 [00:16<00:17, 317.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5094/10570 [00:16<00:17, 317.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5128/10570 [00:16<00:16, 322.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5161/10570 [00:16<00:16, 324.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5194/10570 [00:16<00:16, 324.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5228/10570 [00:16<00:16, 326.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5261/10570 [00:16<00:16, 324.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5295/10570 [00:16<00:16, 327.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5328/10570 [00:16<00:16, 322.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5361/10570 [00:16<00:16, 321.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5394/10570 [00:17<00:15, 323.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5427/10570 [00:17<00:15, 324.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5460/10570 [00:17<00:16, 308.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5491/10570 [00:17<00:17, 294.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5523/10570 [00:17<00:16, 299.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5555/10570 [00:17<00:16, 304.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5587/10570 [00:17<00:16, 308.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5619/10570 [00:17<00:15, 310.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5651/10570 [00:17<00:15, 312.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5683/10570 [00:18<00:16, 302.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5717/10570 [00:18<00:15, 311.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5749/10570 [00:18<00:15, 313.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5781/10570 [00:18<00:15, 315.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5813/10570 [00:18<00:15, 314.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5846/10570 [00:18<00:14, 318.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5879/10570 [00:18<00:14, 321.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5912/10570 [00:18<00:14, 321.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5945/10570 [00:18<00:14, 322.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 5978/10570 [00:18<00:14, 324.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6011/10570 [00:19<00:14, 320.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6044/10570 [00:19<00:14, 320.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6077/10570 [00:19<00:14, 317.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6109/10570 [00:19<00:14, 317.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6142/10570 [00:19<00:13, 320.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6175/10570 [00:19<00:13, 322.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6208/10570 [00:19<00:13, 319.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6240/10570 [00:19<00:14, 306.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6273/10570 [00:19<00:13, 311.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6307/10570 [00:19<00:13, 317.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6339/10570 [00:20<00:13, 318.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6372/10570 [00:20<00:13, 319.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6404/10570 [00:20<00:13, 307.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6438/10570 [00:20<00:13, 314.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6472/10570 [00:20<00:12, 319.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6505/10570 [00:20<00:12, 321.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6538/10570 [00:20<00:12, 323.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6571/10570 [00:20<00:12, 324.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6604/10570 [00:20<00:12, 322.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6638/10570 [00:21<00:12, 325.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6671/10570 [00:21<00:11, 326.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6704/10570 [00:21<00:12, 321.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6737/10570 [00:21<00:11, 322.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6771/10570 [00:21<00:11, 326.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6804/10570 [00:21<00:11, 323.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6837/10570 [00:21<00:11, 317.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6870/10570 [00:21<00:11, 318.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6903/10570 [00:21<00:11, 319.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6936/10570 [00:21<00:11, 322.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6969/10570 [00:22<00:11, 324.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 7002/10570 [00:22<00:10, 324.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7035/10570 [00:22<00:10, 325.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7068/10570 [00:22<00:10, 319.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7101/10570 [00:22<00:10, 322.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7135/10570 [00:22<00:10, 325.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7169/10570 [00:22<00:10, 327.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7202/10570 [00:22<00:10, 326.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7235/10570 [00:22<00:10, 324.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7268/10570 [00:22<00:10, 324.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7301/10570 [00:23<00:10, 325.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7334/10570 [00:23<00:10, 314.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7366/10570 [00:23<00:10, 299.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7399/10570 [00:23<00:10, 306.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7432/10570 [00:23<00:10, 312.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7465/10570 [00:23<00:09, 314.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7499/10570 [00:23<00:09, 319.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7532/10570 [00:23<00:09, 322.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7565/10570 [00:23<00:09, 324.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7598/10570 [00:24<00:09, 325.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7632/10570 [00:24<00:08, 327.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7665/10570 [00:24<00:10, 277.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7699/10570 [00:24<00:09, 291.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7732/10570 [00:24<00:09, 301.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7764/10570 [00:24<00:09, 294.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7797/10570 [00:24<00:09, 302.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7829/10570 [00:24<00:08, 306.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7862/10570 [00:24<00:08, 313.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7895/10570 [00:25<00:08, 316.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7929/10570 [00:25<00:08, 321.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7962/10570 [00:25<00:08, 315.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 7994/10570 [00:25<00:08, 316.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8027/10570 [00:25<00:07, 319.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8060/10570 [00:25<00:08, 309.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8095/10570 [00:25<00:07, 318.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8127/10570 [00:25<00:07, 313.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8159/10570 [00:25<00:07, 311.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8191/10570 [00:25<00:07, 311.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8223/10570 [00:26<00:07, 311.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8255/10570 [00:26<00:07, 312.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8287/10570 [00:26<00:07, 297.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8320/10570 [00:26<00:07, 305.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8353/10570 [00:26<00:07, 309.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8386/10570 [00:26<00:06, 315.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8420/10570 [00:26<00:06, 320.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8454/10570 [00:26<00:06, 325.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8487/10570 [00:26<00:06, 326.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8520/10570 [00:26<00:06, 326.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8553/10570 [00:27<00:06, 325.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8586/10570 [00:27<00:06, 322.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8619/10570 [00:27<00:06, 324.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8652/10570 [00:27<00:05, 324.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8685/10570 [00:27<00:05, 323.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8718/10570 [00:27<00:05, 323.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8751/10570 [00:27<00:05, 323.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8784/10570 [00:27<00:05, 319.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8817/10570 [00:27<00:05, 322.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8850/10570 [00:28<00:05, 315.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8883/10570 [00:28<00:05, 319.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8916/10570 [00:28<00:05, 319.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8949/10570 [00:28<00:05, 320.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8982/10570 [00:28<00:04, 322.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 9015/10570 [00:28<00:04, 322.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9048/10570 [00:28<00:04, 322.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9081/10570 [00:28<00:04, 324.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9114/10570 [00:28<00:04, 324.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9147/10570 [00:28<00:04, 324.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9180/10570 [00:29<00:04, 324.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9213/10570 [00:29<00:04, 324.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9247/10570 [00:29<00:04, 326.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9281/10570 [00:29<00:03, 327.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9314/10570 [00:29<00:03, 325.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9347/10570 [00:29<00:03, 324.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9380/10570 [00:29<00:03, 325.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9413/10570 [00:29<00:03, 326.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9447/10570 [00:29<00:03, 327.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9480/10570 [00:29<00:03, 328.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9513/10570 [00:30<00:03, 327.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9547/10570 [00:30<00:03, 329.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9581/10570 [00:30<00:02, 330.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9615/10570 [00:30<00:02, 331.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9649/10570 [00:30<00:02, 329.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9683/10570 [00:30<00:02, 330.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9717/10570 [00:30<00:02, 333.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9751/10570 [00:30<00:02, 334.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9785/10570 [00:30<00:02, 333.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9819/10570 [00:30<00:02, 331.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9853/10570 [00:31<00:02, 326.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9886/10570 [00:31<00:02, 327.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9919/10570 [00:31<00:01, 326.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9953/10570 [00:31<00:01, 329.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9986/10570 [00:31<00:01, 325.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10020/10570 [00:31<00:01, 328.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10054/10570 [00:31<00:01, 331.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10088/10570 [00:31<00:01, 329.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10122/10570 [00:31<00:01, 330.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10156/10570 [00:31<00:01, 329.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10189/10570 [00:32<00:01, 318.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10222/10570 [00:32<00:01, 321.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10255/10570 [00:32<00:00, 323.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10288/10570 [00:32<00:00, 324.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10321/10570 [00:32<00:00, 325.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10354/10570 [00:32<00:00, 326.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10387/10570 [00:32<00:00, 324.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10420/10570 [00:32<00:00, 324.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10453/10570 [00:32<00:00, 324.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10486/10570 [00:33<00:00, 322.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10519/10570 [00:33<00:00, 318.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10570/10570 [00:33<00:00, 317.63it/s]\n",
      "12/01/2024 17:18:48 - INFO - utils_qa - Saving predictions to ./output_qa/mix/eval_predictions.json.\n",
      "12/01/2024 17:18:48 - INFO - utils_qa - Saving nbest_preds to ./output_qa/mix/eval_nbest_predictions.json.\n",
      "                                        \n",
      "\u001b[A{'eval_exact_match': 78.92147587511826, 'eval_f1': 87.0960205718487, 'eval_runtime': 25.1649, 'eval_samples_per_second': 428.534, 'eval_steps_per_second': 53.567, 'epoch': 1.0}\n",
      " 33% 5533/16599 [07:13<11:54, 15.48it/s]\n",
      "100% 1348/1348 [01:15<00:00, 53.88it/s]\u001b[A\n",
      "{'loss': 0.6497, 'grad_norm': 4.1054205894470215, 'learning_rate': 2.1294598031996787e-05, 'epoch': 1.08}\n",
      "{'loss': 0.615, 'grad_norm': 4.958099365234375, 'learning_rate': 2.0290514760024097e-05, 'epoch': 1.17}\n",
      "{'loss': 0.6197, 'grad_norm': 21.89511489868164, 'learning_rate': 1.928643148805141e-05, 'epoch': 1.27}\n",
      "{'loss': 0.6141, 'grad_norm': 13.612069129943848, 'learning_rate': 1.828234821607872e-05, 'epoch': 1.36}\n",
      "{'loss': 0.6147, 'grad_norm': 6.854471206665039, 'learning_rate': 1.7278264944106032e-05, 'epoch': 1.45}\n",
      "{'loss': 0.629, 'grad_norm': 13.182584762573242, 'learning_rate': 1.6274181672133345e-05, 'epoch': 1.54}\n",
      "{'loss': 0.5991, 'grad_norm': 20.16349220275879, 'learning_rate': 1.5270098400160654e-05, 'epoch': 1.63}\n",
      "{'loss': 0.594, 'grad_norm': 11.61806583404541, 'learning_rate': 1.426802329473191e-05, 'epoch': 1.72}\n",
      "{'loss': 0.6034, 'grad_norm': 15.341988563537598, 'learning_rate': 1.3263940022759221e-05, 'epoch': 1.81}\n",
      "{'loss': 0.5945, 'grad_norm': 10.485062599182129, 'learning_rate': 1.2261864917330477e-05, 'epoch': 1.9}\n",
      "{'loss': 0.5998, 'grad_norm': 4.408097267150879, 'learning_rate': 1.1257781645357788e-05, 'epoch': 1.99}\n",
      " 67% 11066/16599 [13:10<05:43, 16.13it/s][INFO|trainer.py:875] 2024-12-01 17:24:50,463 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4128] 2024-12-01 17:24:50,466 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4130] 2024-12-01 17:24:50,466 >>   Num examples = 10784\n",
      "[INFO|trainer.py:4133] 2024-12-01 17:24:50,466 >>   Batch size = 8\n",
      "\n",
      "  0% 0/1348 [00:00<?, ?it/s]\u001b[A\n",
      "  1% 7/1348 [00:00<00:21, 63.85it/s]\u001b[A\n",
      "  1% 14/1348 [00:00<00:23, 57.61it/s]\u001b[A\n",
      "  1% 20/1348 [00:00<00:23, 56.25it/s]\u001b[A\n",
      "  2% 26/1348 [00:00<00:24, 54.71it/s]\u001b[A\n",
      "  2% 32/1348 [00:00<00:23, 54.86it/s]\u001b[A\n",
      "  3% 38/1348 [00:00<00:23, 54.66it/s]\u001b[A\n",
      "  3% 44/1348 [00:00<00:23, 54.59it/s]\u001b[A\n",
      "  4% 50/1348 [00:00<00:23, 54.18it/s]\u001b[A\n",
      "  4% 56/1348 [00:01<00:23, 54.33it/s]\u001b[A\n",
      "  5% 62/1348 [00:01<00:23, 54.54it/s]\u001b[A\n",
      "  5% 68/1348 [00:01<00:23, 54.51it/s]\u001b[A\n",
      "  5% 74/1348 [00:01<00:23, 54.49it/s]\u001b[A\n",
      "  6% 80/1348 [00:01<00:23, 54.55it/s]\u001b[A\n",
      "  6% 86/1348 [00:01<00:23, 54.62it/s]\u001b[A\n",
      "  7% 92/1348 [00:01<00:23, 54.38it/s]\u001b[A\n",
      "  7% 98/1348 [00:01<00:23, 54.31it/s]\u001b[A\n",
      "  8% 104/1348 [00:01<00:23, 53.69it/s]\u001b[A\n",
      "  8% 110/1348 [00:02<00:23, 53.62it/s]\u001b[A\n",
      "  9% 116/1348 [00:02<00:23, 53.55it/s]\u001b[A\n",
      "  9% 122/1348 [00:02<00:22, 53.42it/s]\u001b[A\n",
      "  9% 128/1348 [00:02<00:22, 53.52it/s]\u001b[A\n",
      " 10% 134/1348 [00:02<00:22, 53.55it/s]\u001b[A\n",
      " 10% 140/1348 [00:02<00:22, 53.36it/s]\u001b[A\n",
      " 11% 146/1348 [00:02<00:22, 53.32it/s]\u001b[A\n",
      " 11% 152/1348 [00:02<00:22, 53.39it/s]\u001b[A\n",
      " 12% 158/1348 [00:02<00:22, 53.35it/s]\u001b[A\n",
      " 12% 164/1348 [00:03<00:22, 53.01it/s]\u001b[A\n",
      " 13% 170/1348 [00:03<00:22, 52.79it/s]\u001b[A\n",
      " 13% 176/1348 [00:03<00:22, 52.95it/s]\u001b[A\n",
      " 14% 182/1348 [00:03<00:22, 52.81it/s]\u001b[A\n",
      " 14% 188/1348 [00:03<00:21, 52.92it/s]\u001b[A\n",
      " 14% 194/1348 [00:03<00:21, 52.95it/s]\u001b[A\n",
      " 15% 200/1348 [00:03<00:21, 52.92it/s]\u001b[A\n",
      " 15% 206/1348 [00:03<00:21, 52.78it/s]\u001b[A\n",
      " 16% 212/1348 [00:03<00:21, 53.19it/s]\u001b[A\n",
      " 16% 218/1348 [00:04<00:21, 53.35it/s]\u001b[A\n",
      " 17% 224/1348 [00:04<00:20, 53.76it/s]\u001b[A\n",
      " 17% 230/1348 [00:04<00:20, 54.06it/s]\u001b[A\n",
      " 18% 236/1348 [00:04<00:20, 54.14it/s]\u001b[A\n",
      " 18% 242/1348 [00:04<00:20, 54.33it/s]\u001b[A\n",
      " 18% 248/1348 [00:04<00:20, 54.17it/s]\u001b[A\n",
      " 19% 254/1348 [00:04<00:20, 54.47it/s]\u001b[A\n",
      " 19% 260/1348 [00:04<00:19, 54.49it/s]\u001b[A\n",
      " 20% 266/1348 [00:04<00:19, 54.50it/s]\u001b[A\n",
      " 20% 272/1348 [00:05<00:19, 54.57it/s]\u001b[A\n",
      " 21% 278/1348 [00:05<00:19, 54.19it/s]\u001b[A\n",
      " 21% 284/1348 [00:05<00:19, 54.31it/s]\u001b[A\n",
      " 22% 290/1348 [00:05<00:19, 54.23it/s]\u001b[A\n",
      " 22% 296/1348 [00:05<00:19, 54.03it/s]\u001b[A\n",
      " 22% 302/1348 [00:05<00:19, 54.29it/s]\u001b[A\n",
      " 23% 308/1348 [00:05<00:19, 54.34it/s]\u001b[A\n",
      " 23% 314/1348 [00:05<00:18, 54.48it/s]\u001b[A\n",
      " 24% 320/1348 [00:05<00:18, 54.53it/s]\u001b[A\n",
      " 24% 326/1348 [00:06<00:18, 54.72it/s]\u001b[A\n",
      " 25% 332/1348 [00:06<00:18, 54.78it/s]\u001b[A\n",
      " 25% 338/1348 [00:06<00:18, 54.53it/s]\u001b[A\n",
      " 26% 344/1348 [00:06<00:18, 54.82it/s]\u001b[A\n",
      " 26% 350/1348 [00:06<00:18, 55.00it/s]\u001b[A\n",
      " 26% 356/1348 [00:06<00:18, 54.88it/s]\u001b[A\n",
      " 27% 362/1348 [00:06<00:17, 55.11it/s]\u001b[A\n",
      " 27% 368/1348 [00:06<00:17, 55.10it/s]\u001b[A\n",
      " 28% 374/1348 [00:06<00:17, 55.10it/s]\u001b[A\n",
      " 28% 380/1348 [00:07<00:17, 55.04it/s]\u001b[A\n",
      " 29% 386/1348 [00:07<00:17, 55.23it/s]\u001b[A\n",
      " 29% 392/1348 [00:07<00:17, 54.92it/s]\u001b[A\n",
      " 30% 398/1348 [00:07<00:17, 54.89it/s]\u001b[A\n",
      " 30% 404/1348 [00:07<00:17, 54.64it/s]\u001b[A\n",
      " 30% 410/1348 [00:07<00:17, 54.01it/s]\u001b[A\n",
      " 31% 416/1348 [00:07<00:17, 54.08it/s]\u001b[A\n",
      " 31% 422/1348 [00:07<00:17, 53.59it/s]\u001b[A\n",
      " 32% 428/1348 [00:07<00:17, 53.75it/s]\u001b[A\n",
      " 32% 434/1348 [00:08<00:16, 54.13it/s]\u001b[A\n",
      " 33% 440/1348 [00:08<00:16, 54.20it/s]\u001b[A\n",
      " 33% 446/1348 [00:08<00:16, 54.07it/s]\u001b[A\n",
      " 34% 452/1348 [00:08<00:16, 53.88it/s]\u001b[A\n",
      " 34% 458/1348 [00:08<00:16, 53.44it/s]\u001b[A\n",
      " 34% 464/1348 [00:08<00:16, 53.82it/s]\u001b[A\n",
      " 35% 470/1348 [00:08<00:16, 54.05it/s]\u001b[A\n",
      " 35% 476/1348 [00:08<00:16, 54.21it/s]\u001b[A\n",
      " 36% 482/1348 [00:08<00:15, 54.26it/s]\u001b[A\n",
      " 36% 488/1348 [00:09<00:15, 54.37it/s]\u001b[A\n",
      " 37% 494/1348 [00:09<00:15, 54.56it/s]\u001b[A\n",
      " 37% 500/1348 [00:09<00:15, 54.44it/s]\u001b[A\n",
      " 38% 506/1348 [00:09<00:15, 54.44it/s]\u001b[A\n",
      " 38% 512/1348 [00:09<00:15, 54.51it/s]\u001b[A\n",
      " 38% 518/1348 [00:09<00:15, 54.53it/s]\u001b[A\n",
      " 39% 524/1348 [00:09<00:15, 54.58it/s]\u001b[A\n",
      " 39% 530/1348 [00:09<00:15, 54.52it/s]\u001b[A\n",
      " 40% 536/1348 [00:09<00:14, 54.34it/s]\u001b[A\n",
      " 40% 542/1348 [00:09<00:14, 54.58it/s]\u001b[A\n",
      " 41% 548/1348 [00:10<00:14, 54.72it/s]\u001b[A\n",
      " 41% 554/1348 [00:10<00:14, 54.58it/s]\u001b[A\n",
      " 42% 560/1348 [00:10<00:14, 54.60it/s]\u001b[A\n",
      " 42% 566/1348 [00:10<00:14, 54.19it/s]\u001b[A\n",
      " 42% 572/1348 [00:10<00:14, 54.06it/s]\u001b[A\n",
      " 43% 578/1348 [00:10<00:14, 54.31it/s]\u001b[A\n",
      " 43% 584/1348 [00:10<00:14, 54.48it/s]\u001b[A\n",
      " 44% 590/1348 [00:10<00:13, 54.71it/s]\u001b[A\n",
      " 44% 596/1348 [00:10<00:13, 54.94it/s]\u001b[A\n",
      " 45% 602/1348 [00:11<00:13, 55.00it/s]\u001b[A\n",
      " 45% 608/1348 [00:11<00:13, 55.14it/s]\u001b[A\n",
      " 46% 614/1348 [00:11<00:13, 55.21it/s]\u001b[A\n",
      " 46% 620/1348 [00:11<00:13, 54.69it/s]\u001b[A\n",
      " 46% 626/1348 [00:11<00:13, 53.40it/s]\u001b[A\n",
      " 47% 632/1348 [00:11<00:13, 53.73it/s]\u001b[A\n",
      " 47% 638/1348 [00:11<00:13, 54.01it/s]\u001b[A\n",
      " 48% 644/1348 [00:11<00:13, 53.87it/s]\u001b[A\n",
      " 48% 650/1348 [00:11<00:12, 54.12it/s]\u001b[A\n",
      " 49% 656/1348 [00:12<00:12, 53.89it/s]\u001b[A\n",
      " 49% 662/1348 [00:12<00:12, 54.19it/s]\u001b[A\n",
      " 50% 668/1348 [00:12<00:12, 54.48it/s]\u001b[A\n",
      " 50% 674/1348 [00:12<00:12, 54.26it/s]\u001b[A\n",
      " 50% 680/1348 [00:12<00:12, 54.12it/s]\u001b[A\n",
      " 51% 686/1348 [00:12<00:12, 54.01it/s]\u001b[A\n",
      " 51% 692/1348 [00:12<00:12, 54.38it/s]\u001b[A\n",
      " 52% 698/1348 [00:12<00:12, 53.77it/s]\u001b[A\n",
      " 52% 704/1348 [00:12<00:11, 54.14it/s]\u001b[A\n",
      " 53% 710/1348 [00:13<00:11, 54.36it/s]\u001b[A\n",
      " 53% 716/1348 [00:13<00:11, 54.04it/s]\u001b[A\n",
      " 54% 722/1348 [00:13<00:11, 54.24it/s]\u001b[A\n",
      " 54% 728/1348 [00:13<00:11, 54.07it/s]\u001b[A\n",
      " 54% 734/1348 [00:13<00:11, 54.13it/s]\u001b[A\n",
      " 55% 740/1348 [00:13<00:11, 54.37it/s]\u001b[A\n",
      " 55% 746/1348 [00:13<00:11, 54.28it/s]\u001b[A\n",
      " 56% 752/1348 [00:13<00:11, 54.10it/s]\u001b[A\n",
      " 56% 758/1348 [00:13<00:11, 53.54it/s]\u001b[A\n",
      " 57% 764/1348 [00:14<00:10, 53.61it/s]\u001b[A\n",
      " 67% 11066/16599 [13:25<05:43, 16.13it/s]\n",
      " 58% 776/1348 [00:14<00:10, 53.84it/s]\u001b[A\n",
      " 58% 782/1348 [00:14<00:10, 54.27it/s]\u001b[A\n",
      " 58% 788/1348 [00:14<00:10, 54.54it/s]\u001b[A\n",
      " 59% 794/1348 [00:14<00:10, 54.32it/s]\u001b[A\n",
      " 59% 800/1348 [00:14<00:10, 54.20it/s]\u001b[A\n",
      " 60% 806/1348 [00:14<00:10, 54.19it/s]\u001b[A\n",
      " 60% 812/1348 [00:14<00:09, 54.59it/s]\u001b[A\n",
      " 61% 818/1348 [00:15<00:09, 54.88it/s]\u001b[A\n",
      " 61% 824/1348 [00:15<00:09, 54.74it/s]\u001b[A\n",
      " 62% 830/1348 [00:15<00:09, 55.02it/s]\u001b[A\n",
      " 62% 836/1348 [00:15<00:09, 54.81it/s]\u001b[A\n",
      " 62% 842/1348 [00:15<00:09, 53.54it/s]\u001b[A\n",
      " 63% 848/1348 [00:15<00:09, 53.35it/s]\u001b[A\n",
      " 63% 854/1348 [00:15<00:09, 53.56it/s]\u001b[A\n",
      " 64% 860/1348 [00:15<00:09, 53.76it/s]\u001b[A\n",
      " 64% 866/1348 [00:15<00:08, 54.22it/s]\u001b[A\n",
      " 65% 872/1348 [00:16<00:08, 54.53it/s]\u001b[A\n",
      " 65% 878/1348 [00:16<00:08, 54.02it/s]\u001b[A\n",
      " 66% 884/1348 [00:16<00:08, 54.06it/s]\u001b[A\n",
      " 66% 890/1348 [00:16<00:08, 54.50it/s]\u001b[A\n",
      " 66% 896/1348 [00:16<00:08, 54.54it/s]\u001b[A\n",
      " 67% 902/1348 [00:16<00:08, 54.76it/s]\u001b[A\n",
      " 67% 908/1348 [00:16<00:08, 54.88it/s]\u001b[A\n",
      " 68% 914/1348 [00:16<00:07, 54.64it/s]\u001b[A\n",
      " 68% 920/1348 [00:16<00:07, 54.13it/s]\u001b[A\n",
      " 69% 926/1348 [00:17<00:07, 54.25it/s]\u001b[A\n",
      " 69% 932/1348 [00:17<00:07, 54.05it/s]\u001b[A\n",
      " 70% 938/1348 [00:17<00:07, 54.35it/s]\u001b[A\n",
      " 70% 944/1348 [00:17<00:07, 54.28it/s]\u001b[A\n",
      " 70% 950/1348 [00:17<00:07, 54.30it/s]\u001b[A\n",
      " 71% 956/1348 [00:17<00:07, 54.37it/s]\u001b[A\n",
      " 71% 962/1348 [00:17<00:07, 54.32it/s]\u001b[A\n",
      " 72% 968/1348 [00:17<00:07, 53.94it/s]\u001b[A\n",
      " 72% 974/1348 [00:17<00:06, 54.09it/s]\u001b[A\n",
      " 73% 980/1348 [00:18<00:06, 53.92it/s]\u001b[A\n",
      " 73% 986/1348 [00:18<00:06, 53.90it/s]\u001b[A\n",
      " 74% 992/1348 [00:18<00:06, 53.93it/s]\u001b[A\n",
      " 74% 998/1348 [00:18<00:06, 53.81it/s]\u001b[A\n",
      " 74% 1004/1348 [00:18<00:06, 53.93it/s]\u001b[A\n",
      " 75% 1010/1348 [00:18<00:06, 53.88it/s]\u001b[A\n",
      " 75% 1016/1348 [00:18<00:06, 53.93it/s]\u001b[A\n",
      " 76% 1022/1348 [00:18<00:06, 54.06it/s]\u001b[A\n",
      " 76% 1028/1348 [00:18<00:05, 53.92it/s]\u001b[A\n",
      " 77% 1034/1348 [00:19<00:05, 54.03it/s]\u001b[A\n",
      " 77% 1040/1348 [00:19<00:05, 54.16it/s]\u001b[A\n",
      " 78% 1046/1348 [00:19<00:05, 54.40it/s]\u001b[A\n",
      " 78% 1052/1348 [00:19<00:05, 54.39it/s]\u001b[A\n",
      " 78% 1058/1348 [00:19<00:05, 54.43it/s]\u001b[A\n",
      " 79% 1064/1348 [00:19<00:05, 54.56it/s]\u001b[A\n",
      " 79% 1070/1348 [00:19<00:05, 54.46it/s]\u001b[A\n",
      " 80% 1076/1348 [00:19<00:04, 54.46it/s]\u001b[A\n",
      " 80% 1082/1348 [00:19<00:04, 54.11it/s]\u001b[A\n",
      " 81% 1088/1348 [00:20<00:04, 53.72it/s]\u001b[A\n",
      " 81% 1094/1348 [00:20<00:04, 53.81it/s]\u001b[A\n",
      " 82% 1100/1348 [00:20<00:04, 54.00it/s]\u001b[A\n",
      " 82% 1106/1348 [00:20<00:04, 54.13it/s]\u001b[A\n",
      " 82% 1112/1348 [00:20<00:04, 54.21it/s]\u001b[A\n",
      " 83% 1118/1348 [00:20<00:04, 54.39it/s]\u001b[A\n",
      " 83% 1124/1348 [00:20<00:04, 54.39it/s]\u001b[A\n",
      " 84% 1130/1348 [00:20<00:03, 54.50it/s]\u001b[A\n",
      " 84% 1136/1348 [00:20<00:03, 53.62it/s]\u001b[A\n",
      " 85% 1142/1348 [00:21<00:03, 53.59it/s]\u001b[A\n",
      " 85% 1148/1348 [00:21<00:03, 54.05it/s]\u001b[A\n",
      " 86% 1154/1348 [00:21<00:03, 54.13it/s]\u001b[A\n",
      " 86% 1160/1348 [00:21<00:03, 54.30it/s]\u001b[A\n",
      " 86% 1166/1348 [00:21<00:03, 54.50it/s]\u001b[A\n",
      " 87% 1172/1348 [00:21<00:03, 54.20it/s]\u001b[A\n",
      " 87% 1178/1348 [00:21<00:03, 54.26it/s]\u001b[A\n",
      " 88% 1184/1348 [00:21<00:03, 54.36it/s]\u001b[A\n",
      " 88% 1190/1348 [00:21<00:02, 54.55it/s]\u001b[A\n",
      " 89% 1196/1348 [00:22<00:02, 54.64it/s]\u001b[A\n",
      " 89% 1202/1348 [00:22<00:02, 54.72it/s]\u001b[A\n",
      " 90% 1208/1348 [00:22<00:02, 54.86it/s]\u001b[A\n",
      " 90% 1214/1348 [00:22<00:02, 55.04it/s]\u001b[A\n",
      " 91% 1220/1348 [00:22<00:02, 55.04it/s]\u001b[A\n",
      " 91% 1226/1348 [00:22<00:02, 55.01it/s]\u001b[A\n",
      " 91% 1232/1348 [00:22<00:02, 55.08it/s]\u001b[A\n",
      " 92% 1238/1348 [00:22<00:01, 55.15it/s]\u001b[A\n",
      " 92% 1244/1348 [00:22<00:01, 55.26it/s]\u001b[A\n",
      " 93% 1250/1348 [00:23<00:01, 55.11it/s]\u001b[A\n",
      " 93% 1256/1348 [00:23<00:01, 55.02it/s]\u001b[A\n",
      " 94% 1262/1348 [00:23<00:01, 54.88it/s]\u001b[A\n",
      " 94% 1268/1348 [00:23<00:01, 55.01it/s]\u001b[A\n",
      " 95% 1274/1348 [00:23<00:01, 55.01it/s]\u001b[A\n",
      " 95% 1280/1348 [00:23<00:01, 55.16it/s]\u001b[A\n",
      " 95% 1286/1348 [00:23<00:01, 54.91it/s]\u001b[A\n",
      " 96% 1292/1348 [00:23<00:01, 54.94it/s]\u001b[A\n",
      " 96% 1298/1348 [00:23<00:00, 55.08it/s]\u001b[A\n",
      " 97% 1304/1348 [00:24<00:00, 55.08it/s]\u001b[A\n",
      " 97% 1310/1348 [00:24<00:00, 55.29it/s]\u001b[A\n",
      " 98% 1316/1348 [00:24<00:00, 55.40it/s]\u001b[A\n",
      " 98% 1322/1348 [00:24<00:00, 55.40it/s]\u001b[A\n",
      " 99% 1328/1348 [00:24<00:00, 55.47it/s]\u001b[A\n",
      " 99% 1334/1348 [00:24<00:00, 55.57it/s]\u001b[A\n",
      " 99% 1340/1348 [00:24<00:00, 55.56it/s]\u001b[A\n",
      "100% 1346/1348 [00:24<00:00, 55.47it/s]\u001b[A12/01/2024 17:25:27 - INFO - utils_qa - Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 33/10570 [00:00<00:32, 322.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 69/10570 [00:00<00:30, 338.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 104/10570 [00:00<00:30, 342.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 141/10570 [00:00<00:29, 349.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 176/10570 [00:00<00:29, 348.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 211/10570 [00:00<00:30, 341.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 246/10570 [00:00<00:31, 329.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 280/10570 [00:00<00:37, 273.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 313/10570 [00:01<00:35, 288.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 348/10570 [00:01<00:33, 305.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 384/10570 [00:01<00:32, 318.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 417/10570 [00:01<00:31, 319.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 452/10570 [00:01<00:30, 327.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 487/10570 [00:01<00:30, 332.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 523/10570 [00:01<00:29, 338.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 558/10570 [00:01<00:29, 335.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 592/10570 [00:01<00:29, 335.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 627/10570 [00:01<00:29, 339.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 662/10570 [00:02<00:29, 339.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 697/10570 [00:02<00:28, 341.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 732/10570 [00:02<00:29, 338.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 766/10570 [00:02<00:29, 337.20it/s]\u001b[A\u001b[A\n",
      "100% 1348/1348 [00:39<00:00, 55.47it/s]\u001b[A\n",
      "\n",
      "  8% 800/10570 [00:02<00:29, 328.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 833/10570 [00:02<00:30, 322.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 867/10570 [00:02<00:29, 326.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 901/10570 [00:02<00:29, 330.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 935/10570 [00:02<00:29, 326.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 968/10570 [00:02<00:29, 325.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 1001/10570 [00:03<00:29, 324.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1034/10570 [00:03<00:29, 323.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1067/10570 [00:03<00:29, 321.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1100/10570 [00:03<00:30, 315.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1134/10570 [00:03<00:29, 321.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1168/10570 [00:03<00:28, 325.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1203/10570 [00:03<00:28, 330.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1237/10570 [00:03<00:27, 333.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1271/10570 [00:03<00:28, 331.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1306/10570 [00:03<00:27, 335.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1340/10570 [00:04<00:27, 332.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1374/10570 [00:04<00:27, 333.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1408/10570 [00:04<00:27, 328.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1442/10570 [00:04<00:27, 330.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1477/10570 [00:04<00:27, 333.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1511/10570 [00:04<00:27, 333.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1545/10570 [00:04<00:26, 335.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1580/10570 [00:04<00:26, 336.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1615/10570 [00:04<00:26, 340.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1650/10570 [00:05<00:26, 337.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1686/10570 [00:05<00:25, 343.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1721/10570 [00:05<00:26, 339.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1755/10570 [00:05<00:26, 337.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1790/10570 [00:05<00:25, 341.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1825/10570 [00:05<00:25, 337.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1859/10570 [00:05<00:25, 337.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1893/10570 [00:05<00:25, 338.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1929/10570 [00:05<00:25, 342.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 1964/10570 [00:05<00:25, 341.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 1999/10570 [00:06<00:25, 338.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2033/10570 [00:06<00:25, 338.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2068/10570 [00:06<00:24, 340.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2103/10570 [00:06<00:24, 342.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2138/10570 [00:06<00:27, 305.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2171/10570 [00:06<00:26, 312.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2204/10570 [00:06<00:26, 316.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2239/10570 [00:06<00:25, 325.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2272/10570 [00:06<00:25, 326.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2306/10570 [00:06<00:25, 329.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2340/10570 [00:07<00:24, 330.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2374/10570 [00:07<00:24, 328.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2407/10570 [00:07<00:24, 326.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2440/10570 [00:07<00:24, 326.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2473/10570 [00:07<00:24, 326.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2506/10570 [00:07<00:25, 312.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2538/10570 [00:07<00:25, 312.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2570/10570 [00:07<00:25, 308.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2604/10570 [00:07<00:25, 316.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2638/10570 [00:08<00:24, 322.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2673/10570 [00:08<00:24, 328.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2707/10570 [00:08<00:23, 331.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2741/10570 [00:08<00:23, 332.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2777/10570 [00:08<00:22, 340.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2812/10570 [00:08<00:22, 341.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2847/10570 [00:08<00:22, 339.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2881/10570 [00:08<00:22, 336.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2915/10570 [00:08<00:23, 332.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2949/10570 [00:08<00:22, 332.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2983/10570 [00:09<00:23, 329.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3017/10570 [00:09<00:22, 331.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3051/10570 [00:09<00:22, 330.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3085/10570 [00:09<00:22, 330.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3119/10570 [00:09<00:23, 323.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3152/10570 [00:09<00:22, 324.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3185/10570 [00:09<00:22, 323.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3219/10570 [00:09<00:22, 327.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3252/10570 [00:09<00:22, 325.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3285/10570 [00:09<00:22, 326.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3319/10570 [00:10<00:22, 329.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3353/10570 [00:10<00:21, 330.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3387/10570 [00:10<00:21, 330.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3421/10570 [00:10<00:21, 328.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3455/10570 [00:10<00:21, 330.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3489/10570 [00:10<00:21, 326.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3523/10570 [00:10<00:21, 327.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3557/10570 [00:10<00:21, 328.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3590/10570 [00:10<00:21, 325.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3623/10570 [00:11<00:21, 324.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3657/10570 [00:11<00:21, 326.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3691/10570 [00:11<00:20, 328.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3724/10570 [00:11<00:20, 327.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3758/10570 [00:11<00:20, 328.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3792/10570 [00:11<00:20, 332.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3826/10570 [00:11<00:20, 329.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3860/10570 [00:11<00:20, 332.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3894/10570 [00:11<00:20, 330.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3928/10570 [00:11<00:20, 330.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3962/10570 [00:12<00:19, 330.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 3996/10570 [00:12<00:19, 330.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4030/10570 [00:12<00:19, 329.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4064/10570 [00:12<00:19, 331.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4098/10570 [00:12<00:19, 328.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4131/10570 [00:12<00:20, 320.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4164/10570 [00:12<00:23, 268.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4193/10570 [00:12<00:25, 249.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4220/10570 [00:12<00:26, 243.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4253/10570 [00:13<00:23, 263.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4281/10570 [00:13<00:30, 205.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4304/10570 [00:13<00:32, 190.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4334/10570 [00:13<00:29, 214.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4367/10570 [00:13<00:25, 241.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4400/10570 [00:13<00:23, 263.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4433/10570 [00:13<00:21, 280.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4467/10570 [00:13<00:20, 295.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4498/10570 [00:14<00:20, 298.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4529/10570 [00:14<00:20, 292.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4561/10570 [00:14<00:20, 300.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4593/10570 [00:14<00:19, 304.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4624/10570 [00:14<00:20, 293.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4654/10570 [00:14<00:20, 285.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4686/10570 [00:14<00:20, 292.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4719/10570 [00:14<00:19, 301.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4751/10570 [00:14<00:18, 306.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4782/10570 [00:15<00:19, 291.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4815/10570 [00:15<00:19, 302.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4849/10570 [00:15<00:18, 310.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4881/10570 [00:15<00:19, 292.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4914/10570 [00:15<00:18, 302.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4947/10570 [00:15<00:18, 309.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4979/10570 [00:15<00:17, 311.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 5011/10570 [00:15<00:17, 309.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5043/10570 [00:15<00:17, 309.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5075/10570 [00:15<00:17, 312.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5108/10570 [00:16<00:17, 315.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5141/10570 [00:16<00:17, 318.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5174/10570 [00:16<00:16, 317.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5206/10570 [00:16<00:17, 313.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5239/10570 [00:16<00:16, 317.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5272/10570 [00:16<00:16, 319.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5306/10570 [00:16<00:16, 325.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5339/10570 [00:16<00:16, 318.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5372/10570 [00:16<00:16, 320.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5405/10570 [00:16<00:16, 322.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5438/10570 [00:17<00:15, 322.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5471/10570 [00:17<00:16, 300.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5502/10570 [00:17<00:17, 292.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5534/10570 [00:17<00:16, 297.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5566/10570 [00:17<00:16, 303.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5599/10570 [00:17<00:16, 310.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5631/10570 [00:17<00:16, 302.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5662/10570 [00:17<00:16, 293.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5695/10570 [00:17<00:16, 302.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5728/10570 [00:18<00:15, 309.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5761/10570 [00:18<00:15, 312.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5793/10570 [00:18<00:15, 312.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5825/10570 [00:18<00:15, 309.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5857/10570 [00:18<00:15, 312.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5891/10570 [00:18<00:14, 318.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5923/10570 [00:18<00:14, 317.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5956/10570 [00:18<00:14, 321.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 5989/10570 [00:18<00:14, 323.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6022/10570 [00:18<00:14, 320.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6055/10570 [00:19<00:14, 316.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6087/10570 [00:19<00:14, 316.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6119/10570 [00:19<00:14, 314.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6152/10570 [00:19<00:13, 318.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6185/10570 [00:19<00:13, 319.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6218/10570 [00:19<00:13, 318.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6250/10570 [00:19<00:14, 305.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6282/10570 [00:19<00:13, 309.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6316/10570 [00:19<00:13, 315.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6349/10570 [00:20<00:13, 317.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6381/10570 [00:20<00:13, 302.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6415/10570 [00:20<00:13, 311.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6449/10570 [00:20<00:12, 317.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6482/10570 [00:20<00:12, 318.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6515/10570 [00:20<00:12, 319.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6548/10570 [00:20<00:12, 322.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6581/10570 [00:20<00:12, 322.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6614/10570 [00:20<00:12, 320.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6648/10570 [00:20<00:12, 323.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6681/10570 [00:21<00:12, 323.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6714/10570 [00:21<00:12, 315.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6747/10570 [00:21<00:11, 319.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6781/10570 [00:21<00:11, 322.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6814/10570 [00:21<00:11, 321.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6847/10570 [00:21<00:11, 318.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6879/10570 [00:21<00:11, 318.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6911/10570 [00:21<00:11, 316.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6945/10570 [00:21<00:11, 322.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6978/10570 [00:21<00:11, 323.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 7011/10570 [00:22<00:12, 288.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7044/10570 [00:22<00:11, 299.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7077/10570 [00:22<00:11, 306.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7111/10570 [00:22<00:11, 314.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7145/10570 [00:22<00:10, 319.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7178/10570 [00:22<00:10, 321.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7211/10570 [00:22<00:10, 321.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7244/10570 [00:22<00:10, 321.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7277/10570 [00:22<00:10, 321.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7310/10570 [00:23<00:10, 323.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7343/10570 [00:23<00:10, 293.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7377/10570 [00:23<00:10, 304.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7410/10570 [00:23<00:10, 310.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7443/10570 [00:23<00:09, 315.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7476/10570 [00:23<00:09, 317.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7509/10570 [00:23<00:09, 321.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7542/10570 [00:23<00:09, 315.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7576/10570 [00:23<00:09, 320.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7609/10570 [00:24<00:09, 322.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7642/10570 [00:24<00:09, 324.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7675/10570 [00:24<00:09, 311.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7709/10570 [00:24<00:08, 317.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7743/10570 [00:24<00:08, 322.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7776/10570 [00:24<00:09, 306.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7809/10570 [00:24<00:08, 311.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7841/10570 [00:24<00:08, 313.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7875/10570 [00:24<00:08, 318.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7908/10570 [00:24<00:08, 321.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7942/10570 [00:25<00:08, 324.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7975/10570 [00:25<00:08, 323.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8008/10570 [00:25<00:07, 322.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8041/10570 [00:25<00:07, 322.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8074/10570 [00:25<00:07, 321.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8108/10570 [00:25<00:07, 325.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8141/10570 [00:25<00:07, 323.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8174/10570 [00:25<00:07, 319.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8206/10570 [00:25<00:07, 317.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8238/10570 [00:25<00:07, 315.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8270/10570 [00:26<00:07, 313.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8302/10570 [00:26<00:07, 301.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8334/10570 [00:26<00:07, 304.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8367/10570 [00:26<00:07, 309.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8400/10570 [00:26<00:06, 314.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8434/10570 [00:26<00:06, 318.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8468/10570 [00:26<00:06, 322.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8501/10570 [00:26<00:06, 321.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8534/10570 [00:26<00:06, 322.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8567/10570 [00:27<00:06, 322.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8600/10570 [00:27<00:06, 320.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8633/10570 [00:27<00:06, 321.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8666/10570 [00:27<00:05, 320.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8700/10570 [00:27<00:05, 323.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8733/10570 [00:27<00:05, 320.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8766/10570 [00:27<00:05, 320.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8799/10570 [00:27<00:05, 319.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8832/10570 [00:27<00:05, 320.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8865/10570 [00:27<00:05, 320.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8898/10570 [00:28<00:05, 320.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8931/10570 [00:28<00:05, 319.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8963/10570 [00:28<00:05, 317.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8996/10570 [00:28<00:04, 319.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 9029/10570 [00:28<00:04, 320.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9062/10570 [00:28<00:04, 319.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9094/10570 [00:28<00:04, 319.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9127/10570 [00:28<00:04, 320.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9160/10570 [00:28<00:04, 320.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9193/10570 [00:28<00:04, 321.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9226/10570 [00:29<00:04, 322.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9260/10570 [00:29<00:04, 325.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9293/10570 [00:29<00:03, 323.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9326/10570 [00:29<00:03, 323.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9359/10570 [00:29<00:03, 323.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9392/10570 [00:29<00:03, 323.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9425/10570 [00:29<00:03, 322.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9459/10570 [00:29<00:03, 325.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9492/10570 [00:29<00:03, 326.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9526/10570 [00:29<00:03, 328.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9560/10570 [00:30<00:03, 330.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9594/10570 [00:30<00:02, 327.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9628/10570 [00:30<00:02, 328.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9662/10570 [00:30<00:02, 329.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9695/10570 [00:30<00:02, 329.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9729/10570 [00:30<00:02, 331.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9763/10570 [00:30<00:02, 332.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9797/10570 [00:30<00:02, 330.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9831/10570 [00:30<00:02, 329.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9864/10570 [00:31<00:02, 319.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9897/10570 [00:31<00:02, 322.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9930/10570 [00:31<00:01, 323.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9963/10570 [00:31<00:01, 325.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 9996/10570 [00:31<00:01, 321.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10030/10570 [00:31<00:01, 325.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10063/10570 [00:31<00:01, 325.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10096/10570 [00:31<00:01, 324.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10130/10570 [00:31<00:01, 326.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10163/10570 [00:31<00:01, 318.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10196/10570 [00:32<00:01, 319.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10229/10570 [00:32<00:01, 322.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10262/10570 [00:32<00:00, 321.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10296/10570 [00:32<00:00, 324.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10329/10570 [00:32<00:00, 323.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10362/10570 [00:32<00:00, 317.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10394/10570 [00:32<00:00, 317.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10427/10570 [00:32<00:00, 317.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10459/10570 [00:32<00:00, 318.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10491/10570 [00:32<00:00, 318.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10524/10570 [00:33<00:00, 321.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10570/10570 [00:33<00:00, 318.16it/s]\n",
      "12/01/2024 17:26:00 - INFO - utils_qa - Saving predictions to ./output_qa/mix/eval_predictions.json.\n",
      "12/01/2024 17:26:00 - INFO - utils_qa - Saving nbest_preds to ./output_qa/mix/eval_nbest_predictions.json.\n",
      "                                         \n",
      "\u001b[A{'eval_exact_match': 79.89593188268685, 'eval_f1': 87.65097364229696, 'eval_runtime': 24.8465, 'eval_samples_per_second': 434.025, 'eval_steps_per_second': 54.253, 'epoch': 2.0}\n",
      " 67% 11066/16599 [14:25<05:43, 16.13it/s]\n",
      "100% 1348/1348 [01:14<00:00, 55.47it/s]\u001b[A\n",
      "{'loss': 0.2784, 'grad_norm': 10.798102378845215, 'learning_rate': 1.02536983733851e-05, 'epoch': 2.08}\n",
      "{'loss': 0.2478, 'grad_norm': 6.99989128112793, 'learning_rate': 9.24961510141241e-06, 'epoch': 2.17}\n",
      "{'loss': 0.2322, 'grad_norm': 16.406543731689453, 'learning_rate': 8.245531829439721e-06, 'epoch': 2.26}\n",
      "{'loss': 0.2322, 'grad_norm': 7.6754150390625, 'learning_rate': 7.2414485574670325e-06, 'epoch': 2.35}\n",
      "{'loss': 0.2369, 'grad_norm': 22.51957130432129, 'learning_rate': 6.239373452038289e-06, 'epoch': 2.44}\n",
      "{'loss': 0.2409, 'grad_norm': 8.238862037658691, 'learning_rate': 5.2352901800656e-06, 'epoch': 2.53}\n",
      "{'loss': 0.2251, 'grad_norm': 10.048910140991211, 'learning_rate': 4.231206908092911e-06, 'epoch': 2.62}\n",
      "{'loss': 0.2255, 'grad_norm': 13.494025230407715, 'learning_rate': 3.2271236361202225e-06, 'epoch': 2.71}\n",
      "{'loss': 0.2217, 'grad_norm': 17.571819305419922, 'learning_rate': 2.2230403641475333e-06, 'epoch': 2.8}\n",
      "{'loss': 0.2126, 'grad_norm': 16.16901397705078, 'learning_rate': 1.2189570921748444e-06, 'epoch': 2.89}\n",
      "{'loss': 0.2234, 'grad_norm': 13.12663459777832, 'learning_rate': 2.1487382020215546e-07, 'epoch': 2.98}\n",
      "100% 16599/16599 [20:23<00:00, 16.33it/s][INFO|trainer.py:3812] 2024-12-01 17:32:02,736 >> Saving model checkpoint to ./output_qa/mix/checkpoint-16599\n",
      "[INFO|configuration_utils.py:414] 2024-12-01 17:32:02,744 >> Configuration saved in ./output_qa/mix/checkpoint-16599/config.json\n",
      "[INFO|modeling_utils.py:3035] 2024-12-01 17:32:04,102 >> Model weights saved in ./output_qa/mix/checkpoint-16599/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-12-01 17:32:04,267 >> tokenizer config file saved in ./output_qa/mix/checkpoint-16599/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-12-01 17:32:04,272 >> Special tokens file saved in ./output_qa/mix/checkpoint-16599/special_tokens_map.json\n",
      "[INFO|trainer.py:875] 2024-12-01 17:32:08,995 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4128] 2024-12-01 17:32:08,998 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4130] 2024-12-01 17:32:08,998 >>   Num examples = 10784\n",
      "[INFO|trainer.py:4133] 2024-12-01 17:32:08,998 >>   Batch size = 8\n",
      "\n",
      "  0% 0/1348 [00:00<?, ?it/s]\u001b[A\n",
      "  1% 7/1348 [00:00<00:20, 64.33it/s]\u001b[A\n",
      "  1% 14/1348 [00:00<00:22, 58.83it/s]\u001b[A\n",
      "  1% 20/1348 [00:00<00:23, 57.38it/s]\u001b[A\n",
      "  2% 26/1348 [00:00<00:23, 56.75it/s]\u001b[A\n",
      "  2% 32/1348 [00:00<00:23, 56.33it/s]\u001b[A\n",
      "  3% 38/1348 [00:00<00:23, 56.09it/s]\u001b[A\n",
      "  3% 44/1348 [00:00<00:23, 55.79it/s]\u001b[A\n",
      "  4% 50/1348 [00:00<00:23, 55.73it/s]\u001b[A\n",
      "  4% 56/1348 [00:00<00:23, 55.65it/s]\u001b[A\n",
      "  5% 62/1348 [00:01<00:23, 55.64it/s]\u001b[A\n",
      "  5% 68/1348 [00:01<00:23, 55.26it/s]\u001b[A\n",
      "  5% 74/1348 [00:01<00:23, 55.31it/s]\u001b[A\n",
      "  6% 80/1348 [00:01<00:22, 55.44it/s]\u001b[A\n",
      "  6% 86/1348 [00:01<00:22, 55.23it/s]\u001b[A\n",
      "  7% 92/1348 [00:01<00:22, 55.04it/s]\u001b[A\n",
      "  7% 98/1348 [00:01<00:22, 55.07it/s]\u001b[A\n",
      "  8% 104/1348 [00:01<00:22, 55.09it/s]\u001b[A\n",
      "  8% 110/1348 [00:01<00:22, 54.42it/s]\u001b[A\n",
      "  9% 116/1348 [00:02<00:22, 54.72it/s]\u001b[A\n",
      "  9% 122/1348 [00:02<00:22, 54.68it/s]\u001b[A\n",
      "  9% 128/1348 [00:02<00:22, 54.73it/s]\u001b[A\n",
      " 10% 134/1348 [00:02<00:22, 54.81it/s]\u001b[A\n",
      " 10% 140/1348 [00:02<00:22, 54.79it/s]\u001b[A\n",
      " 11% 146/1348 [00:02<00:21, 54.81it/s]\u001b[A\n",
      " 11% 152/1348 [00:02<00:21, 54.84it/s]\u001b[A\n",
      " 12% 158/1348 [00:02<00:21, 54.56it/s]\u001b[A\n",
      " 12% 164/1348 [00:02<00:21, 54.46it/s]\u001b[A\n",
      " 13% 170/1348 [00:03<00:21, 54.71it/s]\u001b[A\n",
      " 13% 176/1348 [00:03<00:21, 54.78it/s]\u001b[A\n",
      " 14% 182/1348 [00:03<00:21, 54.86it/s]\u001b[A\n",
      " 14% 188/1348 [00:03<00:21, 55.03it/s]\u001b[A\n",
      " 14% 194/1348 [00:03<00:21, 54.57it/s]\u001b[A\n",
      " 15% 200/1348 [00:03<00:21, 54.61it/s]\u001b[A\n",
      " 15% 206/1348 [00:03<00:20, 54.67it/s]\u001b[A\n",
      " 16% 212/1348 [00:03<00:20, 54.70it/s]\u001b[A\n",
      " 16% 218/1348 [00:03<00:20, 54.83it/s]\u001b[A\n",
      " 17% 224/1348 [00:04<00:20, 54.86it/s]\u001b[A\n",
      " 17% 230/1348 [00:04<00:20, 54.89it/s]\u001b[A\n",
      " 18% 236/1348 [00:04<00:20, 54.91it/s]\u001b[A\n",
      " 18% 242/1348 [00:04<00:20, 55.01it/s]\u001b[A\n",
      " 18% 248/1348 [00:04<00:19, 55.05it/s]\u001b[A\n",
      " 19% 254/1348 [00:04<00:19, 55.12it/s]\u001b[A\n",
      " 19% 260/1348 [00:04<00:19, 55.04it/s]\u001b[A\n",
      " 20% 266/1348 [00:04<00:19, 55.13it/s]\u001b[A\n",
      " 20% 272/1348 [00:04<00:19, 55.17it/s]\u001b[A\n",
      " 21% 278/1348 [00:05<00:19, 55.19it/s]\u001b[A\n",
      " 21% 284/1348 [00:05<00:19, 55.24it/s]\u001b[A\n",
      " 22% 290/1348 [00:05<00:19, 55.30it/s]\u001b[A\n",
      " 22% 296/1348 [00:05<00:18, 55.38it/s]\u001b[A\n",
      " 22% 302/1348 [00:05<00:18, 55.38it/s]\u001b[A\n",
      " 23% 308/1348 [00:05<00:18, 55.32it/s]\u001b[A\n",
      " 23% 314/1348 [00:05<00:18, 55.07it/s]\u001b[A\n",
      "100% 16599/16599 [20:35<00:00, 16.33it/s]\n",
      " 24% 326/1348 [00:05<00:18, 54.94it/s]\u001b[A\n",
      " 25% 332/1348 [00:06<00:18, 54.81it/s]\u001b[A\n",
      " 25% 338/1348 [00:06<00:18, 54.80it/s]\u001b[A\n",
      " 26% 344/1348 [00:06<00:18, 54.86it/s]\u001b[A\n",
      " 26% 350/1348 [00:06<00:18, 54.46it/s]\u001b[A\n",
      " 26% 356/1348 [00:06<00:18, 54.52it/s]\u001b[A\n",
      " 27% 362/1348 [00:06<00:18, 54.17it/s]\u001b[A\n",
      " 27% 368/1348 [00:06<00:18, 53.23it/s]\u001b[A\n",
      " 28% 374/1348 [00:06<00:18, 52.97it/s]\u001b[A\n",
      " 28% 380/1348 [00:06<00:18, 53.16it/s]\u001b[A\n",
      " 29% 386/1348 [00:07<00:17, 53.47it/s]\u001b[A\n",
      " 29% 392/1348 [00:07<00:17, 53.65it/s]\u001b[A\n",
      " 30% 398/1348 [00:07<00:17, 53.73it/s]\u001b[A\n",
      " 30% 404/1348 [00:07<00:17, 53.72it/s]\u001b[A\n",
      " 30% 410/1348 [00:07<00:17, 53.74it/s]\u001b[A\n",
      " 31% 416/1348 [00:07<00:17, 53.80it/s]\u001b[A\n",
      " 31% 422/1348 [00:07<00:17, 54.04it/s]\u001b[A\n",
      " 32% 428/1348 [00:07<00:16, 54.31it/s]\u001b[A\n",
      " 32% 434/1348 [00:07<00:16, 54.55it/s]\u001b[A\n",
      " 33% 440/1348 [00:08<00:16, 54.41it/s]\u001b[A\n",
      " 33% 446/1348 [00:08<00:16, 53.46it/s]\u001b[A\n",
      " 34% 452/1348 [00:08<00:17, 50.68it/s]\u001b[A\n",
      " 34% 458/1348 [00:08<00:17, 51.76it/s]\u001b[A\n",
      " 34% 464/1348 [00:08<00:16, 52.10it/s]\u001b[A\n",
      " 35% 470/1348 [00:08<00:16, 52.83it/s]\u001b[A\n",
      " 35% 476/1348 [00:08<00:17, 50.85it/s]\u001b[A\n",
      " 36% 482/1348 [00:08<00:16, 51.51it/s]\u001b[A\n",
      " 36% 488/1348 [00:08<00:16, 52.46it/s]\u001b[A\n",
      " 37% 494/1348 [00:09<00:16, 53.05it/s]\u001b[A\n",
      " 37% 500/1348 [00:09<00:15, 53.53it/s]\u001b[A\n",
      " 38% 506/1348 [00:09<00:15, 53.71it/s]\u001b[A\n",
      " 38% 512/1348 [00:09<00:15, 54.04it/s]\u001b[A\n",
      " 38% 518/1348 [00:09<00:15, 54.04it/s]\u001b[A\n",
      " 39% 524/1348 [00:09<00:15, 54.17it/s]\u001b[A\n",
      " 39% 530/1348 [00:09<00:15, 53.73it/s]\u001b[A\n",
      " 40% 536/1348 [00:09<00:15, 51.75it/s]\u001b[A\n",
      " 40% 542/1348 [00:09<00:15, 52.59it/s]\u001b[A\n",
      " 41% 548/1348 [00:10<00:15, 53.12it/s]\u001b[A\n",
      " 41% 554/1348 [00:10<00:14, 53.58it/s]\u001b[A\n",
      " 42% 560/1348 [00:10<00:14, 54.06it/s]\u001b[A\n",
      " 42% 566/1348 [00:10<00:14, 54.33it/s]\u001b[A\n",
      " 42% 572/1348 [00:10<00:15, 50.74it/s]\u001b[A\n",
      " 43% 578/1348 [00:10<00:14, 51.75it/s]\u001b[A\n",
      " 43% 584/1348 [00:10<00:14, 52.24it/s]\u001b[A\n",
      " 44% 590/1348 [00:10<00:14, 53.22it/s]\u001b[A\n",
      " 44% 596/1348 [00:10<00:14, 51.57it/s]\u001b[A\n",
      " 45% 602/1348 [00:11<00:14, 50.25it/s]\u001b[A\n",
      " 45% 608/1348 [00:11<00:14, 51.78it/s]\u001b[A\n",
      " 46% 614/1348 [00:11<00:13, 52.85it/s]\u001b[A\n",
      " 46% 620/1348 [00:11<00:13, 53.71it/s]\u001b[A\n",
      " 46% 626/1348 [00:11<00:13, 54.28it/s]\u001b[A\n",
      " 47% 632/1348 [00:11<00:13, 54.30it/s]\u001b[A\n",
      " 47% 638/1348 [00:11<00:13, 54.08it/s]\u001b[A\n",
      " 48% 644/1348 [00:11<00:12, 54.46it/s]\u001b[A\n",
      " 48% 650/1348 [00:11<00:12, 54.73it/s]\u001b[A\n",
      " 49% 656/1348 [00:12<00:12, 55.11it/s]\u001b[A\n",
      " 49% 662/1348 [00:12<00:12, 55.23it/s]\u001b[A\n",
      " 50% 668/1348 [00:12<00:12, 55.35it/s]\u001b[A\n",
      " 50% 674/1348 [00:12<00:12, 55.44it/s]\u001b[A\n",
      " 50% 680/1348 [00:12<00:12, 55.30it/s]\u001b[A\n",
      " 51% 686/1348 [00:12<00:12, 55.03it/s]\u001b[A\n",
      " 51% 692/1348 [00:12<00:11, 55.06it/s]\u001b[A\n",
      " 52% 698/1348 [00:12<00:11, 54.80it/s]\u001b[A\n",
      " 52% 704/1348 [00:12<00:11, 54.89it/s]\u001b[A\n",
      " 53% 710/1348 [00:13<00:11, 54.99it/s]\u001b[A\n",
      " 53% 716/1348 [00:13<00:11, 54.68it/s]\u001b[A\n",
      " 54% 722/1348 [00:13<00:11, 54.73it/s]\u001b[A\n",
      " 54% 728/1348 [00:13<00:11, 54.56it/s]\u001b[A\n",
      " 54% 734/1348 [00:13<00:11, 53.50it/s]\u001b[A\n",
      " 55% 740/1348 [00:13<00:11, 53.79it/s]\u001b[A\n",
      " 55% 746/1348 [00:13<00:11, 53.40it/s]\u001b[A\n",
      " 56% 752/1348 [00:13<00:11, 53.75it/s]\u001b[A\n",
      " 56% 758/1348 [00:13<00:10, 54.27it/s]\u001b[A\n",
      " 57% 764/1348 [00:14<00:10, 54.51it/s]\u001b[A\n",
      " 57% 770/1348 [00:14<00:10, 54.69it/s]\u001b[A\n",
      " 58% 776/1348 [00:14<00:10, 54.68it/s]\u001b[A\n",
      " 58% 782/1348 [00:14<00:10, 54.89it/s]\u001b[A\n",
      " 58% 788/1348 [00:14<00:10, 53.37it/s]\u001b[A\n",
      " 59% 794/1348 [00:14<00:11, 50.29it/s]\u001b[A\n",
      " 59% 800/1348 [00:14<00:10, 50.32it/s]\u001b[A\n",
      " 60% 806/1348 [00:14<00:10, 50.72it/s]\u001b[A\n",
      " 60% 812/1348 [00:15<00:10, 49.12it/s]\u001b[A\n",
      " 61% 817/1348 [00:15<00:10, 48.78it/s]\u001b[A\n",
      " 61% 823/1348 [00:15<00:10, 49.99it/s]\u001b[A\n",
      " 61% 829/1348 [00:15<00:10, 51.45it/s]\u001b[A\n",
      " 62% 835/1348 [00:15<00:10, 51.17it/s]\u001b[A\n",
      " 62% 841/1348 [00:15<00:10, 49.39it/s]\u001b[A\n",
      " 63% 846/1348 [00:15<00:10, 48.69it/s]\u001b[A\n",
      " 63% 852/1348 [00:15<00:09, 49.70it/s]\u001b[A\n",
      " 64% 858/1348 [00:15<00:09, 51.02it/s]\u001b[A\n",
      " 64% 864/1348 [00:16<00:09, 51.56it/s]\u001b[A\n",
      " 65% 870/1348 [00:16<00:09, 49.42it/s]\u001b[A\n",
      " 65% 875/1348 [00:16<00:09, 49.37it/s]\u001b[A\n",
      " 65% 881/1348 [00:16<00:09, 50.77it/s]\u001b[A\n",
      " 66% 887/1348 [00:16<00:08, 51.33it/s]\u001b[A\n",
      " 66% 893/1348 [00:16<00:08, 51.99it/s]\u001b[A\n",
      " 67% 899/1348 [00:16<00:08, 49.96it/s]\u001b[A\n",
      " 67% 905/1348 [00:16<00:09, 48.46it/s]\u001b[A\n",
      " 68% 911/1348 [00:16<00:08, 49.91it/s]\u001b[A\n",
      " 68% 917/1348 [00:17<00:08, 50.86it/s]\u001b[A\n",
      " 68% 923/1348 [00:17<00:08, 51.73it/s]\u001b[A\n",
      " 69% 929/1348 [00:17<00:08, 50.90it/s]\u001b[A\n",
      " 69% 935/1348 [00:17<00:08, 47.53it/s]\u001b[A\n",
      " 70% 941/1348 [00:17<00:08, 48.84it/s]\u001b[A\n",
      " 70% 947/1348 [00:17<00:08, 49.79it/s]\u001b[A\n",
      " 71% 953/1348 [00:17<00:07, 51.30it/s]\u001b[A\n",
      " 71% 959/1348 [00:17<00:07, 48.92it/s]\u001b[A\n",
      " 72% 964/1348 [00:18<00:08, 45.31it/s]\u001b[A\n",
      " 72% 970/1348 [00:18<00:07, 47.92it/s]\u001b[A\n",
      " 72% 976/1348 [00:18<00:07, 49.18it/s]\u001b[A\n",
      " 73% 982/1348 [00:18<00:07, 50.87it/s]\u001b[A\n",
      " 73% 988/1348 [00:18<00:07, 47.96it/s]\u001b[A\n",
      " 74% 993/1348 [00:18<00:07, 45.83it/s]\u001b[A\n",
      " 74% 999/1348 [00:18<00:07, 47.38it/s]\u001b[A\n",
      " 75% 1005/1348 [00:18<00:06, 49.23it/s]\u001b[A\n",
      " 75% 1011/1348 [00:19<00:06, 49.68it/s]\u001b[A\n",
      " 75% 1017/1348 [00:19<00:06, 51.21it/s]\u001b[A\n",
      " 76% 1023/1348 [00:19<00:07, 46.23it/s]\u001b[A\n",
      " 76% 1028/1348 [00:19<00:07, 45.12it/s]\u001b[A\n",
      " 77% 1034/1348 [00:19<00:06, 47.80it/s]\u001b[A\n",
      " 77% 1040/1348 [00:19<00:06, 48.20it/s]\u001b[A\n",
      " 78% 1046/1348 [00:19<00:06, 50.01it/s]\u001b[A\n",
      " 78% 1052/1348 [00:19<00:06, 47.93it/s]\u001b[A\n",
      " 78% 1057/1348 [00:20<00:06, 45.35it/s]\u001b[A\n",
      " 79% 1063/1348 [00:20<00:05, 47.86it/s]\u001b[A\n",
      " 79% 1069/1348 [00:20<00:05, 48.78it/s]\u001b[A\n",
      " 80% 1075/1348 [00:20<00:05, 50.45it/s]\u001b[A\n",
      " 80% 1081/1348 [00:20<00:05, 47.04it/s]\u001b[A\n",
      " 81% 1086/1348 [00:20<00:05, 44.70it/s]\u001b[A\n",
      " 81% 1092/1348 [00:20<00:05, 47.46it/s]\u001b[A\n",
      " 81% 1098/1348 [00:20<00:05, 48.82it/s]\u001b[A\n",
      " 82% 1104/1348 [00:20<00:04, 50.64it/s]\u001b[A\n",
      " 82% 1110/1348 [00:21<00:05, 46.33it/s]\u001b[A\n",
      " 83% 1115/1348 [00:21<00:05, 45.04it/s]\u001b[A\n",
      " 83% 1121/1348 [00:21<00:04, 47.59it/s]\u001b[A\n",
      " 84% 1127/1348 [00:21<00:04, 48.77it/s]\u001b[A\n",
      " 84% 1133/1348 [00:21<00:04, 50.72it/s]\u001b[A\n",
      " 84% 1139/1348 [00:21<00:04, 48.81it/s]\u001b[A\n",
      " 85% 1144/1348 [00:21<00:04, 45.08it/s]\u001b[A\n",
      " 85% 1150/1348 [00:21<00:04, 47.92it/s]\u001b[A\n",
      " 86% 1156/1348 [00:22<00:03, 49.07it/s]\u001b[A\n",
      " 86% 1162/1348 [00:22<00:03, 50.85it/s]\u001b[A\n",
      " 87% 1168/1348 [00:22<00:03, 50.02it/s]\u001b[A\n",
      " 87% 1174/1348 [00:22<00:03, 47.03it/s]\u001b[A\n",
      " 87% 1179/1348 [00:22<00:03, 47.04it/s]\u001b[A\n",
      " 88% 1185/1348 [00:22<00:03, 49.30it/s]\u001b[A\n",
      " 88% 1191/1348 [00:22<00:03, 49.94it/s]\u001b[A\n",
      " 89% 1197/1348 [00:22<00:02, 51.30it/s]\u001b[A\n",
      " 89% 1203/1348 [00:23<00:03, 46.71it/s]\u001b[A\n",
      " 90% 1208/1348 [00:23<00:03, 44.87it/s]\u001b[A\n",
      " 90% 1214/1348 [00:23<00:02, 46.92it/s]\u001b[A\n",
      " 91% 1220/1348 [00:23<00:02, 48.20it/s]\u001b[A\n",
      " 91% 1226/1348 [00:23<00:02, 50.14it/s]\u001b[A\n",
      " 91% 1232/1348 [00:23<00:02, 48.86it/s]\u001b[A\n",
      " 92% 1237/1348 [00:23<00:02, 46.33it/s]\u001b[A\n",
      " 92% 1243/1348 [00:23<00:02, 48.38it/s]\u001b[A\n",
      " 93% 1249/1348 [00:23<00:01, 49.73it/s]\u001b[A\n",
      " 93% 1255/1348 [00:24<00:01, 51.18it/s]\u001b[A\n",
      " 94% 1261/1348 [00:24<00:01, 50.99it/s]\u001b[A\n",
      " 94% 1267/1348 [00:24<00:01, 45.86it/s]\u001b[A\n",
      " 94% 1273/1348 [00:24<00:01, 47.34it/s]\u001b[A\n",
      " 95% 1279/1348 [00:24<00:01, 49.64it/s]\u001b[A\n",
      " 95% 1285/1348 [00:24<00:01, 50.63it/s]\u001b[A\n",
      " 96% 1291/1348 [00:24<00:01, 52.17it/s]\u001b[A\n",
      " 96% 1297/1348 [00:24<00:01, 47.86it/s]\u001b[A\n",
      " 97% 1302/1348 [00:25<00:01, 45.22it/s]\u001b[A\n",
      " 97% 1308/1348 [00:25<00:00, 47.74it/s]\u001b[A\n",
      " 97% 1314/1348 [00:25<00:00, 49.29it/s]\u001b[A\n",
      " 98% 1320/1348 [00:25<00:00, 51.12it/s]\u001b[A\n",
      " 98% 1326/1348 [00:25<00:00, 50.60it/s]\u001b[A\n",
      " 99% 1332/1348 [00:25<00:00, 46.24it/s]\u001b[A\n",
      " 99% 1338/1348 [00:25<00:00, 48.42it/s]\u001b[A\n",
      "100% 1344/1348 [00:25<00:00, 49.86it/s]\u001b[A12/01/2024 17:32:48 - INFO - utils_qa - Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0% 33/10570 [00:00<00:32, 323.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 68/10570 [00:00<00:31, 335.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 103/10570 [00:00<00:30, 338.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1% 139/10570 [00:00<00:30, 347.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 174/10570 [00:00<00:30, 345.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 209/10570 [00:00<00:30, 340.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2% 244/10570 [00:00<00:31, 327.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 277/10570 [00:00<00:37, 270.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 311/10570 [00:01<00:35, 287.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3% 346/10570 [00:01<00:33, 303.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 382/10570 [00:01<00:32, 316.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 415/10570 [00:01<00:31, 317.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 450/10570 [00:01<00:31, 325.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 485/10570 [00:01<00:30, 330.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 521/10570 [00:01<00:29, 337.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 555/10570 [00:01<00:29, 336.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 589/10570 [00:01<00:29, 336.46it/s]\u001b[A\u001b[A\n",
      "100% 1348/1348 [00:40<00:00, 49.86it/s]\u001b[A\n",
      "\n",
      "  6% 624/10570 [00:01<00:29, 338.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6% 659/10570 [00:02<00:29, 339.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 694/10570 [00:02<00:50, 196.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 727/10570 [00:02<00:44, 221.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 760/10570 [00:02<00:40, 245.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 792/10570 [00:02<00:37, 261.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 823/10570 [00:02<00:35, 272.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 857/10570 [00:02<00:33, 288.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 891/10570 [00:02<00:32, 300.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 923/10570 [00:03<00:31, 304.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 957/10570 [00:03<00:30, 312.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9% 990/10570 [00:03<00:30, 313.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1023/10570 [00:03<00:30, 315.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1056/10570 [00:03<00:29, 318.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 1089/10570 [00:03<00:29, 320.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1122/10570 [00:03<00:30, 313.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1157/10570 [00:03<00:29, 321.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 1192/10570 [00:03<00:28, 328.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1226/10570 [00:04<00:28, 331.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1260/10570 [00:04<00:28, 329.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 1295/10570 [00:04<00:27, 334.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1329/10570 [00:04<00:28, 325.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1362/10570 [00:04<00:28, 325.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 1395/10570 [00:04<00:28, 322.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1428/10570 [00:04<00:28, 323.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1462/10570 [00:04<00:27, 327.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1496/10570 [00:04<00:27, 330.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14% 1530/10570 [00:04<00:27, 332.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1565/10570 [00:05<00:26, 335.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1599/10570 [00:05<00:26, 337.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15% 1633/10570 [00:05<00:26, 335.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1668/10570 [00:05<00:26, 339.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1703/10570 [00:05<00:25, 341.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 1738/10570 [00:05<00:26, 338.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1772/10570 [00:05<00:25, 338.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1807/10570 [00:05<00:25, 339.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 1841/10570 [00:05<00:25, 337.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1876/10570 [00:05<00:25, 338.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1911/10570 [00:06<00:25, 340.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 1946/10570 [00:06<00:25, 338.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 1981/10570 [00:06<00:25, 339.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2016/10570 [00:06<00:25, 337.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 2050/10570 [00:06<00:25, 338.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2084/10570 [00:06<00:25, 338.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2118/10570 [00:06<00:25, 334.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 2152/10570 [00:06<00:27, 308.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2185/10570 [00:06<00:26, 313.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2220/10570 [00:07<00:25, 322.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 2254/10570 [00:07<00:25, 326.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2288/10570 [00:07<00:25, 330.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2322/10570 [00:07<00:24, 330.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 2357/10570 [00:07<00:24, 334.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2391/10570 [00:07<00:24, 329.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2425/10570 [00:07<00:24, 329.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 2458/10570 [00:07<00:24, 327.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2492/10570 [00:07<00:24, 328.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2525/10570 [00:07<00:25, 310.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 2557/10570 [00:08<00:25, 310.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2590/10570 [00:08<00:25, 314.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2624/10570 [00:08<00:24, 321.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2659/10570 [00:08<00:24, 327.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 2693/10570 [00:08<00:23, 328.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2728/10570 [00:08<00:23, 332.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2763/10570 [00:08<00:23, 336.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 2799/10570 [00:08<00:22, 341.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2834/10570 [00:08<00:22, 340.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2869/10570 [00:08<00:22, 336.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 2903/10570 [00:09<00:23, 332.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2937/10570 [00:09<00:22, 333.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 2971/10570 [00:09<00:22, 331.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 3005/10570 [00:09<00:22, 331.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3039/10570 [00:09<00:22, 332.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3073/10570 [00:09<00:22, 329.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 3107/10570 [00:09<00:22, 330.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3141/10570 [00:09<00:22, 327.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3174/10570 [00:09<00:22, 326.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 3207/10570 [00:10<00:22, 326.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3240/10570 [00:10<00:22, 324.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3273/10570 [00:10<00:22, 325.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 3306/10570 [00:10<00:22, 325.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3340/10570 [00:10<00:22, 327.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3374/10570 [00:10<00:21, 329.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 3407/10570 [00:10<00:21, 329.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3440/10570 [00:10<00:21, 328.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3473/10570 [00:10<00:21, 328.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3506/10570 [00:10<00:21, 327.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 3540/10570 [00:11<00:21, 329.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3573/10570 [00:11<00:21, 327.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3606/10570 [00:11<00:21, 325.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 3640/10570 [00:11<00:21, 327.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3674/10570 [00:11<00:20, 329.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3707/10570 [00:11<00:20, 328.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 3740/10570 [00:11<00:23, 288.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3774/10570 [00:11<00:22, 301.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3805/10570 [00:11<00:22, 300.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 3839/10570 [00:11<00:21, 309.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3873/10570 [00:12<00:21, 316.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3905/10570 [00:12<00:21, 312.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 3939/10570 [00:12<00:20, 317.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 3973/10570 [00:12<00:20, 322.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4006/10570 [00:12<00:20, 323.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 4040/10570 [00:12<00:19, 327.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4074/10570 [00:12<00:19, 329.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4107/10570 [00:12<00:20, 322.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4140/10570 [00:12<00:20, 316.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 4172/10570 [00:13<00:24, 265.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4200/10570 [00:13<00:26, 240.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4226/10570 [00:13<00:25, 244.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 4257/10570 [00:13<00:24, 259.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4284/10570 [00:13<00:32, 196.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4307/10570 [00:13<00:33, 188.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4340/10570 [00:13<00:28, 220.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 4374/10570 [00:14<00:24, 247.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4407/10570 [00:14<00:23, 267.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4441/10570 [00:14<00:21, 285.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 4475/10570 [00:14<00:20, 299.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4507/10570 [00:14<00:19, 303.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4539/10570 [00:14<00:19, 305.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 4572/10570 [00:14<00:19, 310.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4604/10570 [00:14<00:19, 298.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4637/10570 [00:14<00:19, 306.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4668/10570 [00:14<00:20, 292.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 4702/10570 [00:15<00:19, 304.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4735/10570 [00:15<00:18, 311.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4767/10570 [00:15<00:19, 298.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 4799/10570 [00:15<00:19, 302.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4833/10570 [00:15<00:18, 311.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4865/10570 [00:15<00:19, 294.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 4898/10570 [00:15<00:18, 303.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4931/10570 [00:15<00:18, 311.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4963/10570 [00:15<00:18, 307.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 4995/10570 [00:16<00:18, 309.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5027/10570 [00:16<00:17, 309.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5060/10570 [00:16<00:17, 315.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5092/10570 [00:16<00:17, 316.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 5126/10570 [00:16<00:16, 321.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5159/10570 [00:16<00:16, 322.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5192/10570 [00:16<00:16, 320.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 5225/10570 [00:16<00:16, 318.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5257/10570 [00:16<00:16, 316.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5292/10570 [00:16<00:16, 323.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 5326/10570 [00:17<00:16, 325.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5359/10570 [00:17<00:15, 326.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5393/10570 [00:17<00:15, 328.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 5426/10570 [00:17<00:15, 321.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5459/10570 [00:17<00:17, 299.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5490/10570 [00:17<00:17, 289.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 5522/10570 [00:17<00:17, 295.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5554/10570 [00:17<00:16, 301.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5586/10570 [00:17<00:16, 305.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5618/10570 [00:17<00:16, 308.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 5649/10570 [00:18<00:16, 306.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5680/10570 [00:18<00:16, 293.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5712/10570 [00:18<00:16, 298.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 5743/10570 [00:18<00:16, 301.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5775/10570 [00:18<00:15, 304.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5806/10570 [00:18<00:16, 296.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 5839/10570 [00:18<00:15, 303.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5871/10570 [00:18<00:15, 307.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5904/10570 [00:18<00:14, 313.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5936/10570 [00:19<00:14, 314.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 5969/10570 [00:19<00:14, 319.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6002/10570 [00:19<00:14, 319.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6035/10570 [00:19<00:14, 318.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 6067/10570 [00:19<00:14, 315.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6099/10570 [00:19<00:14, 316.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6132/10570 [00:19<00:13, 318.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 6166/10570 [00:19<00:13, 321.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6199/10570 [00:19<00:13, 322.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6232/10570 [00:19<00:14, 308.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 6265/10570 [00:20<00:13, 313.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6299/10570 [00:20<00:13, 318.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6332/10570 [00:20<00:13, 320.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 6365/10570 [00:20<00:13, 319.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6398/10570 [00:20<00:13, 306.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6432/10570 [00:20<00:13, 314.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6466/10570 [00:20<00:12, 320.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 6499/10570 [00:20<00:12, 320.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6532/10570 [00:20<00:12, 323.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6565/10570 [00:21<00:12, 323.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 6598/10570 [00:21<00:12, 321.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6632/10570 [00:21<00:12, 324.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6665/10570 [00:21<00:12, 318.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 6697/10570 [00:21<00:12, 316.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6729/10570 [00:21<00:12, 317.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6763/10570 [00:21<00:11, 321.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 6796/10570 [00:21<00:11, 322.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6829/10570 [00:21<00:11, 320.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6862/10570 [00:21<00:11, 316.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 6895/10570 [00:22<00:11, 317.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6928/10570 [00:22<00:11, 320.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6961/10570 [00:22<00:11, 322.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 6994/10570 [00:22<00:11, 323.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 7028/10570 [00:22<00:10, 325.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7061/10570 [00:22<00:10, 326.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7094/10570 [00:22<00:10, 325.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 7128/10570 [00:22<00:10, 327.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7162/10570 [00:22<00:10, 329.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7195/10570 [00:22<00:10, 327.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 7228/10570 [00:23<00:10, 325.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7261/10570 [00:23<00:10, 324.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7294/10570 [00:23<00:10, 324.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 7327/10570 [00:23<00:10, 321.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7360/10570 [00:23<00:10, 295.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7392/10570 [00:23<00:10, 301.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 7426/10570 [00:23<00:10, 309.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7459/10570 [00:23<00:09, 313.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7491/10570 [00:23<00:09, 314.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 7525/10570 [00:24<00:09, 320.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7558/10570 [00:24<00:09, 321.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7591/10570 [00:24<00:09, 323.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7625/10570 [00:24<00:09, 325.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 7658/10570 [00:24<00:09, 309.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7692/10570 [00:24<00:09, 317.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7725/10570 [00:24<00:08, 319.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 7758/10570 [00:24<00:09, 308.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7790/10570 [00:24<00:08, 310.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7822/10570 [00:24<00:08, 312.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 7855/10570 [00:25<00:08, 316.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7888/10570 [00:25<00:08, 320.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7922/10570 [00:25<00:08, 324.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 7955/10570 [00:25<00:08, 322.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 7988/10570 [00:25<00:08, 320.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8021/10570 [00:25<00:07, 322.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 8054/10570 [00:25<00:08, 308.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8088/10570 [00:25<00:07, 315.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8122/10570 [00:25<00:07, 320.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8155/10570 [00:26<00:07, 316.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 8187/10570 [00:26<00:07, 317.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8219/10570 [00:26<00:07, 313.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8251/10570 [00:26<00:07, 313.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 8283/10570 [00:26<00:07, 294.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8317/10570 [00:26<00:07, 304.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8349/10570 [00:26<00:07, 308.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 8382/10570 [00:26<00:07, 312.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8416/10570 [00:26<00:06, 318.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8450/10570 [00:26<00:06, 323.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 8483/10570 [00:27<00:06, 316.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8516/10570 [00:27<00:06, 319.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8549/10570 [00:27<00:06, 322.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 8582/10570 [00:27<00:06, 316.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8615/10570 [00:27<00:06, 318.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8648/10570 [00:27<00:06, 319.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8681/10570 [00:27<00:05, 318.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 8714/10570 [00:27<00:05, 321.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8747/10570 [00:27<00:05, 320.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8780/10570 [00:27<00:05, 317.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 8812/10570 [00:28<00:05, 316.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8844/10570 [00:28<00:05, 317.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8877/10570 [00:28<00:05, 320.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 8910/10570 [00:28<00:05, 316.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8943/10570 [00:28<00:05, 319.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 8975/10570 [00:28<00:04, 319.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 9008/10570 [00:28<00:04, 321.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9041/10570 [00:28<00:04, 319.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9073/10570 [00:28<00:04, 319.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9105/10570 [00:28<00:04, 318.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 9138/10570 [00:29<00:04, 321.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9171/10570 [00:29<00:04, 318.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9204/10570 [00:29<00:04, 320.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 9237/10570 [00:29<00:04, 319.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9270/10570 [00:29<00:04, 320.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9303/10570 [00:29<00:03, 319.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 9335/10570 [00:29<00:03, 318.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9368/10570 [00:29<00:03, 320.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9401/10570 [00:29<00:03, 319.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 9433/10570 [00:30<00:03, 311.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9467/10570 [00:30<00:03, 317.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9500/10570 [00:30<00:03, 318.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9532/10570 [00:30<00:03, 316.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 9565/10570 [00:30<00:03, 319.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9598/10570 [00:30<00:03, 320.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9631/10570 [00:30<00:02, 320.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 9665/10570 [00:30<00:02, 324.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9698/10570 [00:30<00:02, 325.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9732/10570 [00:30<00:02, 328.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 9765/10570 [00:31<00:02, 328.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9798/10570 [00:31<00:02, 326.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9831/10570 [00:31<00:02, 326.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 9864/10570 [00:31<00:02, 323.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9897/10570 [00:31<00:02, 324.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9930/10570 [00:31<00:01, 325.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 9963/10570 [00:31<00:01, 325.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 9996/10570 [00:31<00:01, 322.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10030/10570 [00:31<00:01, 325.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 10063/10570 [00:31<00:01, 326.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10096/10570 [00:32<00:01, 324.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10130/10570 [00:32<00:01, 326.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10163/10570 [00:32<00:01, 318.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 10195/10570 [00:32<00:01, 318.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10228/10570 [00:32<00:01, 321.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10261/10570 [00:32<00:00, 311.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97% 10294/10570 [00:32<00:00, 316.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10326/10570 [00:32<00:00, 317.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10359/10570 [00:32<00:00, 318.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98% 10391/10570 [00:33<00:00, 317.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10423/10570 [00:33<00:00, 318.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10456/10570 [00:33<00:00, 319.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99% 10488/10570 [00:33<00:00, 318.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10521/10570 [00:33<00:00, 319.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 10570/10570 [00:33<00:00, 314.97it/s]\n",
      "12/01/2024 17:33:21 - INFO - utils_qa - Saving predictions to ./output_qa/mix/eval_predictions.json.\n",
      "12/01/2024 17:33:21 - INFO - utils_qa - Saving nbest_preds to ./output_qa/mix/eval_nbest_predictions.json.\n",
      "                                         \n",
      "\u001b[A{'eval_exact_match': 77.76726584673605, 'eval_f1': 86.80214156242586, 'eval_runtime': 26.0436, 'eval_samples_per_second': 414.075, 'eval_steps_per_second': 51.759, 'epoch': 3.0}\n",
      "100% 16599/16599 [21:46<00:00, 16.33it/s]\n",
      "100% 1348/1348 [01:16<00:00, 49.86it/s]\u001b[A\n",
      "                                       \u001b[A[INFO|trainer.py:2591] 2024-12-01 17:33:26,037 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 1306.3091, 'train_samples_per_second': 203.3, 'train_steps_per_second': 12.707, 'train_loss': 0.7538944467075389, 'epoch': 3.0}\n",
      "100% 16599/16599 [21:46<00:00, 12.71it/s]\n",
      "[INFO|trainer.py:3812] 2024-12-01 17:33:26,040 >> Saving model checkpoint to ./output_qa/mix\n",
      "[INFO|configuration_utils.py:414] 2024-12-01 17:33:26,046 >> Configuration saved in ./output_qa/mix/config.json\n",
      "[INFO|modeling_utils.py:3035] 2024-12-01 17:33:27,376 >> Model weights saved in ./output_qa/mix/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2646] 2024-12-01 17:33:27,563 >> tokenizer config file saved in ./output_qa/mix/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2024-12-01 17:33:27,567 >> Special tokens file saved in ./output_qa/mix/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  total_flos               = 48470522GF\n",
      "  train_loss               =     0.7539\n",
      "  train_runtime            = 0:21:46.30\n",
      "  train_samples            =      88524\n",
      "  train_samples_per_second =      203.3\n",
      "  train_steps_per_second   =     12.707\n",
      "12/01/2024 17:33:28 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:875] 2024-12-01 17:33:28,729 >> The following columns in the evaluation set don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:4128] 2024-12-01 17:33:28,732 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4130] 2024-12-01 17:33:28,732 >>   Num examples = 10784\n",
      "[INFO|trainer.py:4133] 2024-12-01 17:33:28,732 >>   Batch size = 8\n",
      "100% 1348/1348 [00:36<00:00, 53.80it/s]12/01/2024 17:34:05 - INFO - utils_qa - Post-processing 10570 example predictions split into 10784 features.\n",
      "\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\n",
      "  0% 33/10570 [00:00<00:32, 323.93it/s]\u001b[A\n",
      "  1% 68/10570 [00:00<00:31, 336.10it/s]\u001b[A\n",
      "  1% 103/10570 [00:00<00:30, 339.89it/s]\u001b[A\n",
      "  1% 137/10570 [00:00<01:00, 172.07it/s]\u001b[A\n",
      "  2% 171/10570 [00:00<00:49, 208.88it/s]\u001b[A\n",
      "  2% 205/10570 [00:00<00:43, 238.65it/s]\u001b[A\n",
      "  2% 236/10570 [00:00<00:40, 255.47it/s]\u001b[A\n",
      "  3% 266/10570 [00:01<00:43, 236.83it/s]\u001b[A\n",
      "  3% 294/10570 [00:01<00:41, 247.21it/s]\u001b[A\n",
      "  3% 329/10570 [00:01<00:37, 273.21it/s]\u001b[A\n",
      "  3% 364/10570 [00:01<00:34, 292.64it/s]\u001b[A\n",
      "  4% 398/10570 [00:01<00:33, 304.64it/s]\u001b[A\n",
      "  4% 431/10570 [00:01<00:32, 311.13it/s]\u001b[A\n",
      "  4% 465/10570 [00:01<00:31, 317.08it/s]\u001b[A\n",
      "  5% 499/10570 [00:01<00:31, 323.55it/s]\u001b[A\n",
      "  5% 535/10570 [00:01<00:30, 332.39it/s]\u001b[A\n",
      "  5% 569/10570 [00:02<00:31, 322.20it/s]\u001b[A\n",
      "  6% 602/10570 [00:02<00:30, 323.60it/s]\u001b[A\n",
      "  6% 638/10570 [00:02<00:29, 331.23it/s]\u001b[A\n",
      "  6% 673/10570 [00:02<00:29, 335.04it/s]\u001b[A\n",
      "  7% 707/10570 [00:02<00:29, 335.09it/s]\u001b[A\n",
      "  7% 741/10570 [00:02<00:29, 333.12it/s]\u001b[A\n",
      "  7% 775/10570 [00:02<00:29, 329.88it/s]\u001b[A\n",
      "  8% 809/10570 [00:02<00:30, 321.47it/s]\u001b[A\n",
      "  8% 842/10570 [00:02<00:30, 320.62it/s]\u001b[A\n",
      "  8% 876/10570 [00:02<00:29, 326.18it/s]\u001b[A\n",
      "  9% 909/10570 [00:03<00:29, 324.31it/s]\u001b[A\n",
      "  9% 942/10570 [00:03<00:29, 324.67it/s]\u001b[A\n",
      "  9% 975/10570 [00:03<00:29, 324.90it/s]\u001b[A\n",
      " 10% 1008/10570 [00:03<00:29, 323.99it/s]\u001b[A\n",
      " 10% 1041/10570 [00:03<00:29, 322.26it/s]\u001b[A\n",
      " 10% 1074/10570 [00:03<00:29, 323.32it/s]\u001b[A\n",
      " 10% 1107/10570 [00:03<00:30, 313.97it/s]\u001b[A\n",
      " 11% 1141/10570 [00:03<00:29, 319.60it/s]\u001b[A\n",
      " 11% 1176/10570 [00:03<00:28, 327.96it/s]\u001b[A\n",
      " 11% 1210/10570 [00:03<00:28, 330.82it/s]\u001b[A\n",
      " 12% 1245/10570 [00:04<00:27, 335.41it/s]\u001b[A\n",
      " 12% 1279/10570 [00:04<00:27, 332.59it/s]\u001b[A\n",
      " 12% 1314/10570 [00:04<00:27, 335.54it/s]\u001b[A\n",
      " 13% 1348/10570 [00:04<00:27, 334.89it/s]\u001b[A\n",
      " 13% 1382/10570 [00:04<00:27, 331.30it/s]\u001b[A\n",
      " 13% 1416/10570 [00:04<00:27, 331.63it/s]\u001b[A\n",
      " 14% 1450/10570 [00:04<00:27, 330.55it/s]\u001b[A\n",
      " 14% 1484/10570 [00:04<00:27, 331.61it/s]\u001b[A\n",
      " 14% 1518/10570 [00:04<00:27, 331.30it/s]\u001b[A\n",
      " 15% 1553/10570 [00:05<00:26, 334.11it/s]\u001b[A\n",
      " 15% 1587/10570 [00:05<00:26, 334.41it/s]\u001b[A\n",
      " 15% 1622/10570 [00:05<00:26, 337.06it/s]\u001b[A\n",
      " 16% 1657/10570 [00:05<00:26, 339.85it/s]\u001b[A\n",
      " 16% 1693/10570 [00:05<00:25, 343.61it/s]\u001b[A\n",
      " 16% 1728/10570 [00:05<00:25, 342.99it/s]\u001b[A\n",
      " 17% 1763/10570 [00:05<00:26, 331.67it/s]\u001b[A\n",
      " 17% 1797/10570 [00:05<00:26, 333.97it/s]\u001b[A\n",
      " 17% 1831/10570 [00:05<00:26, 334.24it/s]\u001b[A\n",
      " 18% 1865/10570 [00:05<00:26, 325.48it/s]\u001b[A\n",
      " 18% 1901/10570 [00:06<00:25, 333.85it/s]\u001b[A\n",
      " 18% 1936/10570 [00:06<00:25, 336.56it/s]\u001b[A\n",
      " 19% 1971/10570 [00:06<00:25, 340.25it/s]\u001b[A\n",
      " 19% 2006/10570 [00:06<00:25, 337.94it/s]\u001b[A\n",
      " 19% 2040/10570 [00:06<00:25, 338.15it/s]\u001b[A\n",
      " 20% 2075/10570 [00:06<00:24, 340.98it/s]\u001b[A\n",
      " 20% 2110/10570 [00:06<00:24, 341.86it/s]\u001b[A\n",
      " 20% 2145/10570 [00:06<00:27, 310.35it/s]\u001b[A\n",
      " 21% 2178/10570 [00:06<00:26, 314.54it/s]\u001b[A\n",
      " 21% 2213/10570 [00:07<00:25, 323.17it/s]\u001b[A\n",
      " 21% 2248/10570 [00:07<00:25, 328.77it/s]\u001b[A\n",
      " 22% 2282/10570 [00:07<00:25, 330.44it/s]\u001b[A\n",
      " 22% 2316/10570 [00:07<00:24, 330.92it/s]\u001b[A\n",
      " 22% 2350/10570 [00:07<00:24, 332.81it/s]\u001b[A\n",
      " 23% 2384/10570 [00:07<00:24, 330.20it/s]\u001b[A\n",
      " 23% 2418/10570 [00:07<00:24, 330.30it/s]\u001b[A\n",
      " 23% 2452/10570 [00:07<00:24, 328.82it/s]\u001b[A\n",
      " 24% 2486/10570 [00:07<00:24, 330.50it/s]\u001b[A\n",
      " 24% 2520/10570 [00:07<00:25, 314.16it/s]\u001b[A\n",
      " 24% 2552/10570 [00:08<00:25, 314.23it/s]\u001b[A\n",
      " 24% 2584/10570 [00:08<00:25, 315.72it/s]\u001b[A\n",
      " 25% 2618/10570 [00:08<00:24, 322.68it/s]\u001b[A\n",
      " 25% 2651/10570 [00:08<00:24, 323.44it/s]\u001b[A\n",
      " 25% 2684/10570 [00:08<00:24, 323.59it/s]\u001b[A\n",
      " 26% 2719/10570 [00:08<00:23, 328.80it/s]\u001b[A\n",
      " 26% 2754/10570 [00:08<00:23, 333.45it/s]\u001b[A\n",
      " 26% 2790/10570 [00:08<00:22, 339.56it/s]\u001b[A\n",
      " 27% 2824/10570 [00:08<00:22, 338.20it/s]\u001b[A\n",
      " 27% 2858/10570 [00:08<00:22, 336.27it/s]\u001b[A\n",
      " 27% 2892/10570 [00:09<00:23, 333.38it/s]\u001b[A\n",
      " 28% 2926/10570 [00:09<00:22, 333.42it/s]\u001b[A\n",
      " 28% 2960/10570 [00:09<00:22, 333.74it/s]\u001b[A\n",
      " 28% 2994/10570 [00:09<00:22, 332.08it/s]\u001b[A\n",
      " 29% 3028/10570 [00:09<00:22, 332.41it/s]\u001b[A\n",
      " 29% 3062/10570 [00:09<00:22, 332.10it/s]\u001b[A\n",
      " 29% 3096/10570 [00:09<00:22, 331.76it/s]\u001b[A\n",
      " 30% 3130/10570 [00:09<00:22, 331.83it/s]\u001b[A\n",
      " 30% 3164/10570 [00:09<00:22, 328.72it/s]\u001b[A\n",
      " 30% 3197/10570 [00:09<00:22, 325.35it/s]\u001b[A\n",
      " 31% 3230/10570 [00:10<00:23, 317.61it/s]\u001b[A\n",
      " 31% 3263/10570 [00:10<00:22, 320.02it/s]\u001b[A\n",
      " 31% 3296/10570 [00:10<00:23, 312.34it/s]\u001b[A\n",
      " 32% 3330/10570 [00:10<00:22, 318.28it/s]\u001b[A\n",
      " 32% 3364/10570 [00:10<00:22, 321.93it/s]\u001b[A\n",
      " 32% 3397/10570 [00:10<00:22, 323.30it/s]\u001b[A\n",
      " 32% 3431/10570 [00:10<00:21, 325.32it/s]\u001b[A\n",
      " 33% 3464/10570 [00:10<00:21, 326.53it/s]\u001b[A\n",
      " 33% 3497/10570 [00:10<00:21, 325.75it/s]\u001b[A\n",
      " 33% 3530/10570 [00:11<00:21, 324.73it/s]\u001b[A\n",
      " 34% 3563/10570 [00:11<00:21, 325.46it/s]\u001b[A\n",
      " 34% 3596/10570 [00:11<00:21, 322.61it/s]\u001b[A\n",
      " 34% 3630/10570 [00:11<00:21, 325.43it/s]\u001b[A\n",
      " 35% 3663/10570 [00:11<00:21, 321.57it/s]\u001b[A\n",
      " 35% 3697/10570 [00:11<00:21, 324.48it/s]\u001b[A\n",
      " 35% 3730/10570 [00:11<00:21, 316.84it/s]\u001b[A\n",
      " 36% 3764/10570 [00:11<00:21, 321.12it/s]\u001b[A\n",
      " 36% 3797/10570 [00:11<00:21, 322.06it/s]\u001b[A\n",
      " 36% 3831/10570 [00:11<00:20, 324.99it/s]\u001b[A\n",
      " 37% 3865/10570 [00:12<00:20, 327.22it/s]\u001b[A\n",
      " 37% 3898/10570 [00:12<00:20, 323.10it/s]\u001b[A\n",
      " 37% 3931/10570 [00:12<00:20, 317.45it/s]\u001b[A\n",
      " 38% 3964/10570 [00:12<00:20, 319.21it/s]\u001b[A\n",
      " 38% 3997/10570 [00:12<00:20, 321.63it/s]\u001b[A\n",
      " 38% 4030/10570 [00:12<00:20, 322.46it/s]\u001b[A\n",
      " 38% 4064/10570 [00:12<00:19, 326.67it/s]\u001b[A\n",
      " 39% 4097/10570 [00:12<00:19, 325.27it/s]\u001b[A\n",
      " 39% 4130/10570 [00:12<00:20, 310.30it/s]\u001b[A\n",
      " 39% 4162/10570 [00:13<00:24, 258.68it/s]\u001b[A\n",
      " 40% 4190/10570 [00:13<00:26, 244.15it/s]\u001b[A\n",
      " 40% 4216/10570 [00:13<00:26, 236.14it/s]\u001b[A\n",
      " 40% 4248/10570 [00:13<00:24, 256.98it/s]\u001b[A\n",
      " 40% 4275/10570 [00:13<00:29, 212.82it/s]\u001b[A\n",
      " 41% 4298/10570 [00:13<00:32, 194.02it/s]\u001b[A\n",
      " 41% 4319/10570 [00:13<00:32, 190.98it/s]\u001b[A\n",
      " 41% 4352/10570 [00:13<00:27, 223.10it/s]\u001b[A\n",
      " 41% 4384/10570 [00:14<00:25, 247.26it/s]\u001b[A\n",
      " 42% 4416/10570 [00:14<00:23, 266.40it/s]\u001b[A\n",
      " 42% 4444/10570 [00:14<00:22, 269.81it/s]\u001b[A\n",
      " 42% 4477/10570 [00:14<00:21, 286.08it/s]\u001b[A\n",
      " 43% 4509/10570 [00:14<00:20, 293.38it/s]\u001b[A\n",
      " 43% 4540/10570 [00:14<00:20, 297.49it/s]\u001b[A\n",
      " 43% 4573/10570 [00:14<00:19, 304.98it/s]\u001b[A\n",
      " 44% 4604/10570 [00:14<00:20, 291.76it/s]\u001b[A\n",
      " 44% 4637/10570 [00:14<00:19, 300.95it/s]\u001b[A\n",
      " 44% 4668/10570 [00:15<00:20, 290.01it/s]\u001b[A\n",
      " 44% 4701/10570 [00:15<00:19, 300.86it/s]\u001b[A\n",
      " 45% 4735/10570 [00:15<00:18, 310.23it/s]\u001b[A\n",
      " 45% 4767/10570 [00:15<00:19, 297.72it/s]\u001b[A\n",
      " 45% 4798/10570 [00:15<00:19, 299.77it/s]\u001b[A\n",
      " 46% 4832/10570 [00:15<00:18, 310.39it/s]\u001b[A\n",
      " 46% 4864/10570 [00:15<00:19, 292.19it/s]\u001b[A\n",
      " 46% 4897/10570 [00:15<00:18, 301.92it/s]\u001b[A\n",
      " 47% 4930/10570 [00:15<00:18, 309.14it/s]\u001b[A\n",
      " 47% 4963/10570 [00:15<00:17, 313.81it/s]\u001b[A\n",
      " 47% 4995/10570 [00:16<00:17, 313.99it/s]\u001b[A\n",
      " 48% 5027/10570 [00:16<00:17, 313.02it/s]\u001b[A\n",
      " 48% 5061/10570 [00:16<00:17, 318.39it/s]\u001b[A\n",
      " 48% 5093/10570 [00:16<00:17, 317.80it/s]\u001b[A\n",
      " 49% 5127/10570 [00:16<00:16, 323.08it/s]\u001b[A\n",
      " 49% 5160/10570 [00:16<00:16, 324.19it/s]\u001b[A\n",
      " 49% 5193/10570 [00:16<00:16, 324.02it/s]\u001b[A\n",
      " 49% 5227/10570 [00:16<00:16, 326.07it/s]\u001b[A\n",
      " 50% 5260/10570 [00:16<00:16, 324.92it/s]\u001b[A\n",
      " 50% 5294/10570 [00:16<00:16, 329.15it/s]\u001b[A\n",
      " 50% 5327/10570 [00:17<00:16, 323.79it/s]\u001b[A\n",
      " 51% 5360/10570 [00:17<00:16, 321.74it/s]\u001b[A\n",
      " 51% 5393/10570 [00:17<00:16, 321.73it/s]\u001b[A\n",
      " 51% 5426/10570 [00:17<00:15, 322.14it/s]\u001b[A\n",
      " 52% 5459/10570 [00:17<00:16, 307.08it/s]\u001b[A\n",
      " 52% 5490/10570 [00:17<00:17, 293.31it/s]\u001b[A\n",
      " 52% 5522/10570 [00:17<00:16, 299.09it/s]\u001b[A\n",
      " 53% 5554/10570 [00:17<00:16, 304.48it/s]\u001b[A\n",
      " 53% 5586/10570 [00:17<00:16, 308.12it/s]\u001b[A\n",
      " 53% 5618/10570 [00:18<00:15, 310.80it/s]\u001b[A\n",
      " 53% 5650/10570 [00:18<00:15, 310.61it/s]\u001b[A\n",
      " 54% 5682/10570 [00:18<00:16, 301.29it/s]\u001b[A\n",
      " 54% 5716/10570 [00:18<00:15, 310.05it/s]\u001b[A\n",
      " 54% 5748/10570 [00:18<00:15, 312.68it/s]\u001b[A\n",
      " 55% 5781/10570 [00:18<00:15, 315.07it/s]\u001b[A\n",
      " 55% 5813/10570 [00:18<00:15, 315.63it/s]\u001b[A\n",
      " 55% 5846/10570 [00:18<00:14, 316.53it/s]\u001b[A\n",
      " 56% 5879/10570 [00:18<00:14, 319.66it/s]\u001b[A\n",
      " 56% 5912/10570 [00:18<00:14, 321.15it/s]\u001b[A\n",
      " 56% 5945/10570 [00:19<00:14, 319.98it/s]\u001b[A\n",
      " 57% 5979/10570 [00:19<00:14, 323.81it/s]\u001b[A\n",
      " 57% 6012/10570 [00:19<00:14, 321.70it/s]\u001b[A\n",
      " 57% 6045/10570 [00:19<00:14, 311.41it/s]\u001b[A\n",
      " 57% 6077/10570 [00:19<00:14, 311.46it/s]\u001b[A\n",
      " 58% 6110/10570 [00:19<00:14, 314.68it/s]\u001b[A\n",
      " 58% 6144/10570 [00:19<00:13, 319.89it/s]\u001b[A\n",
      " 58% 6177/10570 [00:19<00:13, 322.54it/s]\u001b[A\n",
      " 59% 6210/10570 [00:19<00:13, 321.29it/s]\u001b[A\n",
      " 59% 6243/10570 [00:20<00:14, 307.79it/s]\u001b[A\n",
      " 59% 6276/10570 [00:20<00:13, 312.89it/s]\u001b[A\n",
      " 60% 6310/10570 [00:20<00:13, 319.10it/s]\u001b[A\n",
      " 60% 6343/10570 [00:20<00:13, 321.06it/s]\u001b[A\n",
      " 60% 6376/10570 [00:20<00:13, 313.84it/s]\u001b[A\n",
      " 61% 6408/10570 [00:20<00:13, 310.77it/s]\u001b[A\n",
      " 61% 6442/10570 [00:20<00:12, 317.85it/s]\u001b[A\n",
      " 61% 6475/10570 [00:20<00:12, 321.32it/s]\u001b[A\n",
      " 62% 6508/10570 [00:20<00:12, 320.72it/s]\u001b[A\n",
      " 62% 6542/10570 [00:20<00:12, 323.73it/s]\u001b[A\n",
      " 62% 6575/10570 [00:21<00:12, 314.65it/s]\u001b[A\n",
      " 63% 6607/10570 [00:21<00:12, 315.29it/s]\u001b[A\n",
      " 63% 6641/10570 [00:21<00:12, 321.68it/s]\u001b[A\n",
      " 63% 6674/10570 [00:21<00:12, 323.54it/s]\u001b[A\n",
      " 63% 6707/10570 [00:21<00:12, 320.31it/s]\u001b[A\n",
      " 64% 6740/10570 [00:21<00:11, 321.83it/s]\u001b[A\n",
      " 64% 6775/10570 [00:21<00:11, 327.54it/s]\u001b[A\n",
      " 64% 6808/10570 [00:21<00:11, 324.70it/s]\u001b[A\n",
      " 65% 6841/10570 [00:21<00:11, 320.05it/s]\u001b[A\n",
      " 65% 6874/10570 [00:22<00:11, 320.00it/s]\u001b[A\n",
      " 65% 6907/10570 [00:22<00:11, 320.84it/s]\u001b[A\n",
      " 66% 6941/10570 [00:22<00:11, 325.81it/s]\u001b[A\n",
      " 66% 6974/10570 [00:22<00:11, 326.72it/s]\u001b[A\n",
      " 66% 7008/10570 [00:22<00:10, 329.47it/s]\u001b[A\n",
      " 67% 7042/10570 [00:22<00:10, 330.41it/s]\u001b[A\n",
      " 67% 7076/10570 [00:22<00:10, 328.65it/s]\u001b[A\n",
      " 67% 7110/10570 [00:22<00:10, 331.06it/s]\u001b[A\n",
      " 68% 7144/10570 [00:22<00:10, 331.32it/s]\u001b[A\n",
      " 68% 7178/10570 [00:22<00:10, 330.62it/s]\u001b[A\n",
      " 68% 7212/10570 [00:23<00:10, 328.46it/s]\u001b[A\n",
      " 69% 7245/10570 [00:23<00:10, 325.64it/s]\u001b[A\n",
      " 69% 7278/10570 [00:23<00:10, 325.02it/s]\u001b[A\n",
      " 69% 7312/10570 [00:23<00:09, 326.98it/s]\u001b[A\n",
      " 69% 7345/10570 [00:23<00:10, 296.77it/s]\u001b[A\n",
      " 70% 7378/10570 [00:23<00:10, 305.32it/s]\u001b[A\n",
      " 70% 7411/10570 [00:23<00:10, 311.93it/s]\u001b[A\n",
      " 70% 7444/10570 [00:23<00:09, 317.10it/s]\u001b[A\n",
      " 71% 7477/10570 [00:23<00:09, 319.16it/s]\u001b[A\n",
      " 71% 7511/10570 [00:23<00:09, 322.68it/s]\u001b[A\n",
      " 71% 7544/10570 [00:24<00:09, 315.20it/s]\u001b[A\n",
      " 72% 7578/10570 [00:24<00:09, 321.15it/s]\u001b[A\n",
      " 72% 7612/10570 [00:24<00:09, 324.12it/s]\u001b[A\n",
      " 72% 7645/10570 [00:24<00:08, 325.58it/s]\u001b[A\n",
      " 73% 7678/10570 [00:24<00:09, 313.37it/s]\u001b[A\n",
      " 73% 7712/10570 [00:24<00:08, 318.50it/s]\u001b[A\n",
      " 73% 7745/10570 [00:24<00:08, 316.64it/s]\u001b[A\n",
      " 74% 7777/10570 [00:24<00:09, 308.12it/s]\u001b[A\n",
      " 74% 7810/10570 [00:24<00:08, 311.42it/s]\u001b[A\n",
      " 74% 7842/10570 [00:25<00:08, 313.47it/s]\u001b[A\n",
      " 75% 7875/10570 [00:25<00:08, 317.83it/s]\u001b[A\n",
      " 75% 7908/10570 [00:25<00:08, 320.67it/s]\u001b[A\n",
      " 75% 7941/10570 [00:25<00:08, 313.58it/s]\u001b[A\n",
      " 75% 7973/10570 [00:25<00:08, 315.08it/s]\u001b[A\n",
      " 76% 8006/10570 [00:25<00:08, 317.35it/s]\u001b[A\n",
      " 76% 8039/10570 [00:25<00:07, 319.47it/s]\u001b[A\n",
      " 76% 8071/10570 [00:25<00:07, 318.66it/s]\u001b[A\n",
      " 77% 8105/10570 [00:25<00:07, 322.92it/s]\u001b[A\n",
      " 77% 8138/10570 [00:25<00:07, 322.28it/s]\u001b[A\n",
      " 77% 8171/10570 [00:26<00:07, 318.34it/s]\u001b[A\n",
      " 78% 8203/10570 [00:26<00:07, 315.63it/s]\u001b[A\n",
      " 78% 8235/10570 [00:26<00:07, 312.13it/s]\u001b[A\n",
      " 78% 8267/10570 [00:26<00:07, 310.64it/s]\u001b[A\n",
      " 79% 8299/10570 [00:26<00:07, 299.55it/s]\u001b[A\n",
      " 79% 8331/10570 [00:26<00:07, 303.45it/s]\u001b[A\n",
      " 79% 8365/10570 [00:26<00:07, 311.21it/s]\u001b[A\n",
      " 79% 8399/10570 [00:26<00:06, 317.79it/s]\u001b[A\n",
      " 80% 8433/10570 [00:26<00:06, 322.17it/s]\u001b[A\n",
      " 80% 8467/10570 [00:26<00:06, 325.85it/s]\u001b[A\n",
      " 80% 8500/10570 [00:27<00:06, 326.23it/s]\u001b[A\n",
      " 81% 8533/10570 [00:27<00:06, 326.44it/s]\u001b[A\n",
      " 81% 8566/10570 [00:27<00:06, 326.52it/s]\u001b[A\n",
      " 81% 8599/10570 [00:27<00:06, 325.69it/s]\u001b[A\n",
      " 82% 8632/10570 [00:27<00:05, 326.93it/s]\u001b[A\n",
      " 82% 8665/10570 [00:27<00:05, 325.23it/s]\u001b[A\n",
      " 82% 8699/10570 [00:27<00:05, 327.45it/s]\u001b[A\n",
      " 83% 8732/10570 [00:27<00:05, 322.98it/s]\u001b[A\n",
      " 83% 8765/10570 [00:27<00:05, 321.37it/s]\u001b[A\n",
      " 83% 8798/10570 [00:28<00:05, 320.10it/s]\u001b[A\n",
      " 84% 8831/10570 [00:28<00:05, 320.56it/s]\u001b[A\n",
      " 84% 8864/10570 [00:28<00:05, 321.49it/s]\u001b[A\n",
      " 84% 8897/10570 [00:28<00:05, 321.92it/s]\u001b[A\n",
      " 84% 8930/10570 [00:28<00:05, 322.55it/s]\u001b[A\n",
      " 85% 8963/10570 [00:28<00:04, 323.05it/s]\u001b[A\n",
      " 85% 8996/10570 [00:28<00:04, 324.83it/s]\u001b[A\n",
      " 85% 9029/10570 [00:28<00:04, 324.57it/s]\u001b[A\n",
      " 86% 9062/10570 [00:28<00:04, 323.43it/s]\u001b[A\n",
      " 86% 9095/10570 [00:28<00:04, 322.38it/s]\u001b[A\n",
      " 86% 9128/10570 [00:29<00:04, 323.06it/s]\u001b[A\n",
      " 87% 9161/10570 [00:29<00:04, 322.47it/s]\u001b[A\n",
      " 87% 9194/10570 [00:29<00:04, 322.82it/s]\u001b[A\n",
      " 87% 9227/10570 [00:29<00:04, 323.38it/s]\u001b[A\n",
      " 88% 9261/10570 [00:29<00:04, 327.03it/s]\u001b[A\n",
      " 88% 9294/10570 [00:29<00:03, 323.66it/s]\u001b[A\n",
      " 88% 9327/10570 [00:29<00:03, 323.42it/s]\u001b[A\n",
      " 89% 9360/10570 [00:29<00:03, 324.17it/s]\u001b[A\n",
      " 89% 9393/10570 [00:29<00:03, 323.11it/s]\u001b[A\n",
      " 89% 9426/10570 [00:29<00:03, 324.46it/s]\u001b[A\n",
      " 89% 9460/10570 [00:30<00:03, 326.35it/s]\u001b[A\n",
      " 90% 9493/10570 [00:30<00:03, 315.72it/s]\u001b[A\n",
      " 90% 9526/10570 [00:30<00:03, 319.27it/s]\u001b[A\n",
      " 90% 9560/10570 [00:30<00:03, 322.41it/s]\u001b[A\n",
      " 91% 9593/10570 [00:30<00:03, 322.26it/s]\u001b[A\n",
      " 91% 9627/10570 [00:30<00:02, 325.84it/s]\u001b[A\n",
      " 91% 9661/10570 [00:30<00:02, 328.05it/s]\u001b[A\n",
      " 92% 9695/10570 [00:30<00:02, 329.57it/s]\u001b[A\n",
      " 92% 9729/10570 [00:30<00:02, 331.05it/s]\u001b[A\n",
      " 92% 9763/10570 [00:30<00:02, 332.11it/s]\u001b[A\n",
      " 93% 9797/10570 [00:31<00:02, 328.95it/s]\u001b[A\n",
      " 93% 9830/10570 [00:31<00:02, 328.58it/s]\u001b[A\n",
      " 93% 9863/10570 [00:31<00:02, 325.68it/s]\u001b[A\n",
      " 94% 9896/10570 [00:31<00:02, 324.77it/s]\u001b[A\n",
      " 94% 9929/10570 [00:31<00:01, 324.65it/s]\u001b[A\n",
      " 94% 9962/10570 [00:31<00:01, 325.57it/s]\u001b[A\n",
      " 95% 9995/10570 [00:31<00:01, 321.67it/s]\u001b[A\n",
      " 95% 10029/10570 [00:31<00:01, 324.88it/s]\u001b[A\n",
      " 95% 10063/10570 [00:31<00:01, 326.19it/s]\u001b[A\n",
      " 96% 10096/10570 [00:32<00:01, 325.83it/s]\u001b[A\n",
      " 96% 10130/10570 [00:32<00:01, 327.47it/s]\u001b[A\n",
      " 96% 10163/10570 [00:32<00:01, 319.12it/s]\u001b[A\n",
      " 96% 10196/10570 [00:32<00:01, 319.96it/s]\u001b[A\n",
      " 97% 10229/10570 [00:32<00:01, 322.76it/s]\u001b[A\n",
      " 97% 10262/10570 [00:32<00:00, 322.09it/s]\u001b[A\n",
      " 97% 10296/10570 [00:32<00:00, 324.71it/s]\u001b[A\n",
      " 98% 10329/10570 [00:32<00:00, 324.38it/s]\u001b[A\n",
      " 98% 10362/10570 [00:32<00:00, 324.88it/s]\u001b[A\n",
      " 98% 10395/10570 [00:32<00:00, 322.89it/s]\u001b[A\n",
      " 99% 10428/10570 [00:33<00:00, 323.33it/s]\u001b[A\n",
      " 99% 10461/10570 [00:33<00:00, 321.94it/s]\u001b[A\n",
      " 99% 10494/10570 [00:33<00:00, 321.62it/s]\u001b[A\n",
      "100% 10528/10570 [00:33<00:00, 325.41it/s]\u001b[A\n",
      "100% 10570/10570 [00:33<00:00, 315.71it/s]\n",
      "12/01/2024 17:34:39 - INFO - utils_qa - Saving predictions to ./output_qa/mix/eval_predictions.json.\n",
      "12/01/2024 17:34:39 - INFO - utils_qa - Saving nbest_preds to ./output_qa/mix/eval_nbest_predictions.json.\n",
      "100% 1348/1348 [01:15<00:00, 17.97it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_exact_match        =    77.7673\n",
      "  eval_f1                 =    86.8021\n",
      "  eval_runtime            = 0:00:24.97\n",
      "  eval_samples            =      10784\n",
      "  eval_samples_per_second =     431.78\n",
      "  eval_steps_per_second   =     53.972\n",
      "[INFO|modelcard.py:449] 2024-12-01 17:34:44,300 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'squad', 'type': 'squad'}}\n"
     ]
    }
   ],
   "source": [
    "!bash run_squad.sh"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
